---
title: "Logistic regression"
editor: visual
---

# Warm up

## Check-in

-   Feedback on project proposals by the end of the week.
-   Exam review will be posted by the end of the week.
-   Exam:
    -   In class: Fri, June 7th (1 sheet of notes allowed)
    -   Take home due Sun, June 9th

# Logistic regression

## So far in regression

-   Outcome: Numerical, Predictor: One numerical or one categorical with only two levels $\rightarrow$ Simple linear regression

-   Outcome: Numerical, Predictors: Any number of numerical or categorical variables with any number of levels $\rightarrow$ Multiple linear regression

-   Outcome: Categorical with only two levels, Predictors: Any number of numerical or categorical variables with any number of levels $\rightarrow$ Logistic regression

-   Outcome: Categorical with any number of levels, Predictors: Any number of numerical or categorical variables with any number of levels $\rightarrow$ Generalized linear models -- Not covered in STA 101

## Data + packages {.smaller}

```{r}
#| label: load-data-packages
#| message: false

library(tidyverse)
library(tidymodels)

hp_spam <- read_csv("hp-spam.csv")
```

-   `r nrow(hp_spam)` emails collected at Hewlett-Packard labs and contains `r ncol(hp_spam)` variables

-   Outcome: `type`

    -   `type = 1` is spam

    -   `type = 0` is non-spam

-   Predictors of interest:

    -   `capitalTotal`: Number of capital letters in email

    -   Percentages are calculated as (100 \* number of times the WORD appears in the e-mail) / total number of words in email

        -   `george`: Percentage of "george"s in email (these were George's emails)

        -   `you`: Percentage of "you"s in email

## Glimpse at data

::: task
What type of data is `type`? What type should it be in order to use logistic regression?
:::

```{r}
hp_spam |>
  select(type, george, capitalTotal, you)
```

## EDA: How much spam?

```{r}
hp_spam |>
  count(type) |>
  mutate(p = n / sum(n))
```

## EDA: AM I SCREAMING? `capitalTotal`

```{r}
#| fig-width: 8
#| fig-asp: 0.618

ggplot(hp_spam, aes(x = capitalTotal)) +
  geom_histogram()
```

## EDA: `george`, is that `you`?

```{r}
#| layout-ncol: 2
#| fig-width: 5
#| fig-asp: 0.618

ggplot(hp_spam, aes(x = george)) +
  geom_histogram()
ggplot(hp_spam, aes(x = you)) +
  geom_histogram()
```

## Logistic regression

-   Logistic regression takes in a number of predictors and outputs the probability of a "success" (an outcome of 1) in a **binary** outcome variable.

-   The probability is related to the predictors via a **sigmoid link function**, $$
    p(y_i = 1) = \frac{1}{1+\text{exp}({- \sum \beta_i x_i })},
    $$whose output is in $(0,1)$ (a probability).

-   Can also be written as

$$
p(y_i = 1) = \frac{\text{exp}({\sum \beta_ix_i})}{1 + \text{exp}({\sum \beta_ix_i})}
$$

or in **Logit** form

$$
\text{logit}(p) = \log(\frac{p}{1 - p}) = \sum\beta_ix_i
$$

where $p = p(y_i = 1)$.

-   In this modeling scheme, one typically finds $\hat{\beta}$ by maximizing the **likelihood function**, another objective function, different than our previous "least squares" objective.

## Logistic regression, visualized

```{r}
#| echo: false

sigmoid = function(x) 1 / (1 + exp(-x + 10))
plot.function(sigmoid, from = 0, to = 20, n = 101, ylab="p(yi = 1)", xlab="input", main="Sigmoid link function", lwd = 3)
box()
```

## Using data to estimate $\beta_i$

To proceed with building our email classifier, we will, as usual, use our data (outcome $y_i$ and predictor $x_i$ pairs), to estimate $\beta$ (find $\hat{\beta}$) and obtain the model: $$
p(y_i = 1) = \frac{1}{1+\text{exp}({- \sum  \hat{\beta}_i x_i})},
$$

In this lecture, we'll build a spam filter. Or, at least, learn a bit about how spam filters are built by building a very simple (likely not very effective) one.

# Goals

-   Understand logistic regression as a linear model of binary outcomes

-   Fit and interpret logistic regression models in R

To illustrate logistic regression, we will build a spam filter from email data. Today's data consists of `r nrow(hp_spam)` emails that are classified as spam or non-spam.

The data was collected at Hewlett-Packard labs and contains `r nrow(hp_spam)` variables. The first 48 variables are specific keywords and each observation is the percentage of appearance of that word in the message. Click [here](https://rdrr.io/cran/kernlab/man/spam.html) to read more.

The basic logic of our model is that the frequency of certain words can help us determine whether or not an email is spam.

For example, these emails came from George's inbox. If the word "george" (`george`) is not present in the message and the dollar symbol (`charDollar`) is, you might expect the email to be spam.

Using this data, we want to build a model that **predicts** whether a new email is spam or not. How do we build a model that can do this?

# Building intuition

## Exercise 1

One predictor model: Visualize a **linear model** where the outcome is `type` (spam or not) and `george` is the only predictor. Then, discuss your visualization with your neighbor. Is this a good model? Why or why not?

*Add response here.*

```{r}
#| label: one-predictor-plot

# add code here
```

## Exercise 2

Two predictor model: In this exercise focus on two predictors: `you` and `capitalTotal`.

-   Create a visualization with `you` on the x-axis and `capitalTotal` on the y-axis. Color data points by whether or not they are spam (`type`). Make sure that `type` is being used as a categorical variable (factor).

```{r}
#| label: two-predictor-plot

# add code here
```

-   Fit the model predicting `type` from `you` and `capitalTotal`. Comment on how the code differs from code used in previous models we fit. Also comment on how it's similar.

```{r}
#| label: spam-fit

# add code here
```

## Exercise 3

Write the model equation.

*Add response here.*

## Exercise 4

What is the probability the email is spam if the frequency of `you` is 5% in the email and there are 2500 capital letters.

-   First, so this "by hand" (using R as a calculator) and the model you wrote in the previous exercise.

```{r}
#| label: predict-manual

# add code here
```

-   Then, do it using R functions designed for prediction.

```{r}
#| label: predict-function

# add code here
```

# Visualizing logistic regression

Just because there's greater than 50% probability an email is spam doesn't mean we have to label it as such. We can adjust our **threshold** or **critical probability**, a.k.a. **decision boundary** to be more or less sensitive to spam emails.

```{r}
#| label: decision-boundary
#| eval: false

spam_aug_1 <- augment(spam_fit, new_data = hp_spam)
decision_boundary <- 0.5

ggplot(spam_aug_1, aes(x = .pred_1, y = type)) +
  geom_jitter(alpha = 0.5, color = "darkgray") +
  geom_vline(xintercept = decision_boundary, color = "red", linetype = "dashed")
```

In other words we get to select a number $p^*$ such that

if $p > p^*$, then label the email as spam.

## Exercise 5

-   What would you set your decision boundary to and why?

-   Change `decision_boundary` in the code above to 0.01 and 0.999999. Do the results surprise you? Why or why not?

*Add response here.*

## Exercise 6

If you set a lower decision boundary, do you label fewer or more emails as spam? What happens if you set 0 as your boundary? What about 1 as your boundary? If you very much dislike spam, should you set a high or low boundary?

*Add response here.*

# Classify a new email

Read a new email and figure out values of `you` and `capitalTotal` (code already provided below) and store these in a new tibble called `new_email`.

```{r}
#| label: read-new-email

email_text <- read_lines("email-text.txt")
email_text

totalWord <- sum(str_count(email_text, " "))
totalYou <- sum(str_count(tolower(email_text), "you"))
you <- 100 * totalYou / totalWord
capitalTotal <- sum(str_count(email_text, "[A-Z]"))

# add code here
```

## Exercise 6

Using your model, predict whether this email will be classified as spam or not. What does the model predict for the **probability** that this email is spam? With a decision boundary of 0.5, how does the model classify thie email? Do you believe this classification? Why or why not?

```{r}
#| label: predict-new-email

# add code here
```

*Add response here.*

# Assessing predictive ability

We will divide the data into a training set and testing set.

```{r}
#| label: initial-split

set.seed(109)
hp_spam_split <- initial_split(hp_spam)
hp_spam_train <- training(hp_spam_split)
hp_spam_test <- testing(hp_spam_split)
```

## Exercise 7

Inspect `hp_spam_split`. How many emails are in `hp_spam_train`, how many are in `hp_spam_test`. Check out the documentation for the `initial_split()` function, what ratio does it use for splitting the dataset into training and testing samples?

*Add response here.*

```{r}
#| label: initial-split-inspect

# add code here
```

## Exercise 8

Train your model on the training set. Build a predictive model using any combination of predictors from `hp_spam` to predict `type`. Save your fitted model as `my_model_fit` and display its tidy summary.

```{r}
#| label: my-model-fit

# add code here
```

## Exercise 9

Make predictions for your testing set and augment your testing set with these predictions.

```{r}
#| label: my-model-test

# add code here
```

## Exercise 10

What are the false positive and false negative rates of this model?

```{r}
#| label: false-positive-negative

# add code here
```

*Add response here.*
