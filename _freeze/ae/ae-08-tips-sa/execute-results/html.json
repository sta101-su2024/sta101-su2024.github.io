{
  "hash": "09cc6146b118ea1666f623d3b216c28f",
  "result": {
    "markdown": "---\ntitle: \"Tips\"\ncategories: \n  - Application exercise\n  - Suggested answers\neditor: visual\n---\n\n\n::: callout-important\nThese are suggested answers for the application exercise. They're not necessarily complete or 100% accurate, they're roughly what we develop in class while going through the exercises.\n:::\n\nToday we'll explore the question \"What best predicts what percent of the bill amount people tip at restaurants?\"\n\n# Goals\n\n-   Build, fit, and interpret linear models with more than one predictor\n\n-   Compute $R^2$ and adjusted $R^2$\n\n-   Use adjusted $R^2$ for stepwise model selection\n\n-   Evaluate predictive performance of models\n\n# Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(scales)\n```\n:::\n\n\n# Data\n\nThe data for this application exercise was collected in 2011 by a student at St. Olaf who worked at a local restaurant.[^1]\n\n[^1]: Dahlquist, Samantha, and Jin Dong. 2011. \"The Effects of Credit Cards on Tipping.\" Project for Statistics 212-Statistics for the Sciences, St. Olaf College.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntips <- read_csv(\"data/tips.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 129 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): day, meal, payment, age, gift_card, comps, alcohol, bday\ndbl (5): party, bill, w_tip, tip, tip_percentage\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\nThe dataset has 129 observations and 13 columns. Each observation represents a meal by a party at the restaurant, and for each meal we know the bill amount, the tip amount, and a variety of other features like whether the payment was made on credit card or by cash, whether any alcohol was ordered, etc.\n\nTo keep the scope manageable for this application exercise, we'll only consider the following predictors:\n\n-   `meal`: Meal of the day (`Lunch`, `Dinner`, or `Late Night`)\n\n-   `party`: Number of people in the party\n\n-   `alcohol`: Whether the party ordered any alcohol (`No` or `Yes`)\n\n-   `bill`: Bill amount, in USD\n\nWe will aim to predict `tip_percentage` from these variables.\n\n# Exploratory data analysis\n\n## Exercise 1\n\nVisualize the relationship between these variables.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntips <- tips |>\n  mutate(meal = fct_relevel(meal, \"Lunch\", \"Dinner\", \"Late Night\"))\n\nggplot(tips, aes(x = bill, y = tip_percentage, color = party)) +\n  geom_point(alpha = 0.7) +\n  facet_grid(alcohol ~ meal) +\n  scale_colour_continuous(breaks = c(1:9)) +\n  scale_y_continuous(labels = label_percent()) +\n  labs(\n    x = \"Bill amount (USD)\",\n    y = \"Tip percentage\",\n    color = \"Party\\nsize\"\n  )\n```\n\n::: {.cell-output-display}\n![](ae-08-tips-sa_files/figure-html/eda-1.png){width=960}\n:::\n:::\n\n\n## Exercise 2\n\nIn a couple of sentences, describe any apparent patterns.\n\n> Add response here.\n\n# Strength of fit\n\n## Exercise 3\n\nFit a model predicting tip percentage from bill amount. Display and interpret the model coefficients. Additionally, calculate and interpret the $R^2$ of this model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntip_1_fit <- linear_reg() |>\n  fit(tip_percentage ~ bill, data = tips)\n\ntidy(tip_1_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  0.198     0.0134       14.8  2.16e-29\n2 bill        -0.000748  0.000390     -1.92 5.70e- 2\n```\n\n\n:::\n:::\n\n\n> -   For each additional dollar the bill is higher, we expect the tip percentage to be lower, on average, by 0.0748%.\n>\n> <!-- -->\n>\n> -   For bills that are 0 dollars, the model predicts the tip percentage to be 19.8%. This doesn't make sense in context of the data and the intercept is only there the adjust the height of the line.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(tip_1_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared  sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl>  <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1    0.0282        0.0206 0.0819      3.69  0.0570     1   141. -275. -267.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n\n\n:::\n:::\n\n\n> Roughly 2.6% of the variability in tip percentages can be explained by bill amount.\n\n## Exercise 4\n\nSuppose we next add `meal` as a predictor and interpret the model coefficients again.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntip_2_fit <- linear_reg() |>\n  fit(tip_percentage ~ bill + meal, data = tips)\n\ntidy(tip_2_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 4 × 5\n  term            estimate std.error statistic  p.value\n  <chr>              <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)     0.185     0.0237       7.80  2.07e-12\n2 bill           -0.000561  0.000446    -1.26  2.10e- 1\n3 mealDinner      0.00471   0.0191       0.247 8.05e- 1\n4 mealLate Night  0.0203    0.0250       0.814 4.17e- 1\n```\n\n\n:::\n:::\n\n\n> -   All else held constant, for each additional dollar the bill is higher, we expect the tip percentage to be lower, on average, by 0.0561%.\n>\n> -   All else held constant, we would expect the the tip percentage for dinners to be higher, on average, by 0.471% compared to lunches.\n>\n> -   All else held constant, we would expect the the tip percentage for late night meals to be higher, on average, by 2.03% compared to lunches.\n\n## Exercise 5\n\nWould you expect the $R^2$ of the second model (with `bill` and `meal` as predictors) to be higher, lower, or the same as the $R^2$ for the first model (with only `bill` as the predictor)? Explain your reasoning.\n\n> Higher, adding a predictor always increases $R^2$.\n\n## Exercise 6\n\nFit a model predicting tip percentage from bill amount and meal, calculate its $R^2$, and comment on your guess from the previous exercise.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(tip_2_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared  sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl>  <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1    0.0342        0.0110 0.0823      1.48   0.224     3   141. -272. -258.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n\n\n:::\n:::\n\n\n> Indeed, $R^2$ is higher.\n\n# Adjusted $R^2$\n\n## Exercise 7\n\nCalculate adjusted $R^2$ for the two models. Is adding `meal` to a model predicting `tip_percentage` from `bill` useful?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(tip_1_fit)$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02056839\n```\n\n\n:::\n\n```{.r .cell-code}\nglance(tip_2_fit)$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01103831\n```\n\n\n:::\n:::\n\n\n> No, adjusted $R^2$ goes down.\n\n# Stepwise model selection\n\n## Backward elimination\n\nBackward elimination starts with the full model (the model that includes all potential predictor variables). Variables are eliminated one-at-a-time from the model until we cannot improve the model any further.\n\nProcedure:\n\n1.  Start with a model that has all predictors we consider and compute the adjusted $R^2$.\n\n2.  Next fit every possible model with 1 fewer predictor.\n\n3.  Compare adjusted $R^2$s to select the best model (highest adjusted $R^2$) with 1 fewer predictor.\n\n4.  Repeat steps 2 and 3 until adjusted $R^2$ no longer increases.\n\n## Forward selection\n\nForward selection is the reverse of the backward elimination technique. Instead, of eliminating variables one-at-a-time, we add variables one-at-a-time until we cannot find any variables that improve the model any further.\n\nProcedure:\n\n1.  Start with a model that has no predictors.\n\n2.  Next fit every possible model with 1 additional predictor and calculate adjusted $R^2$ of each model.\n\n3.  Compare adjusted $R^2$ values to select the best model (highest adjusted $R^2$) with 1 additional predictor.\n\n4.  Repeat steps 2 and 3 until adjusted $R^2$ no longer increases.\n\n## Exercise 8\n\nPerform backward elimination to find the best model for predicting `tip_percentage` from `meal`, `party`, `alcohol`, `bill`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntip_full_fit <- linear_reg() |> fit(tip_percentage ~ meal + party + alcohol + bill, data = tips)\nglance(tip_full_fit)$adj.r.squared\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.0003858485\n```\n\n\n:::\n\n```{.r .cell-code}\n# step 1\nlinear_reg() |> fit(tip_percentage ~ meal + party + alcohol, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.001215283\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ meal + party + bill, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.007718966\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ meal + alcohol + bill, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.004761466\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ party + alcohol + bill, data = tips) |> glance() |> pull(adj.r.squared) # highest adj R-sq: 0.021\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01225785\n```\n\n\n:::\n\n```{.r .cell-code}\n# step 2\nlinear_reg() |> fit(tip_percentage ~ party + alcohol, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.0003317171\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ party + bill, data = tips) |> glance() |> pull(adj.r.squared) # highest adj R-sq:  0.027\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01989357\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ alcohol + bill, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01374295\n```\n\n\n:::\n\n```{.r .cell-code}\n# step 3 - no increase in adj R-sq\nlinear_reg() |> fit(tip_percentage ~ bill, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02056839\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ party, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.00420045\n```\n\n\n:::\n:::\n\n\n> The \"best\" model attained with backwards elimination predicts `tip_percentage` from `party` and `bill`.\n\n## Exercise 9\n\nPerform backward elimination to find the best model for predicting `tip_percentage` from `meal`, `party`, `alcohol`, `bill`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# step 1\nlinear_reg() |> fit(tip_percentage ~ meal, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.006434878\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ party, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.00420045\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ alcohol, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] -0.002762376\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ bill, data = tips) |> glance() |> pull(adj.r.squared) # highest adj R-sq: 0.02\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.02056839\n```\n\n\n:::\n\n```{.r .cell-code}\n# step 2\nlinear_reg() |> fit(tip_percentage ~ bill + meal, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01103831\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ bill + party, data = tips) |> glance() |> pull(adj.r.squared) # highest adj R-sq:  0.027\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01989357\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ bill + alcohol, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01374295\n```\n\n\n:::\n\n```{.r .cell-code}\n# step 3 - no increase in adj R-sq\nlinear_reg() |> fit(tip_percentage ~ bill + party + meal, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.007718966\n```\n\n\n:::\n\n```{.r .cell-code}\nlinear_reg() |> fit(tip_percentage ~ bill + party + alcohol, data = tips) |> glance() |> pull(adj.r.squared)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.01225785\n```\n\n\n:::\n:::\n\n\n> The \"best\" model attained with forward selection also predicts `tip_percentage` from `party` and `bill`.\n\n## Exercise 10\n\nFit the \"best\" model and interpret it.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntip_fit <- linear_reg() |> \n  fit(tip_percentage ~ bill + party, data = tips)\n\ntidy(tip_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  0.193    0.0142      13.6   1.44e-26\n2 bill        -0.00145  0.000834    -1.74  8.40e- 2\n3 party        0.0113   0.0118       0.955 3.41e- 1\n```\n\n\n:::\n:::\n\n\n> Add response here.\n\n# Predictive performance\n\nA common way of evaluating the predictive performance of a model is to test it against new data that was not used to build the model in the first place. In machine learning, this new dataset is commonly referred to as **testing data**, and the dataset that was used to build and select the model is commonly referred to as **training data**.\n\nLet's first load the new data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntips_test <- read_csv(\"data/tips-test.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRows: 40 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (8): day, meal, payment, age, gift_card, comps, alcohol, bday\ndbl (5): party, bill, w_tip, tip, tip_percentage\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n\n\n:::\n:::\n\n\nThere are 40 observations in this new dataset, and it has all the same columns as our existing dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(tips_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 40\nColumns: 13\n$ day            <chr> \"Tuesday\", \"Tuesday\", \"Sunday\", \"Friday\", \"Friday\", \"Sa…\n$ meal           <chr> \"Late Night\", \"Dinner\", \"Lunch\", \"Late Night\", \"Late Ni…\n$ payment        <chr> \"Credit\", \"Cash\", \"Cash\", \"Cash\", \"Credit\", \"Credit\", \"…\n$ party          <dbl> 1, 2, 2, 1, 3, 5, 4, 3, 3, 2, 1, 6, 4, 4, 6, 1, 2, 2, 3…\n$ age            <chr> \"Yadult\", \"Middle\", \"SenCit\", \"Yadult\", \"Middle\", \"Midd…\n$ gift_card      <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"…\n$ comps          <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"…\n$ alcohol        <chr> \"No\", \"No\", \"No\", \"No\", \"Yes\", \"No\", \"Yes\", \"No\", \"No\",…\n$ bday           <chr> \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"No\", \"…\n$ bill           <dbl> 3.74, 26.54, 25.68, 4.98, 25.40, 64.28, 57.86, 30.38, 3…\n$ w_tip          <dbl> 4.74, 31.00, 30.00, 5.00, 29.40, 74.28, 67.86, 35.38, 3…\n$ tip            <dbl> 1.00, 4.46, 4.32, 0.02, 4.00, 10.00, 10.00, 5.00, 3.48,…\n$ tip_percentage <dbl> 0.267379679, 0.168048229, 0.168224299, 0.004016064, 0.1…\n```\n\n\n:::\n:::\n\n\nLet's use our model to make predictions for `tip_percentage` for these new data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntip_aug <- augment(tip_fit, new_data = tips_test)\ntip_aug\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 40 × 15\n   .pred    .resid day   meal  payment party age   gift_card comps alcohol bday \n   <dbl>     <dbl> <chr> <chr> <chr>   <dbl> <chr> <chr>     <chr> <chr>   <chr>\n 1 0.199  0.0683   Tues… Late… Credit      1 Yadu… No        No    No      No   \n 2 0.177 -0.00918  Tues… Dinn… Cash        2 Midd… No        No    No      No   \n 3 0.178 -0.0103   Sund… Lunch Cash        2 SenC… No        No    No      No   \n 4 0.197 -0.193    Frid… Late… Cash        1 Yadu… No        No    No      No   \n 5 0.190 -0.0327   Frid… Late… Credit      3 Midd… No        No    Yes     No   \n 6 0.156 -0.000670 Satu… Dinn… Credit      5 Midd… No        No    No      No   \n 7 0.154  0.0185   Satu… Dinn… Credit      4 Midd… No        No    Yes     No   \n 8 0.183 -0.0183   Sund… Lunch Credit…     3 SenC… No        No    No      No   \n 9 0.180 -0.0728   Satu… Dinn… Cash        3 Midd… No        No    No      No   \n10 0.174  0.0202   Thur… Dinn… Credit      2 Midd… No        No    No      No   \n# ℹ 30 more rows\n# ℹ 4 more variables: bill <dbl>, w_tip <dbl>, tip <dbl>, tip_percentage <dbl>\n```\n\n\n:::\n:::\n\n\nWe can plot the predicted values of `tip_percentage` against the observed values to see how well we're doing.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(tip_aug, aes(x = tip_percentage, y = .pred)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"gray\") +\n  scale_x_continuous(labels = label_percent()) +\n  scale_y_continuous(labels = label_percent()) +\n  coord_fixed()\n```\n\n::: {.cell-output-display}\n![](ae-08-tips-sa_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\nWe can also quantify the average error in our predictions with a measure called **root mean square error**, RMSE.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrmse(tip_aug, truth = tip_percentage, estimate = .pred)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard      0.0591\n```\n\n\n:::\n:::\n\n\nWhat this value tells us is that our predictions are off by, on average, approximately 6%.\n\nLet's take a look back at the tip percentage variables in this dataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(tips_test, aes(x = tip_percentage)) +\n  geom_histogram(binwidth = 0.05) +\n  scale_x_continuous(labels = label_percent())\n```\n\n::: {.cell-output-display}\n![](ae-08-tips-sa_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n\nThe tips range anywhere from 0 to 30% and our predictions are off, on average, by 6%. It's not great, and it's not terrible either. This, of course, is not a very technical assessment of the predictive performance of our model. There are much more formal ways of evaluating the predictive performance of a model using RMSE, but this is a good starting point for making sense of how well you're doing with your predictions.\n",
    "supporting": [
      "ae-08-tips-sa_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}