{
  "hash": "820f2c0d31ecab0f3db2f815533e590f",
  "result": {
    "markdown": "---\ntitle: Regression with a single predictor\nsubtitle: Lecture 6\nformat: revealjs\nauto-stretch: false\n---\n\n\n# Warm up\n\n## Check-in\n\n-   Daily check-ins for getting you thinking at the beginning of the class and reviewing recent/important concepts\n-   Go to Canvas and open today's \"quiz\" titled `2023-09-18 Check-in`\n-   Access code: \\_\\_\\_ (released in class)\n-   \"Graded\" for completion\n\n## Announcements\n\n-   Lab 3 is due Thu, Sep 21 at 5 pm on Gradescope\n-   No class on Wednesday, catch up on readings, interactive tutorials, labs!\n\n# Regression with a single predictor\n\n## Data and packages\n\nWe'll work with data on Apple and Microsoft stock prices and use the **tidyverse** and **tidymodels** packages.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nstocks <- read_csv(\"data/stocks.csv\")\n```\n:::\n\n\n## Simple regression model and notation {.smaller}\n\n$$\ny = \\beta_0 + \\beta_1 x + \\epsilon\n$$\n\n::: incremental\n-   $y$: the **outcome** variable. Also called the \"response\" or \"dependent variable\". In prediction problems, this is what we are interested in predicting.\n\n-   $x$: the **predictor**. Also commonly referred to as \"regressor\", \"independent variable\", \"covariate\", \"feature\", \"the data\".\n\n-   $\\beta_0$, $\\beta_1$ are called \"constants\" or **coefficients**. They are fixed numbers. These are **population parameters**. $\\beta_0$ has another special name, \"the intercept\".\n\n-   $\\epsilon$: the **error**. This quantity represents observational error, i.e. the difference between our observation and the true population-level expected value: $\\beta_0 + \\beta_1 x$.\n:::\n\n. . .\n\nEffectively this model says our data $y$ is linearly related to $x$ but is not perfectly observed due to some error.\n\n## Stock prices of Microsoft and Apple\n\nLet's examine January 2020 open prices of Microsoft and Apple stocks to illustrate some ideas.\n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\nstocks_jan2020 <- stocks |>\n  filter(month(date) == 1 & year(date) == 2020)\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )\n```\n\n::: {.cell-output-display}\n![](06-simple-regression_files/figure-revealjs/stocks-jan2020-1.png){width=960}\n:::\n:::\n\n\n## Fitting \"some\" model\n\nBefore we get to fitting the best model, let's fit \"some\" model, say with slope = -5 and intercept = 0.5.\n\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code  code-line-numbers=\"|3\"}\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  geom_abline(slope = 0.5, intercept = -5) +\n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )\n```\n\n::: {.cell-output-display}\n![](06-simple-regression_files/figure-revealjs/stocks-jan2020-some-model-1.png){width=960}\n:::\n:::\n\n\n## Fitting \"some\" model\n\n$$\n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x \\\\\n\\hat{y} = -5 + 0.5 ~ x\n$$\n\n-   $\\hat{y}$ is the **expected outcome**\n-   $\\hat{\\beta}$ is the **estimated** or **fitted** coefficient\n-   There is no error term here because we do not predict error\n\n## Populations vs. samples\n\n::: columns\n::: {.column width=\"50%\"}\nPopulation:\n\n$$\ny = \\beta_0 + \\beta_1 ~ x\n$$\n:::\n\n::: {.column width=\"50%\"}\nSamples:\n$$\n\\hat{y} = \\hat{\\beta_0} +  \\hat{\\beta_1} ~ x\n$$\n:::\n:::\n\n::: incremental\n-   The central idea is that if we measure every $x$ and every $y$ in existence, (\"the entire population\") there is some true \"best\" $\\beta_0$ and $\\beta_1$ that describe the relationship between $x$ and $y$\n-   Since we only have a **sample** of the data, we estimate $\\beta_0$ and $\\beta_1$\n-   We call our estimates $\\hat{\\beta_0}$, $\\hat{\\beta_1}$ \"beta hat\". We never have all the data, thus we never can really know what the true $\\beta$s are\n:::\n\n## Residuals\n\n- For any linear equation we write down, there will be some difference between the predicted outcome of our linear model ($\\hat{y}$) and what we observe ($y$)... (But of course! Otherwise everything would fall on a perfect straight line!)\n\nThis difference between what we observe and what we predict $y - \\hat{y}$ is known as a residual, $e$.\n\nMore concisely,\n\n$$\ne = y - \\hat{y}\n$$\n\n## A residual, visualized\n\nResiduals are dependent on the line we draw. Visually, here is a model of the data, $y = -5 + 0.5 ~ x$ and one of the residuals is outlined in red.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](06-simple-regression_files/figure-revealjs/unnamed-chunk-4-1.png){fig-align='center' width=768}\n:::\n:::\n\n\n## All residuals, visualized\n\nThere is, in fact, a residual associated with every single point in the plot.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](06-simple-regression_files/figure-revealjs/all-residuals-1.png){width=960}\n:::\n:::\n\n\n## Minimize residuals\n\nWe often wish to find a line that fits the data \"really well\", but what does this mean? \nWell, we want small residuals! \nSo we pick an **objective function**. That is, a function we wish to minimize or maximize.\n\n## Application exercise\n\nGo to Posit Cloud and start the project titled **ae-06-Stocks**.\n",
    "supporting": [
      "06-simple-regression_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}