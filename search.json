[
  {
    "objectID": "computing/computing-cheatsheets.html",
    "href": "computing/computing-cheatsheets.html",
    "title": "R cheatsheets",
    "section": "",
    "text": "The following cheatsheets come from https://posit.co/resources/cheatsheets. We haven’t covered every function and functionality listed on them, but you might still find them useful as references.",
    "crumbs": [
      "Computing",
      "Cheatsheets"
    ]
  },
  {
    "objectID": "course-links.html",
    "href": "course-links.html",
    "title": "Useful links",
    "section": "",
    "text": "Container Manager\n🔗 Container Manager\n\n\n\nGradescope\n🔗 Gradescope\n\n\n\nDiscussion board\n🔗 on Canvas\n\n\n\nAnnouncements\n🔗 on Canvas\n\n\n\nTextbooks\n🔗 Introduction to Modern Statistics, 2nd Edition\n🔗 R for Data Science, 2nd Edition\n\n\n\nPackage documentation\n🔗 tidyverse: tidyverse.org\n🔗 tidymodels: tidymodels.org",
    "crumbs": [
      "Course information",
      "Useful links"
    ]
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html",
    "href": "lectures/02/02-hello_data_filled_in.html",
    "title": "Hello data - filled in notes",
    "section": "",
    "text": "Office hours are updated with minor changes on the course website .\nIf you haven’t yet done so, please:\n\ncomplete the Getting to know you survey\nread through the syllabus"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#rstudio",
    "href": "lectures/02/02-hello_data_filled_in.html#rstudio",
    "title": "Hello data - filled in notes",
    "section": "RStudio",
    "text": "RStudio\n\nFiles, plots, viewer, environment, etc. panes\nConsole\nEditor"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#r",
    "href": "lectures/02/02-hello_data_filled_in.html#r",
    "title": "Hello data - filled in notes",
    "section": "R",
    "text": "R\n\nWriting code in the console\nBasic math with R\n\n1+2*(3+5)\n\n[1] 17\n\n\nCreating variables in R, the assignment operator (&lt;-), and the Environment pane\n\nage &lt;- 27\n\nage + 4\n\n[1] 31\n\nage + 9\n\n[1] 36\n\n\nR functions and packages and the Packages pane\nGetting help with R and the Help pane"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#quarto",
    "href": "lectures/02/02-hello_data_filled_in.html#quarto",
    "title": "Hello data - filled in notes",
    "section": "Quarto",
    "text": "Quarto\n\nYAML: Metadata\nNarrative: Edited with the visual editor (or the source editor)\nCode: In code chunks\n\nChunk options (following #|)\nComments (following #)\nCode\n\nRunning individual code chunks vs. rendering a document"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#load-packages",
    "href": "lectures/02/02-hello_data_filled_in.html#load-packages",
    "title": "Hello data - filled in notes",
    "section": "Load packages",
    "text": "Load packages\nWe’ll use the tidyverse package for analysis, which offers functionality for data import, wrangling, visualization, and more.\n\n# load a package\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::%||%()   masks base::%||%()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nLoading this package prints out a message. What does this message mean? How can we suppress the message from the output?"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#load-data",
    "href": "lectures/02/02-hello_data_filled_in.html#load-data",
    "title": "Hello data - filled in notes",
    "section": "Load data",
    "text": "Load data\nThe read_csv() function can be used for reading CSV (comma separated values) files. The file we’re reading is called flint with the suffix (.csv) which indicates its file type.\n\nflint &lt;- read_csv(\"flint.csv\")\n\nRows: 813 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): draw\ndbl (4): id, zip, ward, lead\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nview(flint)\n\nOne of two things may have happened:\n\nThe file was read successfully and you now see a dataset called flint in your Environment pane.\nThe file was not read successfully and you see an error Error in read_csv(\"flint.csv\") : could not find function \"read_csv\".\n\nIf (1) happened, great!\nIf (2) happened, let’s troubleshoot first before continuing."
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#data-dictionary",
    "href": "lectures/02/02-hello_data_filled_in.html#data-dictionary",
    "title": "Hello data - filled in notes",
    "section": "Data dictionary",
    "text": "Data dictionary\nThe following variables are in the flint data frame:\n\nid: sample ID number (identifies the home)\nzip: ZIP code in Flint of the sample’s location\nward: ward in Flint of the sample’s location\ndraw: which time point the water was sampled from\nlead: lead content in parts per billion (ppb)"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#populations-and-samples",
    "href": "lectures/02/02-hello_data_filled_in.html#populations-and-samples",
    "title": "Hello data - filled in notes",
    "section": "Populations and samples",
    "text": "Populations and samples\nWe want to learn about the population using a sample.\nIn the case we want to learn about the lead content in all of Flint, MI homes but only have available water readings from a sample of homes (our data set).\nExercise 1: Look at the data, how many observations are there? How many variables?\n\nnrow(flint)\n\n[1] 813\n\nncol(flint)\n\n[1] 5\n\n\nThere are 813 observations and 5 variables."
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#frequencies",
    "href": "lectures/02/02-hello_data_filled_in.html#frequencies",
    "title": "Hello data - filled in notes",
    "section": "Frequencies",
    "text": "Frequencies\nLet’s count() to find the number of different time points water was sampled with the count() function.\n\nThe first argument is flint: the data frame\nThe second argument is draw: the variable\n\n\ncount(flint, draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can achieve the same result with the following “piped” operation as well.\n\nThe first line is flint: the data frame\nThen the pipe operator, read as “and then”, which places what comes before it as the first argument of what comes after it\nThe second line is count(draw)\n\n\nflint |&gt;\n  count(draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can use a similar approach to fund out how many unique homes are in the data set:\n\nflint |&gt;\n  count(id)\n\n# A tibble: 269 × 2\n      id     n\n   &lt;dbl&gt; &lt;int&gt;\n 1     1     3\n 2     2     3\n 3     4     3\n 4     5     3\n 5     6     3\n 6     7     3\n 7     8     3\n 8     9     3\n 9    12     3\n10    13     3\n# ℹ 259 more rows\n\n\nExercise 2: How many samples were taken from each zip code?\n\nflint |&gt;\n  count(zip)\n\n# A tibble: 8 × 2\n    zip     n\n  &lt;dbl&gt; &lt;int&gt;\n1 48502     3\n2 48503   207\n3 48504   165\n4 48505   144\n5 48506   132\n6 48507   153\n7 48529     3\n8 48532     6\n\n\nExercise 3: Which ZIP code had the most samples drawn? Hint: See the help for count.\n\nflint |&gt;\n  count(zip, sort = TRUE)\n\n# A tibble: 8 × 2\n    zip     n\n  &lt;dbl&gt; &lt;int&gt;\n1 48503   207\n2 48504   165\n3 48507   153\n4 48505   144\n5 48506   132\n6 48532     6\n7 48502     3\n8 48529     3"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#measures-of-central-tendency",
    "href": "lectures/02/02-hello_data_filled_in.html#measures-of-central-tendency",
    "title": "Hello data - filled in notes",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency\n\nmean\nmedian\nmode"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#measures-of-spread",
    "href": "lectures/02/02-hello_data_filled_in.html#measures-of-spread",
    "title": "Hello data - filled in notes",
    "section": "Measures of spread",
    "text": "Measures of spread\n\nvariance\nstandard deviation\nrange\nquartiles\ninter-quartile range (IQR)"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#order-statistics",
    "href": "lectures/02/02-hello_data_filled_in.html#order-statistics",
    "title": "Hello data - filled in notes",
    "section": "Order statistics",
    "text": "Order statistics\n\nquantiles\nminimum (0 percentile)\nmedian (50th percentile)\nmaximum (100 percentile)\n\n… and any other arbitrary function of the data you can come up with!\nExercise 4: Compute each of these statistics for lead ppb.\n\nsummary_table &lt;- flint |&gt;\n  summarize(mean_lead = mean(lead),\n            median_lead = median(lead),\n            var_lead = var(lead),\n            sd_lead = sd(lead))\nsummary_table\n\n# A tibble: 1 × 4\n  mean_lead median_lead var_lead sd_lead\n      &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;\n1      8.20        1.85    1718.    41.5"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#histograms",
    "href": "lectures/02/02-hello_data_filled_in.html#histograms",
    "title": "Hello data - filled in notes",
    "section": "Histograms",
    "text": "Histograms\nLet’s take a look at the distribution of lead content in homes in Flint, MI.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can make this plot look nicer/more useful by adjusting the number of bins and zooming into the x-axis.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram(bins = 50) +\n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nLet’s visualize some of our summary statistics on the plot.\nExercise 5: Add a new layer, geom_vline(xintercept = __, color = \"red\"), to the histogram below, filling in the blank with the mean.\n\nmean_lead &lt;- mean(flint$lead)\n\n\nggplot(flint, aes(x = lead)) + \n  geom_histogram(bins = 50) + \n  coord_cartesian(xlim = c(0, 100)) +\n  geom_vline(xintercept = summary_table$mean_lead, color = \"red\")\n\n\n\n\n\n\n\n\nExercise 6: Add one more layer which overlays the median, in a different color.\n\nggplot(flint, aes(x = lead)) + \n  geom_histogram(bins = 50) + \n  coord_cartesian(xlim = c(0, 100)) +\n  geom_vline(xintercept = summary_table$mean_lead, color = \"red\") +\n  geom_vline(xintercept = summary_table$median_lead, color = \"blue\")\n\n\n\n\n\n\n\n# add code here"
  },
  {
    "objectID": "lectures/02/02-hello_data_filled_in.html#box-plots",
    "href": "lectures/02/02-hello_data_filled_in.html#box-plots",
    "title": "Hello data - filled in notes",
    "section": "Box plots",
    "text": "Box plots\nNext, let’s narrow our focus to the zip codes 48503, 48504, 48505, 48506, and 48507 and observations with lead values less than 1,000 ppb.\n\nflint_focus &lt;- flint |&gt;\n  filter(zip %in% 48503:48507 & lead &lt; 1000)\n\nExercise 7: Below are side-by-side box plots for the three flushing times in each of the five zip codes we considered. Add x and y labels; add a title by inserting title = \"title_name\" inside the labs() function.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) +\n  labs(x = \"Lead (ppb)\", y = \"Zip code\", fill = \"Flushing time\") +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  )\n\n\n\n\n\n\n\n\nExercise 8: Add labels for x, y, a title, and subtitle to the code below to update the corresponding plot.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) + \n  labs(\n    x = \"Lead (ppb)\", y = \"Zip code\", fill = \"Flushing time\",\n    title = \"Lead amount by flushing time\",\n    subtitle = \"In five zip codes\"\n    ) +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  ) +\n  coord_cartesian(xlim = c(0, 50)) +\n  theme_bw()\n\n\n\n\n\n\n\n\nExercise 9: What is the difference between the two plots? What are the advantages and disadvantages to each plot?\nThe first plot shows extreme outliers, while the second plot makes it easier to see the bulk of the distribution."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "A hypothesis test is a statistical technique used to evaluate competing claims using data.\n\nNull hypothesis, \\(H_o\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n\n\n\n\n\nNote\n\n\n\nHypotheses are always at the population level!\n\n\n\n\n\nSuppose you’re cooking a pot of soup:\n\n\nTaste a spoonful and decide if that spoonful has enough salt \\(\\rightarrow\\) exploratory data analysis of the sample\nDecide the pot of soup must also have enough salt since the spoonful does \\(\\rightarrow\\) inference\nMixing the soup in the pot before taking a spoonful \\(\\rightarrow\\) randomizing\nTaking a spoonful with the intention of making an inference about the pot \\(\\rightarrow\\) sampling\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::%||%()   masks base::%||%()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5          ✔ rsample      1.2.0     \n✔ dials        1.2.0          ✔ tune         1.1.2     \n✔ infer        1.0.5.9000     ✔ workflows    1.1.3     \n✔ modeldata    1.2.0          ✔ workflowsets 1.0.1     \n✔ parsnip      1.1.1          ✔ yardstick    1.2.0     \n✔ recipes      1.0.8          \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::%||%()     masks base::%||%()\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(openintro)  # for data for case study 2: yawn\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#hypothesis-testing-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#hypothesis-testing-1",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "A hypothesis test is a statistical technique used to evaluate competing claims using data.\n\nNull hypothesis, \\(H_o\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n\n\n\n\n\nNote\n\n\n\nHypotheses are always at the population level!"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#populations-vs.-samples",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#populations-vs.-samples",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "Suppose you’re cooking a pot of soup:\n\n\nTaste a spoonful and decide if that spoonful has enough salt \\(\\rightarrow\\) exploratory data analysis of the sample\nDecide the pot of soup must also have enough salt since the spoonful does \\(\\rightarrow\\) inference\nMixing the soup in the pot before taking a spoonful \\(\\rightarrow\\) randomizing\nTaking a spoonful with the intention of making an inference about the pot \\(\\rightarrow\\) sampling"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#packages",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#packages",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::%||%()   masks base::%||%()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5          ✔ rsample      1.2.0     \n✔ dials        1.2.0          ✔ tune         1.1.2     \n✔ infer        1.0.5.9000     ✔ workflows    1.1.3     \n✔ modeldata    1.2.0          ✔ workflowsets 1.0.1     \n✔ parsnip      1.1.1          ✔ yardstick    1.2.0     \n✔ recipes      1.0.8          \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::%||%()     masks base::%||%()\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(openintro)  # for data for case study 2: yawn\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#organ-donors",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#organ-donors",
    "title": "Hypothesis testing with randomization",
    "section": "Organ donors",
    "text": "Organ donors\nPeople providing an organ for donation sometimes seek the help of a special “medical consultant”. These consultants assist the patient in all aspects of the surgery, with the goal of reducing the possibility of complications during the medical procedure and recovery. Patients might choose a consultant based in part on the historical complication rate of the consultant’s clients.\nOne consultant tried to attract patients by noting that the average complication rate for liver donor surgeries in the US is about 10%, but her clients have only had 3 complications in the 62 liver donor surgeries she has facilitated. She claims this is strong evidence that her work meaningfully contributes to reducing complications (and therefore she should be hired!)."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#data",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#data",
    "title": "Hypothesis testing with randomization",
    "section": "Data",
    "text": "Data\n\norgan_donor &lt;- read_csv(\"organ-donor.csv\")\n\norgan_donor |&gt;\n  count(outcome)\n\n# A tibble: 2 × 2\n  outcome             n\n  &lt;chr&gt;           &lt;int&gt;\n1 complication        3\n2 no complication    59"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#parameter-vs.-statistic",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#parameter-vs.-statistic",
    "title": "Hypothesis testing with randomization",
    "section": "Parameter vs. statistic",
    "text": "Parameter vs. statistic\nA parameter for a hypothesis test is the “true” value of interest. We typically estimate the parameter using a sample statistic as a point estimate.\n\\(p~\\): true rate of complication\n\\(\\hat{p}~\\): rate of complication in the sample = \\(\\frac{3}{62}\\) = 0.048"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#correlation-vs.-causation",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#correlation-vs.-causation",
    "title": "Hypothesis testing with randomization",
    "section": "Correlation vs. causation",
    "text": "Correlation vs. causation\n\nIs it possible to assess the consultant’s claim using the data?\n\nNo. The claim is that there is a causal connection, but the data are observational. For example, maybe patients who can afford a medical consultant can afford better medical care, which can also lead to a lower complication rate.\nWhile it is not possible to assess the causal claim, it is still possible to test for an association using these data. For this question we ask, could the low complication rate of \\(\\hat{p}\\) = 0.048 be due to chance?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#two-claims",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#two-claims",
    "title": "Hypothesis testing with randomization",
    "section": "Two claims",
    "text": "Two claims\n\nNull hypothesis: “There is nothing going on”\n\nComplication rate for this consultant is no different than the US average of 10%\n\nAlternative hypothesis: “There is something going on”\n\nComplication rate for this consultant is different than the US average of 10%"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#hypothesis-testing-as-a-court-trial",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#hypothesis-testing-as-a-court-trial",
    "title": "Hypothesis testing with randomization",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\nHypotheses:\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\n\nPresent the evidence: Collect data\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#hypothesis-testing-framework",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#hypothesis-testing-framework",
    "title": "Hypothesis testing with randomization",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\), that represents the status quo\nSet an alternative hypothesis, \\(H_A\\), that represents the research question, i.e. what we’re testing for\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#setting-the-hypotheses",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#setting-the-hypotheses",
    "title": "Hypothesis testing with randomization",
    "section": "Setting the hypotheses",
    "text": "Setting the hypotheses\n\nWhich of the following is the correct set of hypotheses for evaluating whether the consultant’s complication rate is different than the US average of 10%?\n\n\n\\(H_0: p = 0.10\\); \\(H_A: p \\ne 0.10\\)\n\\(H_0: p = 0.10\\); \\(H_A: p &gt; 0.10\\)\n\\(H_0: p = 0.10\\); \\(H_A: p &lt; 0.10\\)\n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} \\ne 0.10\\)\n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} &gt; 0.10\\)\n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} &lt; 0.10\\)"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulating-the-null-distribution",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulating-the-null-distribution",
    "title": "Hypothesis testing with randomization",
    "section": "Simulating the null distribution",
    "text": "Simulating the null distribution\nSince \\(H_0: p = 0.10\\), we need to simulate a null distribution where the probability of success (complication) for each trial (patient) is 0.10.\n\n\nDescribe how you would simulate the null distribution for this study using a bag of say pocker chips. How many chips? What colors? What do the colors indicate? How many draws? With replacement or without replacement?\n\n\nWe can take a bag of a 100 chips, say 10 of them are red (corresponding to complications) and 90 white (corresponding to no complications). Then, if I draw a chip from it, there is a 10% chance that it is red (aka complication). Thus, this “bag” now corresponds to our world where the true complication rate is 10% (where null hypothesis is true). Every time I draw a chip, I record its color and put it back (if I do not do so, the second chip I draw has either 9/99 or 10/99 chance of being red instead of 10/100 depending on what color the first chip was). This is what we call sampling with replacement.\n\nNow, I will draw 62 chips with replacement and calculate the proportion of red chips out of these 62 chips. This reconstructs consultant’s sample under the assumption that her true complication rate is 10%.\nWe repeat this draw of 62 chips many times and record the proportion of red chips every time."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#what-do-we-expect",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#what-do-we-expect",
    "title": "Hypothesis testing with randomization",
    "section": "What do we expect?",
    "text": "What do we expect?\n\nWhen sampling from the null distribution, what is the expected proportion of success (complications)?\n\n\nWe expect to see around 6.2 (10% of 62) red chips. Of course, it does not make sense to have 0.2 of a chip, but if I were to repeat this many many times, the average number of red chips I observe each time would be close to 6.2.\nIf we were to plot a histogram of the resulting proportions, we expect it to be centered around 0.1, as the probability of drawing a which chip out of a bag is 0.1."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-1",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation #1",
    "text": "Simulation #1\n\n\nsim1\n   complication no complication \n              7              55 \n\n\n[1] 0.1129032"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-2",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-2",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation #2",
    "text": "Simulation #2\n\n\nsim2\n   complication no complication \n             10              52 \n\n\n[1] 0.1612903"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-3",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-3",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation #3",
    "text": "Simulation #3\n\n\nsim3\n   complication no complication \n              5              57 \n\n\n[1] 0.08064516"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#this-is-getting-boring",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#this-is-getting-boring",
    "title": "Hypothesis testing with randomization",
    "section": "This is getting boring…",
    "text": "This is getting boring…\nWe need a way to automate this process!\nThe first dataset we’ll use is organ_donors:\n\norgan_donor &lt;- read_csv(\"organ-donor.csv\")\n\nRows: 62 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): outcome\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe hypotheses we are testing are:\n\\(H_0: p = 0.10\\)\n\\(H_A: p \\ne 0.10\\)\nwhere \\(p\\) is the true complication rate for this consultant."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-1",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 1",
    "text": "Exercise 1\nConstruct the null distribution with 100 resamples. Name it null_dist_donor. How many rows does null_dist_donor have? How many columns? What does each row and each column represent?\n\nset.seed(10)\n\nnull_dist_donor &lt;- organ_donor |&gt;\n  specify(response = outcome, success = \"complication\") |&gt;\n  hypothesise(null = \"point\", p = 0.1) |&gt;\n  generate(reps = 100, type = \"draw\") |&gt;\n  calculate(stat = \"prop\")\n\nnull_dist_donor\n\nResponse: outcome (factor)\nNull Hypothesis: point\n# A tibble: 100 × 2\n   replicate   stat\n       &lt;int&gt;  &lt;dbl&gt;\n 1         1 0.0323\n 2         2 0.0645\n 3         3 0.0968\n 4         4 0.0161\n 5         5 0.161 \n 6         6 0.0968\n 7         7 0.0645\n 8         8 0.129 \n 9         9 0.161 \n10        10 0.0968\n# ℹ 90 more rows\n\n\n\nnull_dist_donor has 100 rows and 2 columns. Each row is a replicate, and replicate column indicates the replicate number and stat is the simulated proportion, \\(\\hat p\\) ."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-2",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-2",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhere do you expect the center of the null distribution to be? Visualize it to confirm.\n\n# option 1\n\nggplot(null_dist_donor, aes(x = stat)) +\n  geom_histogram(bins = 15, color = \"white\")\n\n\n\n\n\n\n\n# option 2\n\nvisualize(null_dist_donor)"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-2-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-2-1",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 2",
    "text": "Exercise 2\nCalculate the observed complication rate of this consultant. Name it obs_stat_donor.\n\nobs_stat_donor &lt;- organ_donor |&gt;\n  specify(response = outcome, success = \"complication\") |&gt;\n  calculate(stat = \"prop\")\n\nobs_stat_donor\n\nResponse: outcome (factor)\n# A tibble: 1 × 1\n    stat\n   &lt;dbl&gt;\n1 0.0484"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-3",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-3",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 3",
    "text": "Exercise 3\nOverlay the observed statistic on the null distribution and comment on whether an observed outcome as extreme as the observed statistic, or lower, is a likely or unlikely outcome, if in fact the null hypothesis is true.\n\n# option 1\n\nggplot(null_dist_donor, aes(x = stat)) +\n  geom_histogram(bins = 15, color = \"white\") + \n  geom_vline(xintercept = obs_stat_donor |&gt; pull(stat), color = \"red\" )\n\n\n\n\n\n\n\n# option 2\n\nvisualize(null_dist_donor) +\n  shade_p_value(obs_stat = obs_stat_donor, direction = \"two-sided\")"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-4",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-4",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate the p-value and comment on whether it provides convincing evidence that this consultant incurs a lower complication rate than 10% (overall US complication rate).\n\nSince the p-value is greater than the discernability level, we fail to reject the null hypothesis. These data do not provide convincing evidence that this consultant incurs a lower complication rate than 10% (overall US complication rate).\n\n\n# option 1\n\nnull_dist_donor |&gt;\n  filter(stat &lt;= pull(obs_stat_donor, stat)) |&gt;\n  nrow()*2/100\n\n[1] 0.26\n\n# option 2\n\nnull_dist_donor |&gt;\n  get_p_value(obs_stat = obs_stat_donor, direction = \"two-sided\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1    0.26"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-5",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-5",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s get real! Redo the test with 15,000 simulations. Note: This can take some time to run.\n\nnull_dist_donor &lt;- organ_donor |&gt;\n  specify(response = outcome, success = \"complication\") |&gt;\n  hypothesise(null = \"point\", p = 0.1) |&gt;\n  generate(reps = 15000, type = \"draw\") |&gt;\n  calculate(stat = \"prop\")\n\nnull_dist_donor |&gt;\n  visualise() + \n  shade_p_value(obs_stat = obs_stat_donor, direction = \"two-sided\")\n\n\n\n\n\n\n\nnull_dist_donor |&gt;\n  get_p_value(obs_stat = obs_stat_donor, direction = \"two-sided\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1   0.250"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#is-yawning-contagious",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#is-yawning-contagious",
    "title": "Hypothesis testing with randomization",
    "section": "Is yawning contagious?",
    "text": "Is yawning contagious?\n\nDo you think yawning is contagious?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#is-yawning-contagious-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#is-yawning-contagious-1",
    "title": "Hypothesis testing with randomization",
    "section": "Is yawning contagious?",
    "text": "Is yawning contagious?\nAn experiment conducted by the MythBusters tested if a person can be subconsciously influenced into yawning if another person near them yawns.\nIf you’re interested, you can watch the full episode at https://www.dailymotion.com/video/x7ydkt2."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#study-description",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#study-description",
    "title": "Hypothesis testing with randomization",
    "section": "Study description",
    "text": "Study description\nIn this study 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a control group where they didn’t see someone yawn (control).\nThe data are in the openintro package: yawn\n\nyawn |&gt;\n  count(group, result)\n\n# A tibble: 4 × 3\n  group result       n\n  &lt;fct&gt; &lt;fct&gt;    &lt;int&gt;\n1 ctrl  not yawn    12\n2 ctrl  yawn         4\n3 trmt  not yawn    24\n4 trmt  yawn        10"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#proportion-of-yawners",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#proportion-of-yawners",
    "title": "Hypothesis testing with randomization",
    "section": "Proportion of yawners",
    "text": "Proportion of yawners\n\nyawn |&gt;\n  count(group, result) |&gt;\n  group_by(group) |&gt;\n  mutate(p_hat = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group result       n p_hat\n  &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 ctrl  not yawn    12 0.75 \n2 ctrl  yawn         4 0.25 \n3 trmt  not yawn    24 0.706\n4 trmt  yawn        10 0.294\n\n\n\nProportion of yawners in the treatment group: \\(\\frac{10}{34} = 0.2941\\)\nProportion of yawners in the control group: \\(\\frac{4}{16} = 0.25\\)\nDifference: \\(0.2941 - 0.25 = 0.0441\\)\nOur results match the ones calculated on the MythBusters episode."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#independence",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#independence",
    "title": "Hypothesis testing with randomization",
    "section": "Independence?",
    "text": "Independence?\n\nBased on the proportions we calculated, do you think yawning is really contagious, i.e. are seeing someone yawn and yawning dependent?\n\n\n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group result       n p_hat\n  &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 ctrl  not yawn    12 0.75 \n2 ctrl  yawn         4 0.25 \n3 trmt  not yawn    24 0.706\n4 trmt  yawn        10 0.294"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#dependence-or-another-possible-explanation",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#dependence-or-another-possible-explanation",
    "title": "Hypothesis testing with randomization",
    "section": "Dependence, or another possible explanation?",
    "text": "Dependence, or another possible explanation?\n\n\nThe observed differences might suggest that yawning is contagious, i.e. seeing someone yawn and yawning are dependent.\nBut the differences are small enough that we might wonder if they might simple be due to chance.\nPerhaps if we were to repeat the experiment, we would see slightly different results.\nSo we will do just that - well, somewhat - and see what happens.\nInstead of actually conducting the experiment many times, we will simulate our results."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#two-competing-claims",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#two-competing-claims",
    "title": "Hypothesis testing with randomization",
    "section": "Two competing claims",
    "text": "Two competing claims\n\n\nNull hypothesis:\n“There is nothing going on.” Yawning and seeing someone yawn are independent, yawning is not contagious, observed difference in proportions is simply due to chance.\n\nAlternative hypothesis:\n“There is something going on.” Yawning and seeing someone yawn are dependent, yawning is contagious, observed difference in proportions is not due to chance."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-by-hand---setup",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-by-hand---setup",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation by hand - setup",
    "text": "Simulation by hand - setup\n\nA regular deck of cards is comprised of 52 cards: 4 aces, 4 of numbers 2-10, 4 jacks, 4 queens, and 4 kings.\nTake out two aces from the deck of cards and set them aside.\nThe remaining 50 playing cards to represent each participant in the study:\n\n14 face cards (including the 2 aces) represent the people who yawn.\n36 non-face cards represent the people who don’t yawn."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-by-hand---running",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-by-hand---running",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation by hand - running",
    "text": "Simulation by hand - running\n\nShuffle the 50 cards at least 7 times1 to ensure that the cards counted out are from a random process.\nCount out the top 16 cards and set them aside. These cards represent the people in the control group.\nOut of the remaining 34 cards (treatment group) count the number of face cards (the number of people who yawned in the treatment group).\nCalculate the difference in proportions of yawners (treatment - control), and plot it on the board.\nMark the difference you find on the dot plot on the board."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-by-computation",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#simulation-by-computation",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation by computation",
    "text": "Simulation by computation"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-6",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#exercise-6",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 6",
    "text": "Exercise 6\nUsing the yawn dataset in the openintro package, conduct a hypothesis test for evaluating whether yawning is contagious. First, set the hypotheses. Then, conduct a randomization test using 1000 simulations. Visualize and calculate the p-value and use it to make a conclusion about the statistical discernability of the difference in proportions of yawners in the two groups. Then, comment on whether you “buy” this conclusion.\n\nNull hypothesis: Yawning is not contagious (there is no relationship between seeing someone yawn and yawning). \\(H_0: p_{trt}= p_{ctr}\\) where \\(p_{trt}\\) is the proportion of those who yawn after seeing someone yawn and \\(p_{ctr}\\) it the proportion of those who yawn in the control group.\nAlternative hypothesis: Yawning is contagious (there is a relationship). \\(H_A: p_{trt} &gt; p_{ctr}\\).\n\n\nnull_dist_yawner &lt;- yawn |&gt;\n  specify(response = result, explanatory = group, success = \"yawn\") |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  calculate(stat = \"diff in props\", order = c(\"trmt\", \"ctrl\"))\n\nobs_stat_yawner &lt;- yawn |&gt;\n  specify(response = result, explanatory = group, success = \"yawn\") |&gt;\n  calculate(stat = \"diff in props\", order = c(\"trmt\", \"ctrl\") )\n\nnull_dist_yawner |&gt;\n  visualise() +\n  shade_p_value(obs_stat = obs_stat_yawner, direction = \"greater\")\n\n\n\n\n\n\n\n\n\nnull_dist_yawner |&gt;\n  filter(stat &gt;= obs_stat_yawner |&gt; pull(stat)) |&gt;\n  nrow()/1000\n\n[1] 0.522\n\n\n\nnull_dist_yawner |&gt;\n  get_p_value(obs_stat = obs_stat_yawner, direction = \"greater\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1   0.522\n\n\n\nSince the p-value is 0.509 and is greater than discernability level of 0.05, we fail to reject the null. There not enough convincing evidence to show that yawning is contagious.\n\nThings to report:\n\np-value\ncompare it to discernability level\nconclude what that mean for null hypothesis\nenough/not enough evidence to conclude …. (context of the problem)"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#types-of-alternative-hypotheses",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#types-of-alternative-hypotheses",
    "title": "Hypothesis testing with randomization",
    "section": "Types of alternative hypotheses",
    "text": "Types of alternative hypotheses\n\nOne-sided (one-tailed) alternatives: The parameter is hypothesized to be less than or greater than the null value, &lt; or &gt;\nTwo-sided (two-tailed) alternatives: The parameter is hypothesized to be not equal to the null value, \\(\\ne\\)\n\nCalculated as two times the tail area beyond the observed sample statistic\nMore objective, and hence more widely preferred\n\n\n\nAverage systolic blood pressure of people with Stage 1 Hypertension is 150 mm Hg. Suppose we want to use a hypothesis test to evaluate whether a new blood pressure medication has an effect on the average blood pressure of heart patients. What are the hypotheses?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#discernability-level",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#discernability-level",
    "title": "Hypothesis testing with randomization",
    "section": "Discernability level",
    "text": "Discernability level\nWe often use 5% as the cutoff for whether the p-value is low enough that the data are unlikely to have come from the null model. This cutoff value is called the discernability level, \\(\\alpha\\).\n\nIf p-value &lt; \\(\\alpha\\), reject \\(H_0\\) in favor of \\(H_A\\): The data provide convincing evidence for the alternative hypothesis.\nIf p-value &gt; \\(\\alpha\\), fail to reject \\(H_0\\) in favor of \\(H_A\\): The data do not provide convincing evidence for the alternative hypothesis."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#statistically-discernable",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#statistically-discernable",
    "title": "Hypothesis testing with randomization",
    "section": "Statistically discernable",
    "text": "Statistically discernable\n\nIf you’ve taken a statistics course before, or read papers that use hypothesis testing for making a conclusion, you might have encountered the term “statistically significant” or “significance level”.\nWe will use the term “statistically discernable” or discernability level”, because “significant” has a different meaning in everyday language and this often causes misconceptions of what “statistically significant” means. It doesn’t necessarily mean a notable or important event has happened, it just means the data are unlikely to have come from the null model."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#setting-a-seed",
    "href": "lectures/10/10-hypothesis-testing-randomization-filled-in.html#setting-a-seed",
    "title": "Hypothesis testing with randomization",
    "section": "Setting a seed",
    "text": "Setting a seed\n\nGoal: Pin down the random generation so that the same random generation happens each time a document is rendered (by you or by someone else wanting to replicate your results)\nWhen: Set a seed each time right before generate()ing new resamples. Setting a seed once in a document would also work for re-rendering the document, but considering we often run the code chunk interactively, it’s best to set the seed again in each code chunk that does random generation."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html",
    "href": "lectures/06/06-regression-one-predictor.html",
    "title": "Regression with one predictor",
    "section": "",
    "text": "Difference between marginal and conditional distributions."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#data-and-packages",
    "href": "lectures/06/06-regression-one-predictor.html#data-and-packages",
    "title": "Regression with one predictor",
    "section": "Data and packages",
    "text": "Data and packages\nWe’ll work with data on Apple and Microsoft stock prices and use the tidyverse and tidymodels packages. The data for lecture was originally gathered using the tidyquant R package. It features Apple and Microsoft stock prices from January 1st 2020 to December 31st 2021.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nstocks &lt;- read_csv(\"stocks.csv\")"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#simple-regression-model-and-notation",
    "href": "lectures/06/06-regression-one-predictor.html#simple-regression-model-and-notation",
    "title": "Regression with one predictor",
    "section": "Simple regression model and notation",
    "text": "Simple regression model and notation\n\\[\ny = \\beta_0 + \\beta_1 x + \\epsilon\n\\]\n\n\n\\(y\\): the outcome variable. Also called the “response” or “dependent variable”. In prediction problems, this is what we are interested in predicting.\n\\(x\\): the predictor. Also commonly referred to as “regressor”, “independent variable”, “covariate”, “feature”, “the data”.\n\\(\\beta_0\\), \\(\\beta_1\\) are called “constants” or coefficients. They are fixed numbers. These are population parameters. \\(\\beta_0\\) has another special name, “the intercept”.\n\\(\\epsilon\\): the error. This quantity represents observational error, i.e. the difference between our observation and the true population-level expected value: \\(\\beta_0 + \\beta_1 x\\).\n\n\n. . .\nEffectively this model says our data \\(y\\) is linearly related to \\(x\\) but is not perfectly observed due to some error."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#stock-prices-of-microsoft-and-apple",
    "href": "lectures/06/06-regression-one-predictor.html#stock-prices-of-microsoft-and-apple",
    "title": "Regression with one predictor",
    "section": "Stock prices of Microsoft and Apple",
    "text": "Stock prices of Microsoft and Apple\nLet’s examine January 2020 open prices of Microsoft and Apple stocks to illustrate some ideas.\n\nstocks_jan2020 &lt;- stocks |&gt;\n  filter(month(date) == 1 & year(date) == 2020)\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#fitting-some-model",
    "href": "lectures/06/06-regression-one-predictor.html#fitting-some-model",
    "title": "Regression with one predictor",
    "section": "Fitting “some” model",
    "text": "Fitting “some” model\nBefore we get to fitting the best model, let’s fit “some” model, say with slope = -5 and intercept = 0.5.\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  geom_abline(slope = 0.5, intercept = -5) +\n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#fitting-some-model-1",
    "href": "lectures/06/06-regression-one-predictor.html#fitting-some-model-1",
    "title": "Regression with one predictor",
    "section": "Fitting “some” model",
    "text": "Fitting “some” model\n\\[\n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x \\quad \\quad\\quad\n\\hat{y} = -5 + 0.5 ~ x\n\\]\n\n\\(\\hat{y}\\) is the expected outcome\n\\(\\hat{\\beta}\\) is the estimated or fitted coefficient\nThere is no error term here because we do not predict error"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#populations-vs.-samples",
    "href": "lectures/06/06-regression-one-predictor.html#populations-vs.-samples",
    "title": "Regression with one predictor",
    "section": "Populations vs. samples",
    "text": "Populations vs. samples\n\n\nPopulation:\n\\[\ny = \\beta_0 + \\beta_1 ~ x\n\\]\n\nSamples: \\[\n\\hat{y} = \\hat{\\beta_0} +  \\hat{\\beta_1} ~ x\n\\]\n\n\n\n\nThe central idea is that if we measure every \\(x\\) and every \\(y\\) in existence, (“the entire population”) there is some true “best” \\(\\beta_0\\) and \\(\\beta_1\\) that describe the relationship between \\(x\\) and \\(y\\)\nSince we only have a sample of the data, we estimate \\(\\beta_0\\) and \\(\\beta_1\\)\nWe call our estimates \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) “beta hat”. We never have all the data, thus we never can really know what the true \\(\\beta\\)s are"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#residuals",
    "href": "lectures/06/06-regression-one-predictor.html#residuals",
    "title": "Regression with one predictor",
    "section": "Residuals",
    "text": "Residuals\n\nFor any linear equation we write down, there will be some difference between the predicted outcome of our linear model (\\(\\hat{y}\\)) and what we observe (\\(y\\))… (But of course! Otherwise everything would fall on a perfect straight line!)\n\nThis difference between what we observe and what we predict \\(y - \\hat{y}\\) is known as a residual, \\(e\\).\nMore concisely,\n\\[\ne = y - \\hat{y}\n\\]"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#a-residual-visualized",
    "href": "lectures/06/06-regression-one-predictor.html#a-residual-visualized",
    "title": "Regression with one predictor",
    "section": "A residual, visualized",
    "text": "A residual, visualized\nResiduals are dependent on the line we draw. Visually, here is a model of the data, \\(y = -5 + 0.5 ~ x\\) and one of the residuals is outlined in red."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#all-residuals-visualized",
    "href": "lectures/06/06-regression-one-predictor.html#all-residuals-visualized",
    "title": "Regression with one predictor",
    "section": "All residuals, visualized",
    "text": "All residuals, visualized\nThere is, in fact, a residual associated with every single point in the plot."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#minimize-residuals",
    "href": "lectures/06/06-regression-one-predictor.html#minimize-residuals",
    "title": "Regression with one predictor",
    "section": "Minimize residuals",
    "text": "Minimize residuals\nWe often wish to find a line that fits the data “really well”, but what does this mean? Well, we want small residuals! So we pick an objective function. That is, a function we wish to minimize or maximize.\nToday we’ll explore the question “How do stock prices of Apple and Microsoft relate to each other?”"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#exercise-1",
    "href": "lectures/06/06-regression-one-predictor.html#exercise-1",
    "title": "Regression with one predictor",
    "section": "Exercise 1",
    "text": "Exercise 1\nAt first, you might be tempted to minimize \\(\\sum_i e_i\\), the sum of all residuals, but this is problematic. Why? Can you come up with a better solution (other than the one listed below)?\nAdd response here."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#minimize-the-sum-of-squared-residuals",
    "href": "lectures/06/06-regression-one-predictor.html#minimize-the-sum-of-squared-residuals",
    "title": "Regression with one predictor",
    "section": "Minimize the sum of squared residuals",
    "text": "Minimize the sum of squared residuals\nIn practice, we minimize the sum of squared residuals:\n\\[\n\\sum_i e_i^2\n\\]\nNote, this is the same as\n\\[\n\\sum_i (y_i - \\hat{y}_i)^2\n\\]"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#exercise-2",
    "href": "lectures/06/06-regression-one-predictor.html#exercise-2",
    "title": "Regression with one predictor",
    "section": "Exercise 2",
    "text": "Exercise 2\nCheck out an interactive visualization of “least squares regression” here. Click on I and drag the points around to get started. Describe what you see.\nAdd response here"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#exercise-4",
    "href": "lectures/06/06-regression-one-predictor.html#exercise-4",
    "title": "Regression with one predictor",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn the slides we fit a model with slope 0.5 and intercept -5. The code for layering the line that represents the model over your data is given below. Add geom_smooth() as described above with color = \"steelblue\" to see how close your line is.\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  geom_abline(slope = 0.5, intercept = -5) +\n  # add code here\n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#exercise-5",
    "href": "lectures/06/06-regression-one-predictor.html#exercise-5",
    "title": "Regression with one predictor",
    "section": "Exercise 5",
    "text": "Exercise 5\nFind the least squares line \\(y = \\hat{\\beta_0} + \\hat{\\beta_1} x\\) for January 2020, where \\(x\\) is Microsoft’s opening price and \\(y\\) is Apple’s opening price. Display a tidy summary of your model.\n\n# code here"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#exercise-6",
    "href": "lectures/06/06-regression-one-predictor.html#exercise-6",
    "title": "Regression with one predictor",
    "section": "Exercise 6",
    "text": "Exercise 6\nRe-write the fitted equation replacing \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) with the estimates from the model you fit in the previous exercise.\n\\[\n\\text{[add equation here]}\n\\]"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#exercise-7",
    "href": "lectures/06/06-regression-one-predictor.html#exercise-7",
    "title": "Regression with one predictor",
    "section": "Exercise 7",
    "text": "Exercise 7\nInterpret \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) in context of the data.\nAdd response here"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor.html#bonus-exercise",
    "href": "lectures/06/06-regression-one-predictor.html#bonus-exercise",
    "title": "Regression with one predictor",
    "section": "Bonus exercise",
    "text": "Bonus exercise\nSay Microsoft opens at 166 dollars. What do I predict the opening price of AAPL to be?\n\n# add code here"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html",
    "href": "lectures/03/03-study_design_filled_in.html",
    "title": "Study design",
    "section": "",
    "text": "Thanks to those who read the syllabus and followed the prompts\nLab 1 is due Sunday (May 19) at 11:59 pm on Gradescope\nLate policy review\n\n\nAny questions about the first assignment due?"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#announcements",
    "href": "lectures/03/03-study_design_filled_in.html#announcements",
    "title": "Study design",
    "section": "",
    "text": "Thanks to those who read the syllabus and followed the prompts\nLab 1 is due Sunday (May 19) at 11:59 pm on Gradescope\nLate policy review\n\n\nAny questions about the first assignment due?"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#reading-check-in",
    "href": "lectures/03/03-study_design_filled_in.html#reading-check-in",
    "title": "Study design",
    "section": "Reading check in",
    "text": "Reading check in\n\nAny questions on the readings or tutorials?"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#sat-scores-and-teacher-salaries",
    "href": "lectures/03/03-study_design_filled_in.html#sat-scores-and-teacher-salaries",
    "title": "Study design",
    "section": "SAT scores and teacher salaries",
    "text": "SAT scores and teacher salaries\n\nWhat is going on in the following plot?\n\n\n\n\n\n\n\n\nModern Data Science with R. Baumer, Kaplan, Horton. (2023)"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#sat-scores-and-teacher-salaries-1",
    "href": "lectures/03/03-study_design_filled_in.html#sat-scores-and-teacher-salaries-1",
    "title": "Study design",
    "section": "SAT scores and teacher salaries",
    "text": "SAT scores and teacher salaries\n\nWhat about this plot?"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#covid-vaccine-and-deaths-from-delta-variant",
    "href": "lectures/03/03-study_design_filled_in.html#covid-vaccine-and-deaths-from-delta-variant",
    "title": "Study design",
    "section": "COVID vaccine and deaths from Delta variant",
    "text": "COVID vaccine and deaths from Delta variant\nThe main question we’ll explore today is “How do deaths from COVID cases compare between vaccinated and unvaccinated?”\nWhat do you think?"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#exercise-1",
    "href": "lectures/03/03-study_design_filled_in.html#exercise-1",
    "title": "Study design",
    "section": "Exercise 1",
    "text": "Exercise 1\nHow many rows and columns are in this dataset? Answer in a full sentence using inline code. What does each row represent and what does each column represent? For each variable, identify its type.\n\nThere are 268166 rows and 3 columns in the dataset. Each row represents a person with COVID, and the columns represent whether the person was vaccinated or not, their age, and whether they died or survived."
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#exercise-2",
    "href": "lectures/03/03-study_design_filled_in.html#exercise-2",
    "title": "Study design",
    "section": "Exercise 2",
    "text": "Exercise 2\nDo these data come from an observational study or experiment? Why?\n\nObservational study, people in the study chose to get vaccinated or not, they weren’t randomized into groups."
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#exercise-3",
    "href": "lectures/03/03-study_design_filled_in.html#exercise-3",
    "title": "Study design",
    "section": "Exercise 3",
    "text": "Exercise 3\nCreate a visualization of health outcome by vaccine status that allows you to compare the proportion of deaths across those who are and are not vaccinated. What can you say about death rates in these two groups based on this visualization?\n\nWhile this is very difficult to see, the proportion of patients who died is slightly higher for the vaccinated group compared to the unvaccinated group.\n\n\nggplot(delta, aes(x = vaccine, fill = outcome)) + \n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#exercise-4",
    "href": "lectures/03/03-study_design_filled_in.html#exercise-4",
    "title": "Study design",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate the proportion of deaths in among those who are vaccinated. Then, calculate the proportion among those who are not vaccinated.\n\nProportion of deaths among the vaccinated is 0.00407 and the proportion of deaths among the unvaccinated is 0.00166.\n\n\ndelta |&gt;\n  count(vaccine, outcome) |&gt;\n  group_by(vaccine) |&gt;\n  mutate(prop = n/sum(n))\n\n# A tibble: 4 × 4\n# Groups:   vaccine [2]\n  vaccine      outcome       n    prop\n  &lt;chr&gt;        &lt;chr&gt;     &lt;int&gt;   &lt;dbl&gt;\n1 Unvaccinated died        250 0.00166\n2 Unvaccinated survived 150802 0.998  \n3 Vaccinated   died        477 0.00407\n4 Vaccinated   survived 116637 0.996"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#exercise-5",
    "href": "lectures/03/03-study_design_filled_in.html#exercise-5",
    "title": "Study design",
    "section": "Exercise 5",
    "text": "Exercise 5\nCreate the visualization and calculate proportions from the two previous exercises, this time controlling for age. How do the proportions compare?\n\nAmong both the younger patients (&lt;50) and the older patients (50+), proportions of deaths is smaller for the vaccinated.\n\n\nggplot(delta, aes(x = vaccine, fill = outcome)) + \n  geom_bar(position = \"fill\") +\n  facet_wrap(~age)\n\n\n\n\n\n\n\n\n\ndelta |&gt;\n  count(age, vaccine, outcome) |&gt;\n  group_by(age, vaccine) |&gt;\n  mutate(prop = n/sum(n))\n\n# A tibble: 8 × 5\n# Groups:   age, vaccine [4]\n  age   vaccine      outcome       n     prop\n  &lt;chr&gt; &lt;chr&gt;        &lt;chr&gt;     &lt;int&gt;    &lt;dbl&gt;\n1 50+   Unvaccinated died        205 0.0596  \n2 50+   Unvaccinated survived   3235 0.940   \n3 50+   Vaccinated   died        459 0.0168  \n4 50+   Vaccinated   survived  26848 0.983   \n5 &lt;50   Unvaccinated died         45 0.000305\n6 &lt;50   Unvaccinated survived 147567 1.00    \n7 &lt;50   Vaccinated   died         18 0.000200\n8 &lt;50   Vaccinated   survived  89789 1.00"
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#exercise-6",
    "href": "lectures/03/03-study_design_filled_in.html#exercise-6",
    "title": "Study design",
    "section": "Exercise 6",
    "text": "Exercise 6\nBased on your findings so far, fill in the blanks with more, less, or equally: Is there anything surprising about these statements? Speculate on what, if anything, the discrepancy might be due to.\n\nIn 2021, among those in the UK who were COVID Delta cases, the vaccinated were more likely to die than the unvaccinated.\nFor those under 50, those who were unvaccinated were more likely to die than those who were vaccinated.\nFor those 50 and up, those who were unvaccinated were more likely to die than those who were vaccinated.\n\nThe relationshio between outcome and vaccine status changes depending on the age of the person."
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#exercise-7",
    "href": "lectures/03/03-study_design_filled_in.html#exercise-7",
    "title": "Study design",
    "section": "Exercise 7",
    "text": "Exercise 7\nLet’s rephrase the previous question which asked you to speculate on why deaths among vaccinated cases overall is higher while deaths among unvaccinated cases are higher when we split the data into two groups (below 50 and 50 and up). What might be the confounding variable in the relationship between vaccination and deaths?\n\nAge."
  },
  {
    "objectID": "lectures/03/03-study_design_filled_in.html#exercise-8",
    "href": "lectures/03/03-study_design_filled_in.html#exercise-8",
    "title": "Study design",
    "section": "Exercise 8",
    "text": "Exercise 8\nVisualize and describe the distribution of seniors (50 and up) based on (a.k.a. conditional on) vaccination status. Hint: Your description will benefit from calculating proportions of seniors in each of the vaccination groups and working those values into your narrative.\n\nThe proportion of seniors (50+) is higher for the vaccinated group (0.233) compared to the unvaccinated group (0.0228).\n\n\nggplot(delta, aes(x = vaccine, fill = age)) + \n  geom_bar(position = \"fill\")\n\n\n\n\n\n\n\n\n\ndelta |&gt;\n  count(vaccine, age) |&gt;\n  group_by(vaccine) |&gt;\n  mutate(prop = n/sum(n))\n\n# A tibble: 4 × 4\n# Groups:   vaccine [2]\n  vaccine      age        n   prop\n  &lt;chr&gt;        &lt;chr&gt;  &lt;int&gt;  &lt;dbl&gt;\n1 Unvaccinated 50+     3440 0.0228\n2 Unvaccinated &lt;50   147612 0.977 \n3 Vaccinated   50+    27307 0.233 \n4 Vaccinated   &lt;50    89807 0.767"
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html",
    "href": "lectures/14/14-more-on-clt.html",
    "title": "More on CLT",
    "section": "",
    "text": "Last day to drop with a W is today!\nLab 6 and Intro+EDA due tomorrow."
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#announcements",
    "href": "lectures/14/14-more-on-clt.html#announcements",
    "title": "More on CLT",
    "section": "",
    "text": "Last day to drop with a W is today!\nLab 6 and Intro+EDA due tomorrow."
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#normal-population-sample-size-10",
    "href": "lectures/14/14-more-on-clt.html#normal-population-sample-size-10",
    "title": "More on CLT",
    "section": "Normal population, sample size 10",
    "text": "Normal population, sample size 10\nLet’s start with a normal distribution. Say we are interested in the number of times first year students eat at the dining hall per month. Let’s suppose that we know that the true population distribution of dining hall meals is \\(N(\\mu= 50,\\sigma = 15)\\).\nNow imagine that each of you conduct your own study in which you randomly select 10 first years and ask them how many times they ate at the dining hall last month. You then calculate the sample mean of the 10 students that you selected.\n\n\n\n\n\n\n\n\n\nFunction rnorm() draws a random sample from a normal distribution.\n\nSample 1\n\n\nsim1\n39.8758423406625 45.1094526422692 46.6511095305911 48.3089852786868 \n               1                1                1                1 \n53.2153918856514  54.661538259704 58.2869278312871 59.2818478343895 \n               1                1                1                1 \n63.7554243426907 67.6094943134405 \n               1                1 \n\n\n[1] 53.6756\n\n\n\n\n\n\n\n\n\n\n\nSample 2\n\n\nsim2\n19.2453827654055  27.997704587548 37.2536788949921 37.7349446618606 \n               1                1                1                1 \n38.0773334687742 46.4497493209566 47.0999305250375 50.8769824677425 \n               1                1                1                1 \n57.8967214831046 71.4163331702455 \n               1                1 \n\n\n[1] 43.40488\n\n\n\n\n\n\n\n\n\n\n\nSample 3\n\n\nsim3\n28.0411736019347  28.844147284922 45.9802918072757 47.5436650108787 \n               1                1                1                1 \n48.2101983845863 57.0060140902287 57.0085844264827 57.4720334665387 \n               1                1                1                1 \n60.6278315623456 61.1665373431298 \n               1                1 \n\n\n[1] 49.19005\n\n\n\n\n\n\n\n\n\n\n\nMore samples\nLet’s repeat this 500 times:"
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#normal-population-sample-size-50",
    "href": "lectures/14/14-more-on-clt.html#normal-population-sample-size-50",
    "title": "More on CLT",
    "section": "Normal population, sample size 50",
    "text": "Normal population, sample size 50\nNow let’s increase our sample size (\\(n\\)). Imagine that you each survey 50 students."
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#normal-population-sample-size-150",
    "href": "lectures/14/14-more-on-clt.html#normal-population-sample-size-150",
    "title": "More on CLT",
    "section": "Normal population, sample size 150",
    "text": "Normal population, sample size 150\nFinally, take a sample of size 150. Calculate the sample mean.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nAs the sample size increases, the standard deviation of the distribution of the sample mean decreases!\n\n\nNow let’s compare different population distributions."
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#skewed-population-distribution-sample-size-10",
    "href": "lectures/14/14-more-on-clt.html#skewed-population-distribution-sample-size-10",
    "title": "More on CLT",
    "section": "Skewed population distribution, sample size 10",
    "text": "Skewed population distribution, sample size 10\nWe collect a random sample of 10 and calculate the sample mean.\n\n\nsamp\n36.0403466760015 36.5318079640983 39.7644136898599 42.6083149724047 \n               1                1                1                1 \n45.7785338109389 52.4099971702863 53.9656837111663 55.9595445823423 \n               1                1                1                1 \n57.5148182340717 67.3147816105797 \n               1                1 \n\n\n[1] 48.78882\n\n\nLet’s repeat this 500 times:"
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#skewed-population-sample-size-50",
    "href": "lectures/14/14-more-on-clt.html#skewed-population-sample-size-50",
    "title": "More on CLT",
    "section": "Skewed population, sample size 50",
    "text": "Skewed population, sample size 50\nNow let’s increase our sample size (\\(n\\)). Imagine that you each survey 50 students."
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#skewed-population-sample-size-150",
    "href": "lectures/14/14-more-on-clt.html#skewed-population-sample-size-150",
    "title": "More on CLT",
    "section": "Skewed population, sample size 150",
    "text": "Skewed population, sample size 150\nFinally, take a sample of size 150. Calculate the sample mean."
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#bimodal-population-distribution-sample-size-10",
    "href": "lectures/14/14-more-on-clt.html#bimodal-population-distribution-sample-size-10",
    "title": "More on CLT",
    "section": "Bimodal population distribution, sample size 10",
    "text": "Bimodal population distribution, sample size 10\nWe collect a random sample of 10 and calculate the sample mean.\n\n\nsamp\n64.0308396618234 \n               1 \n\n\n[1] 64.03084\n\n\nLet’s repeat this 500 times:"
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#bimodal-population-sample-size-50",
    "href": "lectures/14/14-more-on-clt.html#bimodal-population-sample-size-50",
    "title": "More on CLT",
    "section": "Bimodal population, sample size 50",
    "text": "Bimodal population, sample size 50\nNow let’s increase our sample size (\\(n\\)). Imagine that you each survey 50 students."
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#bimodal-population-sample-size-150",
    "href": "lectures/14/14-more-on-clt.html#bimodal-population-sample-size-150",
    "title": "More on CLT",
    "section": "Bimodal population, sample size 150",
    "text": "Bimodal population, sample size 150\nFinally, take a sample of size 150. Calculate the sample mean."
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#what-could-go-wrong",
    "href": "lectures/14/14-more-on-clt.html#what-could-go-wrong",
    "title": "More on CLT",
    "section": "What could go wrong?",
    "text": "What could go wrong?\nSuppose we test the null hypothesis \\(H_0 : \\mu = \\mu_0\\). We could potentially make two types of errors:\n\n\n\nTruth\n\\(\\mu = \\mu_0\\)\n\\(\\mu \\neq \\mu_0\\)\n\n\n\n\nFail to reject \\(H_0\\)\nCorrect decision\nType II Error\n\n\nReject \\(H_0\\)\nType I Error\nCorrect decision\n\n\n\n\nType I Error: rejecting \\(H_0\\) when it is actually true (falsely rejection the null hypothesis)\nType II Error: not rejecting \\(H_0\\) when it is false (falsely failing to reject the null hypothesis)\n\nWhile we of course want to know if any one study is showing us something real or a Type I or Type II error, hypothesis testing does NOT give us the tools to determine this.\n\nDiscernibility level\nThe discernibility level provides the cutoff for the p-value which will lead to a decision of “reject the null hypothesis.” Choosing a discernibility level for a test is important in many contexts, and the traditional level is 0.05. - If making a Type I error is dangerous or especially costly, we should choose a small discernibility level (e.g., 0.01 or 0.001). - If a Type II error is relatively more dangerous or much more costly than a Type I error, then we should choose a higher discernibility level (e.g., 0.10).\nThe risk of committing Type I error is equal to \\(\\alpha\\) - pre-defined discernibility level.\n\n\nPower\nPower is the probability of rejecting the null hypothesis when it is false (i.e., of avoiding a Type II error). Power can be also thought of as the likelihood a planned study will detect a deviation from the null hypothesis if one really exists."
  },
  {
    "objectID": "lectures/14/14-more-on-clt.html#acknowledgements",
    "href": "lectures/14/14-more-on-clt.html#acknowledgements",
    "title": "More on CLT",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThese notes were adapted from notes by Andrea Lane and Yue Jiang."
  },
  {
    "objectID": "lectures/01/unvotes.html",
    "href": "lectures/01/unvotes.html",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\nlibrary(ggthemes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\")"
  },
  {
    "objectID": "lectures/01/unvotes.html#introduction",
    "href": "lectures/01/unvotes.html#introduction",
    "title": "UN Votes",
    "section": "",
    "text": "How do various countries vote in the United Nations General Assembly, how have their voting patterns evolved throughout time, and how similarly or differently do they view certain issues? Answering these questions (at a high level) is the focus of this analysis.\n\n\nWe will use the tidyverse, lubridate, and scales packages for data wrangling and visualization, and the DT package for interactive display of tabular output, and the unvotes package for the data.\n\nlibrary(tidyverse)\nlibrary(scales)\nlibrary(DT)\nlibrary(unvotes)\nlibrary(ggthemes)\n\n\n\n\nThe data we’re using originally come from the unvotes package. In the chunk below we modify the data by joining the various data frames provided in the package to help you get started with the analysis.\n\nunvotes &lt;- un_votes |&gt;\n  inner_join(un_roll_calls, by = \"rcid\") |&gt;\n  inner_join(un_roll_call_issues, by = \"rcid\", relationship = \"many-to-many\")"
  },
  {
    "objectID": "lectures/01/unvotes.html#un-voting-patterns",
    "href": "lectures/01/unvotes.html#un-voting-patterns",
    "title": "UN Votes",
    "section": "UN voting patterns",
    "text": "UN voting patterns\nLet’s create a data visualization that displays how the voting record of the UK & NI changed over time on a variety of issues, and compares it to two other countries: US and Turkey.\nWe can easily change which countries are being plotted by changing which countries the code above filters for. Note that the country name should be spelled and capitalized exactly the same way as it appears in the data. See the Appendix for a list of the countries in the data.\n\nunvotes |&gt;\n  filter(country %in% c(\"United Kingdom\", \"United States\", \"Turkey\")) |&gt;\n  mutate(year = year(date)) |&gt;\n  group_by(country, year, issue) |&gt;\n  summarize(percent_yes = mean(vote == \"yes\")) |&gt;\n  ggplot(mapping = aes(x = year, y = percent_yes, color = country)) +\n  geom_point(alpha = 0.4) +\n  geom_smooth(method = \"loess\", se = FALSE) +\n  facet_wrap(~issue) +\n  scale_y_continuous(labels = percent) +\n  scale_color_colorblind() +\n  labs(\n    title = \"Percentage of 'Yes' votes in the UN General Assembly\",\n    subtitle = \"1946 to 2019\",\n    y = \"% Yes\",\n    x = \"Year\",\n    color = \"Country\"\n  )"
  },
  {
    "objectID": "lectures/01/unvotes.html#references",
    "href": "lectures/01/unvotes.html#references",
    "title": "UN Votes",
    "section": "References",
    "text": "References\n\nRobinson D (2021). unvotes: United Nations General Assembly Voting Data. R package version 0.3.0, https://github.com/dgrtwo/unvotes.\nErik Voeten “Data and Analyses of Voting in the UN General Assembly” Routledge Handbook of International Organization, edited by Bob Reinalda (published May 27, 2013).\nMuch of the analysis has been modeled on the examples presented in the unvotes package vignette."
  },
  {
    "objectID": "lectures/01/unvotes.html#appendix",
    "href": "lectures/01/unvotes.html#appendix",
    "title": "UN Votes",
    "section": "Appendix",
    "text": "Appendix\nBelow is a list of countries in the dataset:"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html",
    "href": "lectures/07/07-regression-multiple-predictors.html",
    "title": "Regression with multiple predictors",
    "section": "",
    "text": "No lab or class on Monday, May 27th.\nProject proposal due Tuesday, May 28th.\nLab 3 due Wednesday, May 29th.\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(scatterplot3d)"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#announcements",
    "href": "lectures/07/07-regression-multiple-predictors.html#announcements",
    "title": "Regression with multiple predictors",
    "section": "",
    "text": "No lab or class on Monday, May 27th.\nProject proposal due Tuesday, May 28th.\nLab 3 due Wednesday, May 29th."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#load-packages-and-data",
    "href": "lectures/07/07-regression-multiple-predictors.html#load-packages-and-data",
    "title": "Regression with multiple predictors",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(scatterplot3d)"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#r2",
    "href": "lectures/07/07-regression-multiple-predictors.html#r2",
    "title": "Regression with multiple predictors",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\\(R^2\\), aka “the coefficient of determination” or “correlation squared” is a way to see how well a given model fits the data.\n\\[\nR^2 = r^2\n\\]"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#sum-of-squares-total-sst",
    "href": "lectures/07/07-regression-multiple-predictors.html#sum-of-squares-total-sst",
    "title": "Regression with multiple predictors",
    "section": "Sum of squares total, SST",
    "text": "Sum of squares total, SST\nThe sum of squares total is a measure of the total variability in the outcome variable:\n\\[\nSST = (y_1 - \\bar{y})^2 + (y_2 - \\bar{y})^2 + \\cdots + (y_n - \\bar{y})^2\n\\]"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#sum-of-squares-residuals-sse",
    "href": "lectures/07/07-regression-multiple-predictors.html#sum-of-squares-residuals-sse",
    "title": "Regression with multiple predictors",
    "section": "Sum of squares residuals, SSE",
    "text": "Sum of squares residuals, SSE\nThe sum of squares residuals (error) is a measure of the variability in the residuals, i.e., variability left unexplained in the outcome variable after the model is fit:\n\\[\nSSE = (y_1 - \\hat{y}_1)^2 + (y_2 - \\hat{y}_2)^2 + \\cdots + (y_n - \\hat{y}_n)^2\n\\]"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#r2-another-look",
    "href": "lectures/07/07-regression-multiple-predictors.html#r2-another-look",
    "title": "Regression with multiple predictors",
    "section": "\\(R^2\\), another look",
    "text": "\\(R^2\\), another look\n\\[\nR^2 = \\frac{SST - SSE}{SST} = 1 - \\frac{SSE}{SST}\n\\]\n. . .\n\nThis can be summarized as “\\(R^2\\) is 1 minus the sum of squared residuals divided by the sum of squared total”.\n\n. . .\n\nIn other words, \\(R^2\\) is the proportion of variability in the outcome that is explained by the model."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#r2-1",
    "href": "lectures/07/07-regression-multiple-predictors.html#r2-1",
    "title": "Regression with multiple predictors",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\n\nIf the sum of squared residuals is 0, then the model explains all variability and \\(R^2 = 1 - 0 = 1\\).\nIf the sum of squared residuals is the same as all the variability in the data, then model does not explain any variability and \\(R^2 = 1 - 1 = 0\\).\n\\(R^2\\) is a measure of the proportion of variability the model explains. An \\(R^2\\) of 0 is a poor fit and \\(R^2\\) of 1 is a perfect fit."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#finding-r2",
    "href": "lectures/07/07-regression-multiple-predictors.html#finding-r2",
    "title": "Regression with multiple predictors",
    "section": "Finding \\(R^2\\)",
    "text": "Finding \\(R^2\\)\nTo find \\(R^2\\) simply call the function glance() on your model_fit, e.g.\n\nmodel_fit &lt;- linear_reg() |&gt;\n  fit(outcome ~ predictor, data = data_set)\n  \nglance(model_fit)"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#two-predictors",
    "href": "lectures/07/07-regression-multiple-predictors.html#two-predictors",
    "title": "Regression with multiple predictors",
    "section": "Two predictors",
    "text": "Two predictors\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\n\\]\n\n\n\\(y\\): the outcome variable. Also called the “response” or “dependent variable”. In prediction problems, this is what we are interested in predicting.\n\\(x_i\\): the \\(i^{th}\\) predictor. Also commonly referred to as “regressor”, “independent variable”, “covariate”, “feature”, “the data”.\n\\(\\beta_i\\): “constants” or coefficients i.e. fixed numbers. These are population parameters. \\(\\beta_0\\) has another special name, “the intercept”.\n\\(\\epsilon\\): the error. This quantity represents observational error, i.e. the difference between our observation and the true population-level expected value: \\(\\beta_0 + \\beta_1 x\\).\nEffectively this model says our data \\(y\\) is linearly related to the \\(x_1\\) and \\(x_2\\) but is not perfectly observed due to unexplained errors."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#a-simple-example",
    "href": "lectures/07/07-regression-multiple-predictors.html#a-simple-example",
    "title": "Regression with multiple predictors",
    "section": "A simple example",
    "text": "A simple example\nLet’s examine the first quarter of 2020 high prices of Microsoft, IBM, and Apple stocks to illustrate some ideas.\n\n\n\n\n\n\n\n\n\n\nIf we have three measurements (variables) then each observation is a point in three-dimensional space. In this example, we can choose one of our measurements to be the outcome variable (e.g. Apple stock price) and use our other two measurements (MSFT and IBM price) as predictors.\nIn general, the total number of measurements, i.e. variables (columns) in our linear model represents the spatial dimension of our model."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#predictors-1-outcome-3-dimensions",
    "href": "lectures/07/07-regression-multiple-predictors.html#predictors-1-outcome-3-dimensions",
    "title": "Regression with multiple predictors",
    "section": "2 predictors + 1 outcome = 3 dimensions",
    "text": "2 predictors + 1 outcome = 3 dimensions\nThe fitted linear model no longer looks like a line, but instead looks like a plane. It shows our prediction of AAPL price (\\(y\\)) given both MSFT price (\\(x_1\\)) and IBM price (\\(x_2\\))."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#fitting-a-multiple-regression-model-in-r",
    "href": "lectures/07/07-regression-multiple-predictors.html#fitting-a-multiple-regression-model-in-r",
    "title": "Regression with multiple predictors",
    "section": "Fitting a multiple regression model in R",
    "text": "Fitting a multiple regression model in R\nFind the equation of the plane by adding in new predictors:\n\nmy_model_fit &lt;- linear_reg() |&gt;\n  fit(outcome ~ predictor1 + predictor2 + predictor3 + ..., data = data_frame)\n\n. . .\n\nThis code template will fit the model according to the ordinary least squares (OLS) objective function, i.e., we are finding the equation of the hyperplane that minimizes the sum of squared residuals\n\n. . .\n\nYou can then display a tidy output of the model with the tidy() function on your fitted model: tidy(my_model_fit)\n\nToday we’ll explore the question “How do volume and weights books relate?” and “How, if at all, does that change when we take whether the book is hardback or paperback into consideration?”"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-1",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-1",
    "title": "Regression with multiple predictors",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize the relationship between volume (on the x-axis) and weight (on the y-axis). Overlay the line of best fit. Describe the relationship between these variables.\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-2",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-2",
    "title": "Regression with multiple predictors",
    "section": "Exercise 2",
    "text": "Exercise 2\nFit a model predicting weight from volume for these books and save it as weight_fit. Display a tidy output of the model.\n\n# add code here"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-3",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-3",
    "title": "Regression with multiple predictors",
    "section": "Exercise 3",
    "text": "Exercise 3\nInterpret the slope and the intercept in context of the data.\n\nAdd response here."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-4",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-4",
    "title": "Regression with multiple predictors",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate the \\(R^2\\) of this model and interpret it in context of the data.\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-5",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-5",
    "title": "Regression with multiple predictors",
    "section": "Exercise 5",
    "text": "Exercise 5\nVisualize the relationship between volume (on the x-axis) and weight (on the y-axis), taking into consideration the cover type of the book. Use different colors and shapes for hardback and paperback books. Also use different colors for lines of best fit for the two types of books. In addition, add the overall line of best fit (from Exercise 1) as a gray dashed line so that you can see the difference between the lines when considering and not considering cover type.\n\n# add code here"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-6",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-6",
    "title": "Regression with multiple predictors",
    "section": "Exercise 6",
    "text": "Exercise 6\nFit a model predicting weight from volume for these books and save it as weight_cover_fit. Display a tidy output of the model.\n\n# add code here"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-7",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-7",
    "title": "Regression with multiple predictors",
    "section": "Exercise 7",
    "text": "Exercise 7\nIn the model output we have a variable coverpb. Why is only the pb (paperback) level of the cover variable shown? What happened to the hb (hardback) level?\n\nAdd response here."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-8",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-8",
    "title": "Regression with multiple predictors",
    "section": "Exercise 8",
    "text": "Exercise 8\nInterpret the slopes and the intercept in context of the data.\n\nAdd response here."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-9",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-9",
    "title": "Regression with multiple predictors",
    "section": "Exercise 9",
    "text": "Exercise 9\nFirst, guess whether the \\(R^2\\) of this model will be greater than, less than, or the same as the previous model, or whether we can’t tell. Then, calculate the \\(R^2\\) of this model to confirm your guess, and then interpret it in context of the data.\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-10",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-10",
    "title": "Regression with multiple predictors",
    "section": "Exercise 10",
    "text": "Exercise 10\nWhich model is preferred for predicting book weights and why?\n\nAdd response here."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors.html#exercise-11",
    "href": "lectures/07/07-regression-multiple-predictors.html#exercise-11",
    "title": "Regression with multiple predictors",
    "section": "Exercise 11",
    "text": "Exercise 11\nUsing the model you chose, predict the weight of a hardcover book that is 1000 cubic centimeters (that is, roughly 25 centimeters in length, 20 centimeters in width, and 2 centimeters in height/thickness).\n\n# add code here"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html",
    "title": "Inference for two proportions",
    "section": "",
    "text": "Peer review due Sunday at 11:59 pm\nIf you have not emailed your reviewe yet, do so (and cc me)!"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#announcements",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#announcements",
    "title": "Inference for two proportions",
    "section": "",
    "text": "Peer review due Sunday at 11:59 pm\nIf you have not emailed your reviewe yet, do so (and cc me)!"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#nc-poll-on-equality",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#nc-poll-on-equality",
    "title": "Inference for two proportions",
    "section": "NC poll on equality",
    "text": "NC poll on equality\nA September 16-19, 2023, asked North Carolina voters, among other issues, about issues of equality and women’s progress. Specifically, one of the questions asked:\n\nWhich of these two statements come closest to your own views—even if neither is exactly right?\n\nThe country has made most of the changes needed to give women equal rights with men.\nThe country needs to continue to make changes to give women equal rights to men."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#sta-101-vs.-nc",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#sta-101-vs.-nc",
    "title": "Inference for two proportions",
    "section": "STA 101 vs. NC",
    "text": "STA 101 vs. NC\n\nHow do you think the distribution of responses from this class would compare to the NC polling results?\na. Similar distribution of answers between the two polls.\nb. Higher percentage of “The country has made most of the changes needed to give women equal rights with men” in STA 101 compared to NC poll.\nc. Lower percentage of “The country has made most of the changes needed to give women equal rights with men” in STA 101 compared to NC poll."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-1",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-1",
    "title": "Inference for two proportions",
    "section": "Exercise 1",
    "text": "Exercise 1\nThe two populations of interest in this survey are 18-24 year olds and 25+ year olds. State the hypotheses for evaluating whether there is a discernible difference between the proportions of those who think “The country needs to continue to make changes to give women equal rights to men.” (need more changes) in the two age groups.\n\n\\(H_0\\): There is no difference in how the two groups think about “The country needs to continue to make changes to give women equal rights to men.”\nLet \\(p\\) true population proportion of those who think more changes need to be made.\n\\(H_0: p_{18-24} = p_{25+}\\)\n\\(H_A: p_{18-24} \\neq p_{25+}\\)"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-2",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-2",
    "title": "Inference for two proportions",
    "section": "Exercise 2",
    "text": "Exercise 2\nLoad the data.\n\nequality &lt;- read_csv(\"equality.csv\")"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-3",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-3",
    "title": "Inference for two proportions",
    "section": "Exercise 3",
    "text": "Exercise 3\nCreate a 2x2 table of the responses across the two age groups.\n\nequality_table &lt;- equality |&gt;\n  count(age, response) |&gt;\n  pivot_wider(names_from = \"response\", values_from = \"n\")\n\nequality_table\n\n# A tibble: 2 × 3\n  age   `Most changes done` `Need more changes`\n  &lt;chr&gt;               &lt;int&gt;               &lt;int&gt;\n1 18-24                  32                  35\n2 25+                   211                 450"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-4",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-4",
    "title": "Inference for two proportions",
    "section": "Exercise 4",
    "text": "Exercise 4\nWhat proportion of 18-24 year olds think “The country needs to continue to make changes to give women equal rights to men”? What proportion of 25+ year olds? Calculate and visualize these proportions.\n\nequality_table |&gt;\n  mutate(phat = round(`Need more changes` /(`Most changes done` + `Need more changes`),3)) \n\n# A tibble: 2 × 4\n  age   `Most changes done` `Need more changes`  phat\n  &lt;chr&gt;               &lt;int&gt;               &lt;int&gt; &lt;dbl&gt;\n1 18-24                  32                  35 0.522\n2 25+                   211                 450 0.681\n\n\n\nggplot(equality, aes(y = age, fill = response)) +\n  geom_bar(position = \"fill\")"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-5",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-5",
    "title": "Inference for two proportions",
    "section": "Exercise 5",
    "text": "Exercise 5\nCalculate the observed sample statistic, i.e., the difference between the proportions of respondents who think “The country needs to continue to make changes to give women equal rights to men” between the two age groups.\n\nobs_stat &lt;- \n  equality |&gt;\n  specify(response = response, explanatory = age, success = \"Need more changes\") |&gt;\n  calculate(stat = \"diff in props\", order = c(\"18-24\", \"25+\"))\n\nobs_stat\n\nResponse: response (factor)\nExplanatory: age (factor)\n# A tibble: 1 × 1\n    stat\n   &lt;dbl&gt;\n1 -0.158"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-6",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-6",
    "title": "Inference for two proportions",
    "section": "Exercise 6",
    "text": "Exercise 6\nWhat is the parameter of interest?\n\nDifference between the proportions of those who think “The country needs to continue to make changes to give women equal rights to men” between 18-24 and 25+ year old NC voters."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-7",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-7",
    "title": "Inference for two proportions",
    "section": "Exercise 7",
    "text": "Exercise 7\nExplain how you can set up a simulation for this hypothesis test.\n\nRefer to Chapter 11. Take 485 (35 + 450) white cards and 243 (32 + 211) red cards. Shuffle them. Deal 67 cards into one pile and 661 cards into the second pile. Calculate the proportion of white cards in the first pile minus the proportion of the white cards in the second pile. Repeat many times."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-8",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-8",
    "title": "Inference for two proportions",
    "section": "Exercise 8",
    "text": "Exercise 8\nConduct the hypothesis test using randomization and visualize and report the p-value.\n\nset.seed(1234)\n\nnull_dist &lt;- equality |&gt;\n  specify(response = response, explanatory = age, success = \"Need more changes\") |&gt;\n  hypothesise(null = \"independence\") |&gt;\n  generate(reps = 1000, type = \"permute\") |&gt;\n  calculate(stat = \"diff in props\", order = c(\"18-24\", \"25+\"))\n\nnull_dist |&gt;\n  get_p_value(obs_stat = obs_stat, direction = \"two sided\")\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1   0.012\n\nnull_dist |&gt;\n  visualize() +\n  shade_p_value(obs_stat = obs_stat, direction = \"two sided\")"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-9",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-9",
    "title": "Inference for two proportions",
    "section": "Exercise 9",
    "text": "Exercise 9\nWhat is the conclusion of the hypothesis test?\n\nWith the p-value of 0.012, which is smaller than 0.05 discernability level, we reject the null hypothesis.\nThe data provides evidence that there is a difference between the proportion of those who think “The country needs to continue to make changes” in the 18-24 and 25+ groups."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-10",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-10",
    "title": "Inference for two proportions",
    "section": "Exercise 10",
    "text": "Exercise 10\nInterpret the p-value in the context of the data and the hypotheses.\n\nThe probability of observing a difference in sample proportions of those who think “The country needs to continue to make changes to give women equal rights to men” between a sample of 67 18-24 year olds and 661 25+ year olds of 0.158 or more (in either direction) is 0.012 if in fact the two population proportions are equal."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-11",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-11",
    "title": "Inference for two proportions",
    "section": "Exercise 11",
    "text": "Exercise 11\nEstimate the difference in population proportions of 18-24 year old NC voters and 25+ year old NC voters using a 95% bootstrap interval.\n\nset.seed(1234)\n\nboot_dist &lt;- equality |&gt;\n  specify(response = response, explanatory = age, success = \"Need more changes\") |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  calculate(stat = \"diff in props\", order = c(\"18-24\", \"25+\"))\n\nci &lt;- boot_dist |&gt;\n  get_ci()\nci\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1   -0.288  -0.0279\n\nboot_dist |&gt;\n  summarise(quantile(stat, 0.025),\n            quantile(stat, 0.975))\n\n# A tibble: 1 × 2\n  `quantile(stat, 0.025)` `quantile(stat, 0.975)`\n                    &lt;dbl&gt;                   &lt;dbl&gt;\n1                  -0.288                 -0.0279\n\nvisualise(boot_dist) +\n  shade_ci(ci)"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-12",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-12",
    "title": "Inference for two proportions",
    "section": "Exercise 12",
    "text": "Exercise 12\nInterpret the confidence interval in context of the data.\n\nWe are 95% confident that the proportion of 18-24 year old NC voters who think “The country needs to continue to make changes to give women equal rights to men” is 28.8% to 2.9% lower than 25+ year old NC voters who share this opinion."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-13",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-13",
    "title": "Inference for two proportions",
    "section": "Exercise 13",
    "text": "Exercise 13\nDescribe how the simulation scheme for bootstrapping is different than that for the hypothesis test.\n\nFor bootstrap, we sample with replacement from our sample under the assumption that our sample is representative of population.\nFor hypothesis test, we sample under the assumption that the null is true."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-14",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-14",
    "title": "Inference for two proportions",
    "section": "Exercise 14",
    "text": "Exercise 14\nWhat is \\(p\\) vs. \\(\\hat{p}\\) vs. p-value. Explain generically as well as in the context of these data and research question.\n\n\\(p\\) - population proportion\n\\(\\hat p\\) - sample proportion\n\\(p\\)-value - probability of observing our observed sample statistic or something more extreme if null is true."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-15",
    "href": "lectures/16/16-inference-two-proportions-filled-in.html#exercise-15",
    "title": "Inference for two proportions",
    "section": "Exercise 15",
    "text": "Exercise 15\nWhat is sampling distribution vs. bootstrap distribution vs. null distribution? Explain generically as well as in the context of these data and research question.\n\nSuppose we have a sample of size \\(n\\).\nSampling distribution: if we were to collect many samples of size \\(n\\) from the population and calculate sample statistic for each, how would they be distributed?\nBootstrap distribution: “collect” a sample of size \\(n\\) by performing sampling with replacement from our sample. Calculate sample statistic on each sample and look at how they are distributed.\nNull distribution: assume null is true. Then, we have a “population” to sample from. Generate a sample of size \\(n\\) under the null assumption and calculate sample statistic for each, how would they be distributed?"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html",
    "href": "lectures/09/09-logistic-regression-filled-in.html",
    "title": "Logistic regression",
    "section": "",
    "text": "Feedback on project proposals by the end of the week.\nExam review will be posted by the end of the week.\nExam:\n\nIn class: Fri, June 7th (1 sheet of notes allowed)\nTake home due Sun, June 9th"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#check-in",
    "href": "lectures/09/09-logistic-regression-filled-in.html#check-in",
    "title": "Logistic regression",
    "section": "",
    "text": "Feedback on project proposals by the end of the week.\nExam review will be posted by the end of the week.\nExam:\n\nIn class: Fri, June 7th (1 sheet of notes allowed)\nTake home due Sun, June 9th"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#so-far-in-regression",
    "href": "lectures/09/09-logistic-regression-filled-in.html#so-far-in-regression",
    "title": "Logistic regression",
    "section": "So far in regression",
    "text": "So far in regression\n\nOutcome: Numerical, Predictor: One numerical or one categorical with only two levels \\(\\rightarrow\\) Simple linear regression\nOutcome: Numerical, Predictors: Any number of numerical or categorical variables with any number of levels \\(\\rightarrow\\) Multiple linear regression\nOutcome: Categorical with only two levels, Predictors: Any number of numerical or categorical variables with any number of levels \\(\\rightarrow\\) Logistic regression\nOutcome: Categorical with any number of levels, Predictors: Any number of numerical or categorical variables with any number of levels \\(\\rightarrow\\) Generalized linear models – Not covered in STA 101"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#data-packages",
    "href": "lectures/09/09-logistic-regression-filled-in.html#data-packages",
    "title": "Logistic regression",
    "section": "Data + packages",
    "text": "Data + packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nhp_spam &lt;- read_csv(\"hp-spam.csv\")\n\n\n4601 emails collected at Hewlett-Packard labs and contains 58 variables\nOutcome: type\n\ntype = 1 is spam\ntype = 0 is non-spam\n\nPredictors of interest:\n\ncapitalTotal: Number of capital letters in email\nPercentages are calculated as (100 * number of times the WORD appears in the e-mail) / total number of words in email\n\ngeorge: Percentage of “george”s in email (these were George’s emails)\nyou: Percentage of “you”s in email"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#glimpse-at-data",
    "href": "lectures/09/09-logistic-regression-filled-in.html#glimpse-at-data",
    "title": "Logistic regression",
    "section": "Glimpse at data",
    "text": "Glimpse at data\n\nWhat type of data is type? What type should it be in order to use logistic regression?\n\n\nhp_spam |&gt;\n  select(type, george, capitalTotal, you)\n\n# A tibble: 4,601 × 4\n    type george capitalTotal   you\n   &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1     1      0          278  1.93\n 2     1      0         1028  3.47\n 3     1      0         2259  1.36\n 4     1      0          191  3.18\n 5     1      0          191  3.18\n 6     1      0           54  0   \n 7     1      0          112  3.85\n 8     1      0           49  0   \n 9     1      0         1257  1.23\n10     1      0          749  1.67\n# ℹ 4,591 more rows"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#eda-how-much-spam",
    "href": "lectures/09/09-logistic-regression-filled-in.html#eda-how-much-spam",
    "title": "Logistic regression",
    "section": "EDA: How much spam?",
    "text": "EDA: How much spam?\n\nhp_spam |&gt;\n  count(type) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 2 × 3\n   type     n     p\n  &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1     0  2788 0.606\n2     1  1813 0.394"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#eda-am-i-screaming-capitaltotal",
    "href": "lectures/09/09-logistic-regression-filled-in.html#eda-am-i-screaming-capitaltotal",
    "title": "Logistic regression",
    "section": "EDA: AM I SCREAMING? capitalTotal",
    "text": "EDA: AM I SCREAMING? capitalTotal\n\nggplot(hp_spam, aes(x = capitalTotal)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#eda-george-is-that-you",
    "href": "lectures/09/09-logistic-regression-filled-in.html#eda-george-is-that-you",
    "title": "Logistic regression",
    "section": "EDA: george, is that you?",
    "text": "EDA: george, is that you?\nggplot(hp_spam, aes(x = george)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nggplot(hp_spam, aes(x = you)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#logistic-regression-1",
    "href": "lectures/09/09-logistic-regression-filled-in.html#logistic-regression-1",
    "title": "Logistic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nLogistic regression takes in a number of predictors and outputs the probability of a “success” (an outcome of 1) in a binary outcome variable.\nThe probability is related to the predictors via a sigmoid link function, \\[\np(y_i = 1) = \\frac{1}{1+\\text{exp}({- \\sum \\beta_i x_i })},\n\\]whose output is in \\((0,1)\\) (a probability).\nCan also be written as\n\n\\[\np(y_i = 1) = \\frac{\\text{exp}({\\sum \\beta_ix_i})}{1 + \\text{exp}({\\sum \\beta_ix_i})}\n\\]\nor in Logit form\n\\[\n\\text{logit}(p) = \\log(\\frac{p}{1 - p}) = \\sum\\beta_ix_i\n\\]\nwhere \\(p = p(y_i = 1)\\).\n\nIn this modeling scheme, one typically finds \\(\\hat{\\beta}\\) by maximizing the likelihood function, another objective function, different than our previous “least squares” objective."
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#logistic-regression-visualized",
    "href": "lectures/09/09-logistic-regression-filled-in.html#logistic-regression-visualized",
    "title": "Logistic regression",
    "section": "Logistic regression, visualized",
    "text": "Logistic regression, visualized"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#using-data-to-estimate-beta_i",
    "href": "lectures/09/09-logistic-regression-filled-in.html#using-data-to-estimate-beta_i",
    "title": "Logistic regression",
    "section": "Using data to estimate \\(\\beta_i\\)",
    "text": "Using data to estimate \\(\\beta_i\\)\nTo proceed with building our email classifier, we will, as usual, use our data (outcome \\(y_i\\) and predictor \\(x_i\\) pairs), to estimate \\(\\beta\\) (find \\(\\hat{\\beta}\\)) and obtain the model: \\[\np(y_i = 1) = \\frac{1}{1+\\text{exp}({- \\sum  \\hat{\\beta}_i x_i})},\n\\]\nIn this lecture, we’ll build a spam filter. Or, at least, learn a bit about how spam filters are built by building a very simple (likely not very effective) one."
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-1",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-1",
    "title": "Logistic regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nOne predictor model: Visualize a linear model where the outcome is type (spam or not) and george is the only predictor. Then, discuss your visualization with your neighbor. Is this a good model? Why or why not?\nDoesn’t make sense to draw a line and predict values between 0 and 1.\n\nggplot(hp_spam, aes(x = george, y = type)) + \n  geom_point() + \n  geom_smooth(method = \"lm\", se = FALSE)\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-2",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-2",
    "title": "Logistic regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nTwo predictor model: In this exercise focus on two predictors: you and capitalTotal.\n\nCreate a visualization with you on the x-axis and capitalTotal on the y-axis. Color data points by whether or not they are spam (type). Make sure that type is being used as a categorical variable (factor).\n\n\nhp_spam &lt;- hp_spam |&gt;\n  mutate(type = as.factor(type))\n\nggplot(hp_spam, aes(x = you, y = capitalTotal, color = type)) + \n  geom_point(alpha = 0.2)\n\n\n\n\n\n\n\n\n\nFit the model predicting type from you and capitalTotal. Comment on how the code differs from code used in previous models we fit. Also comment on how it’s similar.\n\n\nspam_fit &lt;- logistic_reg() |&gt;\n  fit(type ~ you + capitalTotal, data = hp_spam)\n\ntidy(spam_fit)\n\n# A tibble: 3 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  -1.50     0.0554       -27.1 2.97e-162\n2 you           0.361    0.0198        18.3 1.84e- 74\n3 capitalTotal  0.00173  0.000104      16.6 5.66e- 62"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-3",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-3",
    "title": "Logistic regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWrite the model equation.\n\\[\nlogit(\\hat p) = -1.50 + 0.362 \\times you + 0.00173\\times capitalTotal\n\\]\n\\[\nlog(\\frac{\\hat p}{1 - \\hat p}) = -1.50 + 0.362 \\times you + 0.00173\\times capitalTotal\n\\]"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-4",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-4",
    "title": "Logistic regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nWhat is the probability the email is spam if the frequency of you is 5% in the email and there are 2500 capital letters.\n\nFirst, so this “by hand” (using R as a calculator) and the model you wrote in the previous exercise.\n\n\nlogit_phat = -1.50 + 0.362 * 5 + 0.00173* 2500\n\nphat &lt;- exp(logit_phat)/(1 + exp(logit_phat))\n\nphat\n\n[1] 0.9903872\n\n\n\nThen, do it using R functions designed for prediction.\n\n\nnew_email &lt;- tibble(\n  you = 5,\n  capitalTotal = 2500\n)\n\npredict(spam_fit, new_data = new_email)\n\n# A tibble: 1 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 1          \n\npredict(spam_fit, new_data = new_email, type = \"prob\")\n\n# A tibble: 1 × 2\n  .pred_0 .pred_1\n    &lt;dbl&gt;   &lt;dbl&gt;\n1 0.00963   0.990"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-5",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-5",
    "title": "Logistic regression",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nWhat would you set your decision boundary to and why?\nChange decision_boundary in the code above to 0.01 and 0.999999. Do the results surprise you? Why or why not?"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-6",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-6",
    "title": "Logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nIf you set a lower decision boundary, do you label fewer or more emails as spam? What happens if you set 0 as your boundary? What about 1 as your boundary? If you very much dislike spam, should you set a high or low boundary?\n*Lower boundary means that we label more emails as spam, high boundary means fewer emails as spam. We can adjust the boundary depending on how much we value receiving important emails vs. how much we dislike spam.\n0 means all emails are spam, 1 means no emails are spam. Note you cannot set decision boundary to 0 or 1 because of logit function (would evaluate to inf or negative inf). *"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-6-1",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-6-1",
    "title": "Logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUsing your model, predict whether this email will be classified as spam or not. What does the model predict for the probability that this email is spam? With a decision boundary of 0.5, how does the model classify this email? Do you believe this classification? Why or why not?\n\npredict(spam_fit, new_data = new_email)\n\n# A tibble: 1 × 1\n  .pred_class\n  &lt;fct&gt;      \n1 1          \n\npredict(spam_fit, new_data = new_email, type = \"prob\")\n\n# A tibble: 1 × 2\n  .pred_0 .pred_1\n    &lt;dbl&gt;   &lt;dbl&gt;\n1  0.0254   0.975\n\n\nThe model predicts 0.99 probability that this new email is spam. This seems reasonable based on the new email text."
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-7",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-7",
    "title": "Logistic regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nInspect hp_spam_split. How many emails are in hp_spam_train, how many are in hp_spam_test. Check out the documentation for the initial_split() function, what ratio does it use for splitting the dataset into training and testing samples?\ninitial_split() splits the data so that 3/4 are are saved for training and 1/4 are saved for testing.\n\nhp_spam_split\n\n&lt;Training/Testing/Total&gt;\n&lt;3450/1151/4601&gt;"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-8",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-8",
    "title": "Logistic regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nTrain your model on the training set. Build a predictive model using any combination of predictors from hp_spam to predict type. Save your fitted model as my_model_fit and display its tidy summary.\n\nmy_model_fit &lt;- logistic_reg() |&gt;\n  fit(type ~ you + capitalTotal, data = hp_spam_train)\n\ntidy(my_model_fit)\n\n# A tibble: 3 × 5\n  term         estimate std.error statistic   p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)  -1.46     0.0635       -23.1 1.31e-117\n2 you           0.353    0.0227        15.5 2.25e- 54\n3 capitalTotal  0.00170  0.000119      14.3 2.51e- 46"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-9",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-9",
    "title": "Logistic regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nMake predictions for your testing set and augment your testing set with these predictions.\n\nmy_model_aug &lt;- augment(my_model_fit, hp_spam_test) |&gt;\n  select(contains(\"pred\"), type, you, capitalTotal)"
  },
  {
    "objectID": "lectures/09/09-logistic-regression-filled-in.html#exercise-10",
    "href": "lectures/09/09-logistic-regression-filled-in.html#exercise-10",
    "title": "Logistic regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nWhat are the false positive and false negative rates of this model?\n\nmy_model_aug |&gt;\n  count(type, .pred_class) |&gt;\n  group_by(type)|&gt;\n  mutate(prop = n/sum(n))\n\n# A tibble: 4 × 4\n# Groups:   type [2]\n  type  .pred_class     n  prop\n  &lt;fct&gt; &lt;fct&gt;       &lt;int&gt; &lt;dbl&gt;\n1 0     0             626 0.879\n2 0     1              86 0.121\n3 1     0             247 0.563\n4 1     1             192 0.437"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html",
    "title": "Inference for a proportion",
    "section": "",
    "text": "Lab 6 due 11:59 pm\nIntro and EDA due 11:59 pm\nEmail your reviewer!"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#announcements",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#announcements",
    "title": "Inference for a proportion",
    "section": "",
    "text": "Lab 6 due 11:59 pm\nIntro and EDA due 11:59 pm\nEmail your reviewer!"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#proportions",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#proportions",
    "title": "Inference for a proportion",
    "section": "Proportions",
    "text": "Proportions\n\nIf the parameter of interest is a single population proportion, what type of and how many variables are being studied?"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-1",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-1",
    "title": "Inference for a proportion",
    "section": "Exercise 1",
    "text": "Exercise 1\nWhat, if anything, do you know about voter turnout in the US?\n\n~ 60% last presidential election."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-2",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-2",
    "title": "Inference for a proportion",
    "section": "Exercise 2",
    "text": "Exercise 2\nLoad the data and visualize the distribution of responses. Also calculate the proportion of respondents who are certain to vote in the next presidential election.\n\nggplot(voting_survey, aes(y = vote)) + \n  geom_bar()\n\n\n\n\n\n\n\nvoting_survey |&gt;\n  count(vote) |&gt;\n  mutate(p_hat = n/sum(n)) |&gt;\n  filter(vote == \"Certain to vote\")\n\n# A tibble: 1 × 3\n  vote                n p_hat\n  &lt;chr&gt;           &lt;int&gt; &lt;dbl&gt;\n1 Certain to vote  1921 0.696"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-3",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-3",
    "title": "Inference for a proportion",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat is the parameter of interest?\n\nProportion of registered voters who are certain to vote in the next presidential election."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-4",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-4",
    "title": "Inference for a proportion",
    "section": "Exercise 4",
    "text": "Exercise 4\nEstimate using a 95% bootstrap interval.\n\nvoting_survey &lt;- voting_survey |&gt;\n  mutate(vote_certain = if_else(\n    vote == \"Certain to vote\", \n    \"Certain to vote\",\n    \"Not certain to vote\"\n  ))\n\nobs_stat &lt;- voting_survey |&gt;\n  specify(response = vote_certain, success = \"Certain to vote\") |&gt;\n  calculate(stat = \"prop\")\n\nset.seed(1234)\n\nboot_dist &lt;- voting_survey |&gt;\n  specify(response = vote_certain, success = \"Certain to vote\") |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  calculate(stat = \"prop\")\n\nci &lt;- boot_dist |&gt;\n  get_ci()\n\nvisualise(boot_dist) +\n  shade_ci(ci)\n\n\n\n\n\n\n\nci\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1    0.678    0.714"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-5",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-5",
    "title": "Inference for a proportion",
    "section": "Exercise 5",
    "text": "Exercise 5\nL = 0.6781443 ; U = 0.7140268\nSuppose the bounds of this interval are L = 0.678 and U = 0.714, your friend interprets the interval as\n\n95% of the time, the true proportion of proportion of registered US voters who are certain to vote in the next presidential election is between L and U.\n\nComment on this interpretation. Is it correct? If not, how would ix it?\nWe are 95% confident that 67.8% to 71.4% of all registered voters are certain to vote in the next presidential election."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-6",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-6",
    "title": "Inference for a proportion",
    "section": "Exercise 6",
    "text": "Exercise 6\nWhat are the hypotheses?\n\n\\(H_0\\) 60% of registered US voters are certain to vote ($p =0.6$)\n\\(H_A\\) More than 60% of registered US voters are certain to vote ($p &gt; 0.6$)."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-7",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-7",
    "title": "Inference for a proportion",
    "section": "Exercise 7",
    "text": "Exercise 7\nConduct a randomization test, at 5% discernability level, for this claim. What is the conclusion of the test?\n\nset.seed(1234)\n\nnull_dist &lt;- voting_survey |&gt;\n  specify(response = vote_certain, success = \"Certain to vote\") |&gt;\n  hypothesise(null = \"point\", p = 0.6) |&gt;\n  generate(reps = 1000, type = \"draw\") |&gt;\n  calculate(stat = \"prop\")\n\n\nnull_dist |&gt;\n  get_p_value(obs_stat, direction = \"greater\")\n\nWarning: Please be cautious in reporting a p-value of 0. This result is an approximation\nbased on the number of `reps` chosen in the `generate()` step.\nℹ See `get_p_value()` (`?infer::get_p_value()`) for more information.\n\n\n# A tibble: 1 × 1\n  p_value\n    &lt;dbl&gt;\n1       0\n\nvisualize(null_dist) +\n  shade_p_value(obs_stat, direction = \"greater\")\n\nWarning in min(diff(unique_loc)): no non-missing arguments to min; returning\nInf\n\n\n\n\n\n\n\n\n\n\nThe p-value is smaller than 0.001, which is smaller than 0.05 (disernability level), so we reject the null hypothesis. The data provides evidence that the true proportion of US voters certain to vote is greater than 60%."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-8",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-8",
    "title": "Inference for a proportion",
    "section": "Exercise 8",
    "text": "Exercise 8\nSuppose the p-value you found is approx 0, and your friends are in disagreement about the interpretation about this value. One friend claims:\n\nThe probability that 60% of all of registered US voters are certain to vote in the next presidential election is approx 0.\n\nAnother friend claims:\n\nThe probability that more than 60% of all of registered US voters are certain to vote in the next presidential election is approx 0.\n\nWho is right? Explain your reasoning.\n\nBoth are wrong. P-value does not give us a probability that \\(H_0\\) is true or the probability that \\(H_A\\) is true."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-9",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-9",
    "title": "Inference for a proportion",
    "section": "Exercise 9",
    "text": "Exercise 9\nWhat is \\(p\\) vs. \\(\\hat{p}\\) vs. p-value. Explain generically as well as in the context of these data and research question.\nAdd response here."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-10",
    "href": "lectures/15/15-inference-one-proportion-filled-in.html#exercise-10",
    "title": "Inference for a proportion",
    "section": "Exercise 10",
    "text": "Exercise 10\nWhat is sampling distribution vs. bootstrap distribution vs. null distribution? Explain generically as well as in the context of these data and research question.\nAdd response here."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html",
    "href": "lectures/13/13-inference-mathematical-models.html",
    "title": "Inference with mathematical models",
    "section": "",
    "text": "Last day to drop with a W is tomorrow!"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#announcements",
    "href": "lectures/13/13-inference-mathematical-models.html#announcements",
    "title": "Inference with mathematical models",
    "section": "",
    "text": "Last day to drop with a W is tomorrow!"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#that-familiar-shape",
    "href": "lectures/13/13-inference-mathematical-models.html#that-familiar-shape",
    "title": "Inference with mathematical models",
    "section": "That familiar shape…",
    "text": "That familiar shape…\n\nDescribe the shape of the distributions."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#its-not-happenstance",
    "href": "lectures/13/13-inference-mathematical-models.html#its-not-happenstance",
    "title": "Inference with mathematical models",
    "section": "It’s not happenstance!",
    "text": "It’s not happenstance!\nIt’s the Central Limit Theorem (or CLT), which says that the distribution of the sample statistic is normal, if certain conditions are met.\n\nTwo questions:\n\nWhat do we mean by the distribution of the sample statistic?\nWhat conditions need to be met?"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#the-distribution-of-the-sample-statistic",
    "href": "lectures/13/13-inference-mathematical-models.html#the-distribution-of-the-sample-statistic",
    "title": "Inference with mathematical models",
    "section": "The distribution of the sample statistic",
    "text": "The distribution of the sample statistic\n\nYou can build the distribution of the sample statistic by repeatedly taking samples of size \\(n\\) (original sample size) from the population and calculating and recording the sample statistic for each of these samples.\nBut, you would never do this in reality!\nYou’d either use simulation (randomization, bootstrapping, stuff we’ve done so far!) or you would leverage mathematical theory to know what to expect if we had taken repeated samples."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#the-technical-conditions",
    "href": "lectures/13/13-inference-mathematical-models.html#the-technical-conditions",
    "title": "Inference with mathematical models",
    "section": "The (technical) conditions",
    "text": "The (technical) conditions\n\nIndependent observations: Observations in the sample are independent. Independence is guaranteed when we take a random sample from a population. Independence can also be guaranteed if we randomly divide individuals into treatment and control groups.\nLarge enough sample: The sample size cannot be too small. What qualifies as “small” differs from one context (i.e., from sample statistic to sample statistic).\n\n\n\n\n\n\n\nImportant\n\n\n\nNOTE: if the population distribution is normal, the sampling distribution will be normal (can use CLT even if the sample size is small)."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#more-to-the-clt",
    "href": "lectures/13/13-inference-mathematical-models.html#more-to-the-clt",
    "title": "Inference with mathematical models",
    "section": "More to the CLT",
    "text": "More to the CLT\n\nThere is more to the CLT than just the shape of the distribution – normal.\nThe CLT says that the center of the sampling distribution will be at the true population parameter.\nThe CLT also says something about the spread of the sampling distribution, measured by the standard error. For each sample statistic (\\(\\bar{x}\\) – the sample mean, \\(\\hat{p}\\) – the sample proportion, \\(\\bar{x}_1 - \\bar{x}_2\\) – the difference in sample means, etc.) the CLT provides a formula for its standard error.\n\nYou won’t be asked to memorize these formulas.\nIn fact, you’ll rarely use the CLT to calculate the variability of sample statistics, you’ll simulate their distributions directly."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#clt-for-proportions",
    "href": "lectures/13/13-inference-mathematical-models.html#clt-for-proportions",
    "title": "Inference with mathematical models",
    "section": "CLT for proportions",
    "text": "CLT for proportions\n\nIf we look at a proportion (or difference in proportions) and the scenario satisfies certain conditions, then the sample proportion (or difference in proportions) will appear to follow a bell-shaped curve called the normal distribution."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#clt-for-means",
    "href": "lectures/13/13-inference-mathematical-models.html#clt-for-means",
    "title": "Inference with mathematical models",
    "section": "CLT for means",
    "text": "CLT for means\n\nLet \\(x\\) be the variable of interest. Suppose \\(x\\) follows a distribution with mean \\(\\mu\\) and standard deviation is \\(\\sigma\\). When certain criteria are satisfied, the sample mean \\(\\bar x\\) of sample of size \\(n\\) is normally distributed. Specifically \\[\\bar x \\sim N(\\mu, \\sigma/\\sqrt{n}),\\] i.e. \\(\\bar x\\) is normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma/\\sqrt{n}\\). The standard deviation of the sampling distribution is called the standard error."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#normal-distributions",
    "href": "lectures/13/13-inference-mathematical-models.html#normal-distributions",
    "title": "Inference with mathematical models",
    "section": "Normal distributions",
    "text": "Normal distributions\n\nHow are these normal distributions similar? How are they different? Which one is \\(N(\\mu = 0, \\sigma = 1)\\) and which \\(N(\\mu = 19, \\sigma = 4)\\)?"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#the-68-95-99.7-rule",
    "href": "lectures/13/13-inference-mathematical-models.html#the-68-95-99.7-rule",
    "title": "Inference with mathematical models",
    "section": "The 68-95-99.7 rule",
    "text": "The 68-95-99.7 rule\nThe normal distribution is not just any unimodal and symmetric distribution, it follows the 68-95-99.7 rule."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#using-the-normal-distribution",
    "href": "lectures/13/13-inference-mathematical-models.html#using-the-normal-distribution",
    "title": "Inference with mathematical models",
    "section": "Using the normal distribution…",
    "text": "Using the normal distribution…\n\nTo make decisions \\(\\rightarrow\\) hypothesis testing\n\nUse properties of the normal distribution to determine the probability of the observed sample statistic (or something more extreme, in the direction of the alternative hypothesis), i.e. the p-value\n\nTo make estimations \\(\\rightarrow\\) confidence intervals\n\nUse properties of the normal distribution to calculate the bounds of the confidence interval, adding and subtracting a margin of error to the observed sample statistic"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-1",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-1",
    "title": "Inference with mathematical models",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize the distribution of bone density of 65-year-old women.\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-2",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-2",
    "title": "Inference with mathematical models",
    "section": "Exercise 2",
    "text": "Exercise 2\nBefore typing any code, based on what you know about the normal distribution, what do you expect the median bone density to be?\nAdd response here."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-3",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-3",
    "title": "Inference with mathematical models",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat bone densities correspond to Q1 (25th percentile), Q2 (50th percentile), and Q3 (the 75th percentile) of this distribution? Use the qnorm() function to calculate these values.\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-4",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-4",
    "title": "Inference with mathematical models",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe densities of three woods are below:\n\nPlywood: 540 \\(mg/cm^3\\)\nPine: 600 \\(mg/cm^3\\)\nMahogany: 710 \\(mg/cm^3\\)\n\nLet’s set these as variables we can use later:\n\nplywood &lt;- 540\npine &lt;- 600\nmahogany &lt;- 710\n\nWhat is the probability that a randomly selected 65-year-old woman has bones less dense than Pine?\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-5",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-5",
    "title": "Inference with mathematical models",
    "section": "Exercise 5",
    "text": "Exercise 5\nWould you be surprised if a randomly selected 65-year-old woman had bone density less than Mahogany? What if she had bone density less than Plywood? Use the respective probabilities to support your response.\nAdd response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-6",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-6",
    "title": "Inference with mathematical models",
    "section": "Exercise 6",
    "text": "Exercise 6\nAre the conditions for the Central Limit Theorem met?\nAdd response here."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-7",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-7",
    "title": "Inference with mathematical models",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhat is the shape, center, and spread of the distribution of the mean bone density for a group of 10 randomly selected 65-year-old women?\nAdd response here."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-8",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-8",
    "title": "Inference with mathematical models",
    "section": "Exercise 8",
    "text": "Exercise 8\nWhat is the probability that the mean bone density for the group of 10 randomly-selected 65-year-old women is less dense than Pine?\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-9",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-9",
    "title": "Inference with mathematical models",
    "section": "Exercise 9",
    "text": "Exercise 9\nWould you be surprised if a group of 10 randomly-selected 65-year old women had a mean bone density less than Mahogany? What the group had a mean bone density less than Plywood? Use the respective probabilities to support your response.\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models.html#exercise-10",
    "href": "lectures/13/13-inference-mathematical-models.html#exercise-10",
    "title": "Inference with mathematical models",
    "section": "Exercise 10",
    "text": "Exercise 10\nExplain how your answers differ in similar sounding earlier vs. later exercises.\nAdd response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html",
    "href": "lectures/04/04-explore-categorical_filled_in.html",
    "title": "Explore categorical data",
    "section": "",
    "text": "The main question we’ll explore today is “What are the demographics and priorities of City of Durham residents?”"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#sample-survey-questions---demographics-todays-focus",
    "href": "lectures/04/04-explore-categorical_filled_in.html#sample-survey-questions---demographics-todays-focus",
    "title": "Explore categorical data",
    "section": "",
    "text": "The main question we’ll explore today is “What are the demographics and priorities of City of Durham residents?”"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-1",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-1",
    "title": "Explore categorical data",
    "section": "Exercise 1",
    "text": "Exercise 1\nHow many rows and columns are in this dataset? Answer in a full sentence using inline code. What does each row represent and what does each column represent?\n\nThere are 803 rows and 49 columns in this data set."
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-2",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-2",
    "title": "Explore categorical data",
    "section": "Exercise 2",
    "text": "Exercise 2\nThe variables we’ll use in this analysis are as follows. Rename the variables to the updated names shown below.\n\n\n\nOriginal name\nUpdated name\n\n\n\n\nprimary_language\nprimary_language\n\n\ndo_you_own_or_rent_your_current_resi_31\nown_rent\n\n\nwould_you_say_your_total_annual_hous_35\nincome\n\n\n\n\ndurham &lt;- durham |&gt;\n  rename(own_rent = do_you_own_or_rent_your_current_resi_31,\n         income = would_you_say_your_total_annual_hous_35)"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-3",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-3",
    "title": "Explore categorical data",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat language do Durham residents speak: primary_language?\n\nWhat is the primary language used in your household?\n\nAdd your answer here.\n\ndurham |&gt;\n  ggplot(aes(x = primary_language)) +\n  geom_bar()\n\n\n\n\n\n\n\ndurham |&gt;\n  count(primary_language)\n\n# A tibble: 4 × 2\n  primary_language     n\n  &lt;chr&gt;            &lt;int&gt;\n1 English            768\n2 Other                3\n3 Spanish             18\n4 &lt;NA&gt;                14"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-4",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-4",
    "title": "Explore categorical data",
    "section": "Exercise 4",
    "text": "Exercise 4\nMake similar bar plots of own_rent and income. What distinct values do these variables take?\n\ndurham |&gt;\n  ggplot(aes(x = income)) +\n  geom_bar()\n\nWarning: Removed 110 rows containing non-finite values (`stat_count()`).\n\n\n\n\n\n\n\n\ndurham |&gt;\n  ggplot(aes(x = own_rent)) +\n  geom_bar()\n\nWarning: Removed 2 rows containing non-finite values (`stat_count()`)."
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-5",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-5",
    "title": "Explore categorical data",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe variables own_rent and income are both categorical, but they’re stored as numbers. In R, categorical data are called factors. Recode these variables as factors with the as_factor() function.\n\ndurham &lt;- durham |&gt;\n  mutate(income = as_factor(income),\n         own_rent = as_factor(own_rent))"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-6",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-6",
    "title": "Explore categorical data",
    "section": "Exercise 6",
    "text": "Exercise 6\nRecreate the visualization from the previous exerciseincome` barplot, improving it for both visual appeal and better communication of findings.\nAdd your answer here.\n\ndurham |&gt;\n  ggplot(aes(y = income, fill = income)) + \n  geom_bar(show.legend = FALSE) +\n  scale_fill_viridis_d(na.value = \"darkgray\") +\n  scale_y_discrete(\n    labels = c(\n      \"1\" = \"Under $30,000\",\n      \"2\" = \"$30,000 - $59,999\",\n      \"3\" = \"$60,000 - $99,999\",\n      \"4\" = \"$100,000 or more\"\n    )\n  ) + \n  labs(\n    x = \"Count\",\n    y = NULL,\n    title = \"Would you say your total annual household income is ... \"\n  )"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-7",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-7",
    "title": "Explore categorical data",
    "section": "Exercise 7",
    "text": "Exercise 7\nRecreate the visualization from the previous exercise, but first calculate relative frequencies (proportions) of income (the marginal distribution) and plot the proportions instead of counts.\n\ndurham |&gt; \n  count(income) |&gt;\n  mutate(prop = n/sum(n)) |&gt;\n  ggplot(aes(y = income, x= prop, fill = income)) +\n  geom_col(show.legend = FALSE) +\n  scale_fill_viridis_d(na.value = \"darkgray\") +\n  scale_y_discrete(\n    labels = c(\n      \"1\" = \"Under $30,000\",\n      \"2\" = \"$30,000 - $59,999\",\n      \"3\" = \"$60,000 - $99,999\",\n      \"4\" = \"$100,000 or more\"\n    )\n  ) + \n  labs(\n    x = \"Proportion\",\n    y = NULL,\n    title = \"Would you say your total annual household income is ... \"\n  )"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-8",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-8",
    "title": "Explore categorical data",
    "section": "Exercise 8",
    "text": "Exercise 8\nVisualize and describe the relationship between income and home ownership of Durham residents.\nStretch goal: Customize the colors using named colors from http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf.\n\ndurham |&gt;\n  select(income, own_rent) |&gt;\n  drop_na() |&gt;\n  ggplot(aes(y = income, fill = own_rent )) + \n  geom_bar(position = \"fill\") +\n  scale_y_discrete(\n    labels = c(\n      \"1\" = \"Under $30,000\",\n      \"2\" = \"$30,000 - $59,999\",\n      \"3\" = \"$60,000 - $99,999\",\n      \"4\" = \"$100,000 or more\"\n    )\n  ) + \n  scale_fill_manual(\n    values = c(\"1\" = \"cadetblue\", \"2\" = \"coral\"), # can choose your own colors\n    labels = c(\"1\" = \"Own\", \"2\" = \"Rent\")\n  ) +\n  labs(\n    x = \"Proportion\",\n    y = \"Would you say your total\\n annual household incom is...\",\n    fill = \"Do you own\\n or rent\\n your current\\n residence?\",\n    title = \"Income v. home ownership of Durham residents\"\n  )"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-9",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-9",
    "title": "Explore categorical data",
    "section": "Exercise 9",
    "text": "Exercise 9\nCalculate the proportions of home owners for each category of Durham residents. Describe the relationship between these two variables, this time with the actual values from the conditional distribution of home ownership based on income level.\nAdd your answer here.\n\ndurham |&gt;\n  select(income, own_rent) |&gt;\n  drop_na() |&gt;\n  count(income, own_rent) |&gt;\n  group_by(income) |&gt;\n  mutate(prop = n/sum(n))\n\n# A tibble: 8 × 4\n# Groups:   income [4]\n  income own_rent     n   prop\n  &lt;fct&gt;  &lt;fct&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 1      1           51 0.362 \n2 1      2           90 0.638 \n3 2      1          105 0.565 \n4 2      2           81 0.435 \n5 3      1          107 0.552 \n6 3      2           87 0.448 \n7 4      1          160 0.930 \n8 4      2           12 0.0698"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#exercise-10",
    "href": "lectures/04/04-explore-categorical_filled_in.html#exercise-10",
    "title": "Explore categorical data",
    "section": "Exercise 10",
    "text": "Exercise 10\nStretch goal: Recode the levels of these two variables to be more informatively labeled and calculate the proportions from the previous exercise again.\n\ndurham &lt;- durham |&gt;\n  mutate(\n    income = case_when(\n      income == \"1\" ~ \"Under $30,000\",\n      income == \"2\" ~ \"$30,000 - $59,999\",\n      income == \"3\" ~ \"$60,000 - $99,999\",\n      income == \"4\" ~ \"$100,000 or more\"\n    ),\n    own_rent = if_else(own_rent == 1, \"Own\", \"Rent\") \n  )\n\n\n\ndurham |&gt;\n  select(income, own_rent) |&gt;\n  drop_na() |&gt;\n  count(income, own_rent) |&gt;\n  group_by(income) |&gt;\n  mutate(prop = n/sum(n))\n\n# A tibble: 8 × 4\n# Groups:   income [4]\n  income            own_rent     n   prop\n  &lt;chr&gt;             &lt;chr&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 $100,000 or more  Own        160 0.930 \n2 $100,000 or more  Rent        12 0.0698\n3 $30,000 - $59,999 Own        105 0.565 \n4 $30,000 - $59,999 Rent        81 0.435 \n5 $60,000 - $99,999 Own        107 0.552 \n6 $60,000 - $99,999 Rent        87 0.448 \n7 Under $30,000     Own         51 0.362 \n8 Under $30,000     Rent        90 0.638"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#conceptual",
    "href": "lectures/04/04-explore-categorical_filled_in.html#conceptual",
    "title": "Explore categorical data",
    "section": "Conceptual",
    "text": "Conceptual\nSome of the terms we introduced are:\n\nMarginal distribution: Distribution of a single variable.\nConditional distribution: Distribution of a variable conditioned on the values (or levels, in the context of categorical data) of another."
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#r",
    "href": "lectures/04/04-explore-categorical_filled_in.html#r",
    "title": "Explore categorical data",
    "section": "R",
    "text": "R\nIn this application exercise we:\n\nDefined factors – the data type that R uses for categorical variables, i.e., variables that can take on values from a finite set of levels.\n\n\n\nReviewed data imports, visualization, and wrangling functions encountered before:\n\nImport: read_csv(): Read data from a CSV (comma separated values) file\nVisualization:\n\nggplot(): Create a plot using the ggplot2 package\naes(): Map variables from the data to aesthetic elements of the plot, generally passed as an argument to ggplot() or to geom_*() functions (define only x or y aesthetic)\ngeom_bar(): Represent data with bars, after calculating heights of bars under the hood\nlabs(): Label x axis, y axis, legend for color of plot, title` of plot, etc.\n\nWrangling:\n\nmutate(): Mutate the data frame by creating a new column or overwriting one of the existing columns\ncount(): Count the number of observations for each level of a categorical variable (factor) or each distinct value of any other type of variable\ngroup_by(): Perform each subsequent action once per each group of the variable, where groups can be defined based on the levels of one or more variables\n\n\nIntroduced new data wrangling functions:\n\nrename(): Rename columns in a data frame\nas_factor(): Convert a variable to a factor\ndrop_na(): Drop rows that have NA in one ore more specified variables\nif_else(): Write logic for what happens if a condition is true and what happens if it’s not\ncase_when(): Write a generalized if_else() logic for more than one codition\n\nIntroduced new data visualization functions:\n\ngeom_col(): Represent data with bars (columns), for heights that have already been calculated (must define x and y aesthetics)\nscale_fill_viridis_d(): Customize the discrete fill scale, using a color-blind friendly, ordinal discrete color scale\nscale_y_discrete(): Customize the discrete y scale\nscale_fill_manual(): Customize the fill scale by manually adjusting values for colors"
  },
  {
    "objectID": "lectures/04/04-explore-categorical_filled_in.html#quarto",
    "href": "lectures/04/04-explore-categorical_filled_in.html#quarto",
    "title": "Explore categorical data",
    "section": "Quarto",
    "text": "Quarto\nWe also introduced chunk options for managing figure sizes:\n\nfig-width: Width of figure\nfig-asp: Aspect ratio of figure (height / width)\nfig-height: Height of figure – but I recommend using fig-width and fig-asp, instead of fig-width and fig-height"
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html",
    "href": "lectures/08/08-model-selection-filled-in.html",
    "title": "Model selection",
    "section": "",
    "text": "Project proposal due Tuesday, May 28th.\nLab 3 due Wednesday, May 29th."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#announcements",
    "href": "lectures/08/08-model-selection-filled-in.html#announcements",
    "title": "Model selection",
    "section": "",
    "text": "Project proposal due Tuesday, May 28th.\nLab 3 due Wednesday, May 29th."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#two-r2s",
    "href": "lectures/08/08-model-selection-filled-in.html#two-r2s",
    "title": "Model selection",
    "section": "Two \\(R^2\\)s",
    "text": "Two \\(R^2\\)s\n\n\\(R^2\\) measures the proportion of variability in the outcome variable that is explained by the model.\n\nAlways goes up with the addition of a predictor.\nAdjusted \\(R^2\\) is this value adjusted to penalize for the number of predictors in the model.\nGoes up if the added predictor is “useful”, i.e. actually increases the predictive performance of the model.\nTherefore we use this metric for choosing between models. Today we’ll explore the question “What best predicts what percent of the bill amount people tip at restaurants?”"
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-1",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-1",
    "title": "Model selection",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize the relationship between these variables.\n\ntips &lt;- tips |&gt;\n  mutate(meal = fct_relevel(meal, \"Lunch\", \"Dinner\", \"Late Night\"))\n\ntips |&gt;\n  ggplot(aes(x = bill, y = tip_percentage, color = party)) + \n  geom_point(alpha = 0.7) + \n  facet_grid(alcohol ~ meal) +\n  scale_color_continuous(breaks = c(1:9)) +\n  scale_y_continuous(labels = label_percent()) +\n  labs(\n    x = \"Bill amount (USD)\",\n    y = \"Tip precentage\",\n    color = \"Party\\n size\"\n  )"
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-2",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-2",
    "title": "Model selection",
    "section": "Exercise 2",
    "text": "Exercise 2\nIn a couple of sentences, describe any apparent patterns.\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-3",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-3",
    "title": "Model selection",
    "section": "Exercise 3",
    "text": "Exercise 3\nFit a model predicting tip percentage from bill amount. Display and interpret the model coefficients. Additionally, calculate and interpret the \\(R^2\\) of this model.\n\ntip_1_fit &lt;- linear_reg() |&gt;\n  fit(tip_percentage ~ bill, data = tips)\n\ntidy(tip_1_fit)\n\n# A tibble: 2 × 5\n  term         estimate std.error statistic  p.value\n  &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)  0.198     0.0134       14.8  2.16e-29\n2 bill        -0.000748  0.000390     -1.92 5.70e- 2\n\n\n\n\nIntercept: For bills that are 0 dollars, the model predicts the tip percentage to be 19.8%.\nSlope: For each additional dollar the bill is higher, we expect the tip percentage to decrease, on average, by 0.0748%.\n\n\n\nglance(tip_1_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared  sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0282        0.0206 0.0819      3.69  0.0570     1   141. -275. -267.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nAbout 2.8% of the variability in the tip percentage can be explained by bill amount."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-4",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-4",
    "title": "Model selection",
    "section": "Exercise 4",
    "text": "Exercise 4\nSuppose we next add meal as a predictor and interpret the model coefficients again.\n\ntip_2_fit &lt;- linear_reg() |&gt;\n  fit(tip_percentage ~ bill + meal, data = tips)\n\ntidy(tip_2_fit)\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic  p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)     0.185     0.0237       7.80  2.07e-12\n2 bill           -0.000561  0.000446    -1.26  2.10e- 1\n3 mealDinner      0.00471   0.0191       0.247 8.05e- 1\n4 mealLate Night  0.0203    0.0250       0.814 4.17e- 1\n\n\n\n\nIntercept: For bills that are 0 dollars in the Lunch group, the model predicts the tip percentage to be 18.5%.\nSlope bill: All else held constant, for each additional dollar the bill is higher, we expect the tip percentage to decrease, on average, by 0.0561%.\nSlope dinner: All else held constant, we expect the tip percentage for dinners to be higher by 0.471% compared to lunches, on average.\nSlope late night: All else held constant, we expect the tip percentage for late night meals to be higher by 2.03% compared to lunches, on average."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-5",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-5",
    "title": "Model selection",
    "section": "Exercise 5",
    "text": "Exercise 5\nWould you expect the \\(R^2\\) of the second model (with bill and meal as predictors) to be higher, lower, or the same as the \\(R^2\\) for the first model (with only bill as the predictor)? Explain your reasoning.\n\nWe expect \\(R^2\\) to be higher since more predictors are used."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-6",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-6",
    "title": "Model selection",
    "section": "Exercise 6",
    "text": "Exercise 6\nFit a model predicting tip percentage from bill amount and meal, calculate its \\(R^2\\), and comment on your guess from the previous exercise.\n\nglance(tip_1_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared  sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0282        0.0206 0.0819      3.69  0.0570     1   141. -275. -267.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\nglance(tip_2_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared  sigma statistic p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    0.0342        0.0110 0.0823      1.48   0.224     3   141. -272. -258.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nThe \\(R^2\\) did go up."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-7",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-7",
    "title": "Model selection",
    "section": "Exercise 7",
    "text": "Exercise 7\nCalculate adjusted \\(R^2\\) for the two models. Is adding meal to a model predicting tip_percentage from bill useful?\n\nglance(tip_1_fit)$adj.r.squared\n\n[1] 0.02056839\n\nglance(tip_2_fit)$adj.r.squared\n\n[1] 0.01103831\n\n\n\nThe adjusted \\(R^2\\) went down, so no, adding meal to a model predicting tip from bill is not useful."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#backward-elimination",
    "href": "lectures/08/08-model-selection-filled-in.html#backward-elimination",
    "title": "Model selection",
    "section": "Backward elimination",
    "text": "Backward elimination\nBackward elimination starts with the full model (the model that includes all potential predictor variables). Variables are eliminated one-at-a-time from the model until we cannot improve the model any further.\nProcedure:\n\nStart with a model that has all predictors we consider and compute the adjusted \\(R^2\\).\nNext fit every possible model with 1 fewer predictor.\nCompare adjusted \\(R^2\\)s to select the best model (highest adjusted \\(R^2\\)) with 1 fewer predictor.\nRepeat steps 2 and 3 until adjusted \\(R^2\\) no longer increases."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#forward-selection",
    "href": "lectures/08/08-model-selection-filled-in.html#forward-selection",
    "title": "Model selection",
    "section": "Forward selection",
    "text": "Forward selection\nForward selection is the reverse of the backward elimination technique. Instead, of eliminating variables one-at-a-time, we add variables one-at-a-time until we cannot find any variables that improve the model any further.\nProcedure:\n\nStart with a model that has no predictors.\nNext fit every possible model with 1 additional predictor and calculate adjusted \\(R^2\\) of each model.\nCompare adjusted \\(R^2\\) values to select the best model (highest adjusted \\(R^2\\)) with 1 additional predictor.\nRepeat steps 2 and 3 until adjusted \\(R^2\\) no longer increases."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-8",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-8",
    "title": "Model selection",
    "section": "Exercise 8",
    "text": "Exercise 8\nPerform backward elimination to find the best model for predicting tip_percentage from meal, party, alcohol, bill.\n\ntip_full_fit &lt;- linear_reg() |&gt; \n  fit(tip_percentage ~ meal + party + alcohol + bill,\n      data = tips)\nglance(tip_full_fit)$adj.r.squared\n\n[1] 0.0003858485\n\n# step 1\n# without bill\nlinear_reg() |&gt;\n  fit(tip_percentage ~ meal + party + alcohol,\n      data = tips) |&gt;\n  glance() |&gt; \n  pull(adj.r.squared)\n\n[1] -0.001215283\n\n# without alcohol\n\nlinear_reg() |&gt;\n  fit(tip_percentage ~ meal + party + bill,\n      data = tips) |&gt;\n  glance() |&gt; \n  pull(adj.r.squared)\n\n[1] 0.007718966\n\n#without party\n\nlinear_reg() |&gt;\n  fit(tip_percentage ~ meal + alcohol + bill,\n      data = tips) |&gt;\n  glance() |&gt; \n  pull(adj.r.squared)\n\n[1] 0.004761466\n\n# without meal\nlinear_reg() |&gt;\n  fit(tip_percentage ~ party + alcohol + bill,\n      data = tips) |&gt;\n  glance() |&gt; \n  pull(adj.r.squared)\n\n[1] 0.01225785\n\n\nBest model (highest adjusted \\(R^2\\)) is without meal as predictor.\n\n# without bill\nlinear_reg() |&gt;\n  fit(tip_percentage ~ party + alcohol,\n      data = tips) |&gt;\n  glance() |&gt; \n  pull(adj.r.squared)\n\n[1] -0.0003317171\n\n# without alcohol\nlinear_reg() |&gt;\n  fit(tip_percentage ~ party + bill,\n      data = tips) |&gt;\n  glance() |&gt; \n  pull(adj.r.squared)\n\n[1] 0.01989357\n\n# without party\n\nlinear_reg() |&gt;\n  fit(tip_percentage ~ alcohol + bill,\n      data = tips) |&gt;\n  glance() |&gt; \n  pull(adj.r.squared)\n\n[1] 0.01374295\n\n\nBest model uses party and bill as predictors.\n\n# without bill\nlinear_reg() |&gt;\n  fit(tip_percentage ~ party,\n      data = tips) |&gt;\n  glance() |&gt; \n  pull(adj.r.squared)\n\n[1] 0.00420045\n\n# without party\nlinear_reg() |&gt;\n  fit(tip_percentage ~ bill,\n      data = tips) |&gt;\n  glance() |&gt; \n  pull(adj.r.squared)\n\n[1] 0.02056839\n\n\n\nThe “best” model attained using backwards elimination predicts tip_percentage from bill."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-9",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-9",
    "title": "Model selection",
    "section": "Exercise 9",
    "text": "Exercise 9\nPerform forward selection to find the best model for predicting tip_percentage from meal, party, alcohol, bill.\n\n# step 1\n# just meal\nlinear_reg() |&gt;\n  fit(tip_percentage ~ meal, data = tips) |&gt;\n  glance() |&gt;\n  pull(adj.r.squared)\n\n[1] 0.006434878\n\n# just party\nlinear_reg() |&gt;\n  fit(tip_percentage ~ party, data = tips) |&gt;\n  glance() |&gt;\n  pull(adj.r.squared)\n\n[1] 0.00420045\n\n# just alcohol\nlinear_reg() |&gt;\n  fit(tip_percentage ~ alcohol, data = tips) |&gt;\n  glance() |&gt;\n  pull(adj.r.squared)\n\n[1] -0.002762376\n\n# just bill\nlinear_reg() |&gt;\n  fit(tip_percentage ~ bill, data = tips) |&gt;\n  glance() |&gt;\n  pull(adj.r.squared)\n\n[1] 0.02056839\n\n\nBest model uses bill as predictor.\n\n# add meal\nlinear_reg() |&gt;\n  fit(tip_percentage ~ bill + meal, data = tips) |&gt;\n  glance() |&gt;\n  pull(adj.r.squared)\n\n[1] 0.01103831\n\n# add party\nlinear_reg() |&gt;\n  fit(tip_percentage ~ bill + party, data = tips) |&gt;\n  glance() |&gt;\n  pull(adj.r.squared)\n\n[1] 0.01989357\n\n# add alcohol\nlinear_reg() |&gt;\n  fit(tip_percentage ~ bill + alcohol, data = tips) |&gt;\n  glance() |&gt;\n  pull(adj.r.squared)\n\n[1] 0.01374295\n\n\nNo increase in adjusted \\(R^2\\).\n\nThe “best” model attained with forward selection also predicts tip_percentage from bill."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#exercise-10",
    "href": "lectures/08/08-model-selection-filled-in.html#exercise-10",
    "title": "Model selection",
    "section": "Exercise 10",
    "text": "Exercise 10\nFit the “best” model and interpret it.\n\nSee ex. 3 (tip_1_fit model)."
  },
  {
    "objectID": "lectures/08/08-model-selection-filled-in.html#footnotes",
    "href": "lectures/08/08-model-selection-filled-in.html#footnotes",
    "title": "Model selection",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College.↩︎"
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html",
    "href": "lectures/05/05-explore-numerical-filled-in.html",
    "title": "Explore numerical data",
    "section": "",
    "text": "Suppose you have a data frame called df and a single variable in it called x. How many variables will df have after running the following code?\n\ndf |&gt;\n  mutate(y = x + 2)\n\n\n. . .\n\nSuppose you have a data frame called df and a single variable in it called x. How many variables will df have after running the following code?\n\ndf &lt;- df |&gt;\n  mutate(y = x + 2)\n\n\n. . .\n\nWhat is the &lt;- operator called and what does it do?"
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#recap-from-last-time",
    "href": "lectures/05/05-explore-numerical-filled-in.html#recap-from-last-time",
    "title": "Explore numerical data",
    "section": "",
    "text": "Suppose you have a data frame called df and a single variable in it called x. How many variables will df have after running the following code?\n\ndf |&gt;\n  mutate(y = x + 2)\n\n\n. . .\n\nSuppose you have a data frame called df and a single variable in it called x. How many variables will df have after running the following code?\n\ndf &lt;- df |&gt;\n  mutate(y = x + 2)\n\n\n. . .\n\nWhat is the &lt;- operator called and what does it do?"
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#exercise-1",
    "href": "lectures/05/05-explore-numerical-filled-in.html#exercise-1",
    "title": "Explore numerical data",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize and describe the relationship between income and home ownership of Durham residents.\nStretch goal: Customize the colors using named colors from http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf.\n\ndurham |&gt;\n  select(income, own_rent) |&gt;\n  drop_na() |&gt;\n  ggplot(aes(y = income, fill = own_rent)) +\n    geom_bar(position = \"fill\") +\n    scale_y_discrete(\n      labels = c(\n        \"1\" = \"&lt; $30,000\",\n        \"2\" = \"$30,000 - $59,999\",\n        \"3\" = \"$60,000 - $99,999\",\n        \"4\" = \"$100,000 + \"\n      )\n    ) +\n    scale_fill_manual(\n      values = c(\"1\" = \"cadetblue\", \"2\" = \"coral\"),\n      labels = c( \"1\" = \"Own\", \"2\" = \"Rent\")\n    ) + \n    labs(\n      x = \"Proportion\",\n      y = \"Would you say your total\\n annual household income is...\",\n      fill = \"Do you own\\n or rent\\n your current\\n residence?\",\n      title = \"Income v. home ownership of Durham residents\"\n    )"
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#exercise-2",
    "href": "lectures/05/05-explore-numerical-filled-in.html#exercise-2",
    "title": "Explore numerical data",
    "section": "Exercise 2",
    "text": "Exercise 2\nCalculate the proportions of home owners for each category of Durham residents. Describe the relationship between these two variables, this time with the actual values from the conditional distribution of home ownership based on income level.\n\ndurham |&gt;\n  select(income, own_rent) |&gt;\n  drop_na() |&gt;\n  count(income, own_rent) |&gt;\n  group_by(income) |&gt;\n  mutate(prop = n/sum(n))\n\n# A tibble: 8 × 4\n# Groups:   income [4]\n  income own_rent     n   prop\n  &lt;fct&gt;  &lt;fct&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 1      1           51 0.362 \n2 1      2           90 0.638 \n3 2      1          105 0.565 \n4 2      2           81 0.435 \n5 3      1          107 0.552 \n6 3      2           87 0.448 \n7 4      1          160 0.930 \n8 4      2           12 0.0698"
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#exercise-3",
    "href": "lectures/05/05-explore-numerical-filled-in.html#exercise-3",
    "title": "Explore numerical data",
    "section": "Exercise 3",
    "text": "Exercise 3\nRecode the levels of these two variables to be more informatively labeled and calculate the proportions from the previous exercise again.\n\ndurham &lt;- durham |&gt;\n  mutate(\n    income_clean = case_when(\n      income == \"1\" ~ \"Under $30,000\",\n      income == \"2\" ~ \"$30,000 - $59,999\",\n      income == \"3\" ~ \"$60,000 - $99,999\",\n      income == \"4\" ~ \"$100,000 or more\"\n    ),\n    income_clean = fct_relevel(income_clean, \n                               \"Under $30,000\",\n                               \"$30,000 - $59,999\",\n                               \"$60,000 - $99,999\",\n                               \"$100,000 or more\"),\n    own_rent = if_else(own_rent == 1, \"Own\", \"Rent\") \n  )\n\n# quality check\ndurham|&gt; \n  count(income, income_clean)\n\n# A tibble: 5 × 3\n  income income_clean          n\n  &lt;fct&gt;  &lt;fct&gt;             &lt;int&gt;\n1 1      Under $30,000       141\n2 2      $30,000 - $59,999   186\n3 3      $60,000 - $99,999   194\n4 4      $100,000 or more    172\n5 &lt;NA&gt;   &lt;NA&gt;                110\n\n# own_rent = case_when(\n#  own_rent == 1 ~ \"Own\",\n#  own_rent == 2 ~ \"Rent\"\n# )\n\n\ndurham |&gt;\n  select(income_clean, own_rent) |&gt;\n  drop_na() |&gt;\n  count(income_clean, own_rent) |&gt;\n  group_by(income_clean) |&gt;\n  mutate(prop = n/sum(n))\n\n# A tibble: 8 × 4\n# Groups:   income_clean [4]\n  income_clean      own_rent     n   prop\n  &lt;fct&gt;             &lt;chr&gt;    &lt;int&gt;  &lt;dbl&gt;\n1 Under $30,000     Own         51 0.362 \n2 Under $30,000     Rent        90 0.638 \n3 $30,000 - $59,999 Own        105 0.565 \n4 $30,000 - $59,999 Rent        81 0.435 \n5 $60,000 - $99,999 Own        107 0.552 \n6 $60,000 - $99,999 Rent        87 0.448 \n7 $100,000 or more  Own        160 0.930 \n8 $100,000 or more  Rent        12 0.0698"
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#exercise-4",
    "href": "lectures/05/05-explore-numerical-filled-in.html#exercise-4",
    "title": "Explore numerical data",
    "section": "Exercise 4",
    "text": "Exercise 4\nOne of the questions on the survey is “How satisfied are you with the overall quality of services provided by the city?” A response of 1 indicates Very Dissatisfied and a response of 5 indicates Very Satisfied. The responses for this question are in the variable qos_city. This could be considered an ordinal, categorical variable but can also be treated as a numerical variable in an analysis. Let’s do the latter!\nVisualize and describe the distribution of qos_city. If you get a warning with your visualization, comment on what it means.\n\nggplot(durham, aes(x = qos_city)) + \n  geom_histogram(binwidth =  1) +\n  labs(\n    x = \"Quality of services provided by the city\\n 1 - Very Dissatisfied, 5 - Very Satisfied\"\n  )\n\nWarning: Removed 75 rows containing non-finite values (`stat_bin()`)."
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#exercise-5",
    "href": "lectures/05/05-explore-numerical-filled-in.html#exercise-5",
    "title": "Explore numerical data",
    "section": "Exercise 5",
    "text": "Exercise 5\nCalculate the mean and median of the distribution of qos_city. If these values are not exactly the same, can you explain what the difference might be attributed to?\n\ndurham |&gt;\n  summarize(\n    mean_qos_city = mean(qos_city, na.rm = TRUE),\n    median_qos_city = median(qos_city, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 2\n  mean_qos_city median_qos_city\n          &lt;dbl&gt;           &lt;dbl&gt;\n1          3.54               4\n\n\n\nMore rare responses of “1 - Very dissatisfied” pull the mean response down away from the median."
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#exercise-6",
    "href": "lectures/05/05-explore-numerical-filled-in.html#exercise-6",
    "title": "Explore numerical data",
    "section": "Exercise 6",
    "text": "Exercise 6\nBased on the shape of the distribution of qos_city, which measure of spread (variability) is more appropriate? Calculate that value and interpret it in context of the data.\n\ndurham |&gt; \n  summarise(\n    iqr_qos_city = IQR(qos_city, na.rm = T),\n    q1_qos_city = quantile(qos_city, 0.25, na.rm = T),\n    q3_qos_city = quantile(qos_city, 0.75, na.rm = T)\n  )\n\n# A tibble: 1 × 3\n  iqr_qos_city q1_qos_city q3_qos_city\n         &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n1            1           3           4"
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#exercise-7",
    "href": "lectures/05/05-explore-numerical-filled-in.html#exercise-7",
    "title": "Explore numerical data",
    "section": "Exercise 7",
    "text": "Exercise 7\nMake a box plot of qos_city and comment on how the values you calculated map on to the box plot.\n\nggplot(durham, aes(x = qos_city)) + \n  geom_boxplot() +\n  labs(\n    x = \"Quality of service provided by the city\\n 1 - Very Dissatisfied, 5 - Very Satisfied\"\n  )\n\nWarning: Removed 75 rows containing non-finite values (`stat_boxplot()`)."
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#exercise-8",
    "href": "lectures/05/05-explore-numerical-filled-in.html#exercise-8",
    "title": "Explore numerical data",
    "section": "Exercise 8",
    "text": "Exercise 8\nHow the average level of happiness with quality of services provided by the city vary by income group?\nStretch goal: Visualize mean qos_city by income group.\nAdd your response here.\n\ndurham |&gt;\n  drop_na(income_clean) |&gt;\n  group_by(income_clean) |&gt;\n  summarize(\n    mean_qos_city = mean(qos_city, na.rm = TRUE),\n    median_qos_city = median(qos_city, na.rm = TRUE)\n  )\n\n# A tibble: 4 × 3\n  income_clean      mean_qos_city median_qos_city\n  &lt;fct&gt;                     &lt;dbl&gt;           &lt;dbl&gt;\n1 Under $30,000              3.45               4\n2 $30,000 - $59,999          3.50               4\n3 $60,000 - $99,999          3.56               4\n4 $100,000 or more           3.72               4\n\n\n\ndurham |&gt;\n  drop_na(income_clean) |&gt;\n  group_by(income_clean) |&gt;\n  summarize(\n    mean_qos_city = mean(qos_city, na.rm = TRUE)\n  ) |&gt;\n  ggplot(aes(x = income_clean, y = mean_qos_city)) +\n  geom_point()"
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#conceptual",
    "href": "lectures/05/05-explore-numerical-filled-in.html#conceptual",
    "title": "Explore numerical data",
    "section": "Conceptual",
    "text": "Conceptual\nSome of the terms we introduced are:\n\nMarginal distribution: Distribution of a single variable.\nConditional distribution: Distribution of a variable conditioned on the values (or levels, in the context of categorical data) of another."
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#r",
    "href": "lectures/05/05-explore-numerical-filled-in.html#r",
    "title": "Explore numerical data",
    "section": "R",
    "text": "R\nIn this lecture we:\n\nDefined factors – the data type that R uses for categorical variables, i.e., variables that can take on values from a finite set of levels.\nReviewed data imports, visualization, and wrangling functions encountered before:\n\nImport: read_csv(): Read data from a CSV (comma separated values) file\nVisualization:\n\nggplot(): Create a plot using the ggplot2 package\naes(): Map variables from the data to aesthetic elements of the plot, generally passed as an argument to ggplot() or to geom_*() functions (define only x or y aesthetic)\ngeom_bar(): Represent data with bars, after calculating heights of bars under the hood\ngeom_histogram(): Represent data with a histogram\ngeom_boxplot(): Represent data with a box plot\ngeom_point(): Represent data with points\nlabs(): Label x axis, y axis, legend for color of plot, title` of plot, etc.\n\nWrangling:\n\nmutate(): Mutate the data frame by creating a new column or overwriting one of the existing columns\ncount(): Count the number of observations for each level of a categorical variable (factor) or each distinct value of any other type of variable\ngroup_by(): Perform each subsequent action once per each group of the variable, where groups can be defined based on the levels of one or more variables\nsummarize(): Calculate summary statistics\n\n\nIntroduced new data wrangling functions:\n\nrename(): Rename columns in a data frame\nas_factor(): Convert a variable to a factor\ndrop_na(): Drop rows that have NA in one ore more specified variables\nif_else(): Write logic for what happens if a condition is true and what happens if it’s not\ncase_when(): Write a generalized if_else() logic for more than one condition\nfct_relevel: Change the order of levels in a factor\n\nIntroduced new data visualization functions:\n\ngeom_col(): Represent data with bars (columns), for heights that have already been calculated (must define x and y aesthetics)\nscale_fill_viridis_d(): Customize the discrete fill scale, using a color-blind friendly, ordinal discrete color scale\nscale_y_discrete(): Customize the discrete y scale\nscale_fill_manual(): Customize the fill scale by manually adjusting values for colors"
  },
  {
    "objectID": "lectures/05/05-explore-numerical-filled-in.html#quarto",
    "href": "lectures/05/05-explore-numerical-filled-in.html#quarto",
    "title": "Explore numerical data",
    "section": "Quarto",
    "text": "Quarto\nWe also introduced chunk options for managing figure sizes:\n\nfig-width: Width of figure\nfig-asp: Aspect ratio of figure (height / width)\nfig-height: Height of figure – but I recommend using fig-width and fig-asp, instead of fig-width and fig-height"
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html",
    "href": "lectures/17/17-inference-twoway-tables.html",
    "title": "Inference for two-way tables",
    "section": "",
    "text": "Peer review due Sunday at 11:59 pm\nMonday lab: I will talk to each of you individually for about 15 minutes about the project.\nMake sure to read chapters 16 and 17 in the text book (specifically mathematical model section)"
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html#announcements",
    "href": "lectures/17/17-inference-twoway-tables.html#announcements",
    "title": "Inference for two-way tables",
    "section": "",
    "text": "Peer review due Sunday at 11:59 pm\nMonday lab: I will talk to each of you individually for about 15 minutes about the project.\nMake sure to read chapters 16 and 17 in the text book (specifically mathematical model section)"
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html#so-far",
    "href": "lectures/17/17-inference-twoway-tables.html#so-far",
    "title": "Inference for two-way tables",
    "section": "So far:",
    "text": "So far:\n\nSingle proportion: 1 categorical variable with 2 levels (“success” vs “failure”).\nDifference in proportions: 2 categorical variables with 2 levels each (“success” vs “failure” and group 1 vs group 2).\n\n\n\n\n\n\n\nNote\n\n\n\nSuppose we have a categorical variable with 3 response levels. How do we define “success”?\nWhat is a difference in proportions in this setting?\n\n\nIn such setting, a difference across two groups is not sufficient, and the proportion of “success” is not well defined if there are 3 or 4 or more possible response levels. The primary way to summarize categorical data where the explanatory and response variables both have 2 or more levels is through a two-way table.\nNote that with two-way tables, there is not an obvious single parameter of interest. Instead, research questions usually focus on how the proportions of the response variable changes (or not) across the different levels of the explanatory variable."
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html#exercise-1",
    "href": "lectures/17/17-inference-twoway-tables.html#exercise-1",
    "title": "Inference for two-way tables",
    "section": "Exercise 1",
    "text": "Exercise 1\nLoad the data.\n\ncandidate_talk = read_csv(\"candidate-talk.csv\")"
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html#exercise-2",
    "href": "lectures/17/17-inference-twoway-tables.html#exercise-2",
    "title": "Inference for two-way tables",
    "section": "Exercise 2",
    "text": "Exercise 2\nCreate a two-way table of the issues across parties and visualize the frequency distribution.\n\n# add code here"
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html#exercise-3",
    "href": "lectures/17/17-inference-twoway-tables.html#exercise-3",
    "title": "Inference for two-way tables",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhich do you think should be the explanatory variable and which the response variable? Accordingly, create a visualization that shows the correct conditional probabilities.\n\n# add code here\n\nYou should also be asking yourself: could we see these results due to chance alone if there really is no difference in the party affiliation, or is this in fact evidence that parties find different issues to be of interest?"
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html#exercise-4",
    "href": "lectures/17/17-inference-twoway-tables.html#exercise-4",
    "title": "Inference for two-way tables",
    "section": "Exercise 4",
    "text": "Exercise 4\nState the hypotheses for evaluating whether the issue of choice is independent of party affiliation.\nAdd response here."
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html#exercise-5",
    "href": "lectures/17/17-inference-twoway-tables.html#exercise-5",
    "title": "Inference for two-way tables",
    "section": "Exercise 5",
    "text": "Exercise 5\nCalculate the observed sample statistic.\n\n# add code here"
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html#exercise-6",
    "href": "lectures/17/17-inference-twoway-tables.html#exercise-6",
    "title": "Inference for two-way tables",
    "section": "Exercise 6",
    "text": "Exercise 6\nConduct the hypothesis test using randomization and visualize and report the p-value.\n\n# add code here"
  },
  {
    "objectID": "lectures/17/17-inference-twoway-tables.html#exercise-7",
    "href": "lectures/17/17-inference-twoway-tables.html#exercise-7",
    "title": "Inference for two-way tables",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhat is the conclusion of the hypothesis test?\nAdd response here."
  },
  {
    "objectID": "exam_review/exam-review.html",
    "href": "exam_review/exam-review.html",
    "title": "Exam 1 Review",
    "section": "",
    "text": "In 2020, employees of Blizzard Entertainment circulated a spreadsheet to anonymously share salaries and recent pay increases amidst rising tension in the video game industry over wage disparities and executive compensation. (Source: Blizzard Workers Share Salaries in Revolt Over Pay)\nThe name of the data frame used for this analysis is blizzard_salary and the relevant variables are:\nThe top six rows of blizzard_salary are shown below:\n# A tibble: 409 × 4\n   percent_incr salary_type annual_salary performance_rating\n          &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n 1          1   Salaried               1  High              \n 2          1   Salaried               1  Successful        \n 3          1   Salaried               1  High              \n 4          1   Hourly             33987. Successful        \n 5         NA   Hourly             34798. High              \n 6         NA   Hourly             35360  &lt;NA&gt;              \n 7         NA   Hourly             37440  &lt;NA&gt;              \n 8          0   Hourly             37814. &lt;NA&gt;              \n 9          4   Hourly             41101. Top               \n10          1.2 Hourly             42328  &lt;NA&gt;              \n# ℹ 399 more rows"
  },
  {
    "objectID": "exam_review/exam-review.html#question-1",
    "href": "exam_review/exam-review.html#question-1",
    "title": "Exam 1 Review",
    "section": "Question 1",
    "text": "Question 1\nHow rows observations are there in the blizzard_salary dataset and what does each row represent?"
  },
  {
    "objectID": "exam_review/exam-review.html#question-2",
    "href": "exam_review/exam-review.html#question-2",
    "title": "Exam 1 Review",
    "section": "Question 2",
    "text": "Question 2\nFigure 1 (a) and Figure 1 (b) show the distributions of annual salaries of hourly and salaried workers. The two figures show the same data, with the facets organized across rows and across columns. Which of the two figures is better for comparing the median annual salaries of hourly and salaried workers. Explain your reasoning.\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\nFigure 1: Distribution of annual salaries of Blizzard employees"
  },
  {
    "objectID": "exam_review/exam-review.html#question-3",
    "href": "exam_review/exam-review.html#question-3",
    "title": "Exam 1 Review",
    "section": "Question 3",
    "text": "Question 3\nSuppose your teammate wrote the following code as part of their analysis of the data.\nThey then printed out the results shown below. Unfortunately one of the number got erased from the printout, it’s indicated with _____ below.\n# A tibble: 2 × 3\n  salary_type mean_annual_salary median_annual_salary\n  &lt;chr&gt;                    &lt;dbl&gt;                &lt;dbl&gt;\n1 Hourly                  63003.               54246.\n2 Salaried                90183.               _____\nWhich of the following is the best estimate for that erased value?\n\n30,000\n50,000\n80,000\n100,000"
  },
  {
    "objectID": "exam_review/exam-review.html#question-4",
    "href": "exam_review/exam-review.html#question-4",
    "title": "Exam 1 Review",
    "section": "Question 4",
    "text": "Question 4\nWhich distribution has a higher standard deviation?\n\nHourly workers\nSalaried workers\nRoughly the same"
  },
  {
    "objectID": "exam_review/exam-review.html#question-5",
    "href": "exam_review/exam-review.html#question-5",
    "title": "Exam 1 Review",
    "section": "Question 5",
    "text": "Question 5\nWhich of the following alternate plots would also be useful for visualizing the distributions of annual salaries of hourly and salaried workers?\nI.  Box plot\nII. Density plot\nIII. Pie chart\n\nI\nI and II\nI, II, and III\nII and III"
  },
  {
    "objectID": "exam_review/exam-review.html#question-6",
    "href": "exam_review/exam-review.html#question-6",
    "title": "Exam 1 Review",
    "section": "Question 6",
    "text": "Question 6\nNext, you fit a model for predicting raises (percent_incr) from salaries (annual_salary). We’ll call this model raise_1_fit. A tidy output of the model is shown below.\n\n\n# A tibble: 2 × 5\n  term           estimate  std.error statistic   p.value\n  &lt;chr&gt;             &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   1.87      0.432           4.33 0.0000194\n2 annual_salary 0.0000155 0.00000452      3.43 0.000669 \n\n\nWhich of the following is the best interpretation of the slope coefficient?\n\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.55%.\nFor every additional $1,000 of annual salary, the raise goes up by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.87%."
  },
  {
    "objectID": "exam_review/exam-review.html#question-7",
    "href": "exam_review/exam-review.html#question-7",
    "title": "Exam 1 Review",
    "section": "Question 7",
    "text": "Question 7\nYou then fit a model for predicting raises (percent_incr) from salaries (annual_salary) and performance ratings (performance_rating). We’ll call this model raise_2_fit. Which of the following is definitely true based on the information you have so far?\n\nIntercept of raise_2_fit is higher than intercept of raise_1_fit.\nRMSE of raise_2_fit is higher than RMSE of raise_1_fit.\nAdjusted \\(R^2\\) of raise_2_fit is higher than adjusted \\(R^2\\) of raise_1_fit.\n\\(R^2\\) of raise_2_fit is higher \\(R^2\\) of raise_1_fit."
  },
  {
    "objectID": "exam_review/exam-review.html#question-8",
    "href": "exam_review/exam-review.html#question-8",
    "title": "Exam 1 Review",
    "section": "Question 8",
    "text": "Question 8\nThe tidy model output for the raise_2_fit model you fit is shown below.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic  p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                   3.55       0.508           6.99 1.99e-11\n2 annual_salary                 0.00000989 0.00000436      2.27 2.42e- 2\n3 performance_ratingPoor       -4.06       1.42           -2.86 4.58e- 3\n4 performance_ratingSuccessful -2.40       0.397          -6.05 4.68e- 9\n5 performance_ratingTop         2.99       0.715           4.18 3.92e- 5\n\n\nWhen your teammate sees this model output, they remark “The coefficient for performance_ratingSuccessful is negative, that’s weird. I guess it means that people who get successful performance ratings get lower raises.” How would you respond to your teammate?"
  },
  {
    "objectID": "exam_review/exam-review.html#question-9",
    "href": "exam_review/exam-review.html#question-9",
    "title": "Exam 1 Review",
    "section": "Question 9",
    "text": "Question 9\nUltimately, your teammate decides they don’t like the negative slope coefficients in the model output you created (not that there’s anything wrong with negative slope coefficients!), does something else, and comes up with the following model output.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic    p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)                  -0.511      1.47          -0.347 0.729     \n2 annual_salary                 0.00000989 0.00000436     2.27  0.0242    \n3 performance_ratingSuccessful  1.66       1.42           1.17  0.242     \n4 performance_ratingHigh        4.06       1.42           2.86  0.00458   \n5 performance_ratingTop         7.05       1.53           4.60  0.00000644\n\n\nUnfortunately they didn’t write their code in a Quarto document, instead just wrote some code in the Console and then lost track of their work. They remember using the fct_relevel() function and doing something like the following:\nWhat should they put in the blanks to get the same model output as above?\n\n“Poor”, “Successful”, “High”, “Top”\n“Successful”, “High”, “Top”\n“Top”, “High”, “Successful”, “Poor”\nPoor, Successful, High, Top"
  },
  {
    "objectID": "exam_review/exam-review.html#question-10",
    "href": "exam_review/exam-review.html#question-10",
    "title": "Exam 1 Review",
    "section": "Question 10",
    "text": "Question 10\nFinally, your teammate creates the following two plots and ask you for help deciding which one to use in the final report for visualizing the relationship between performance rating and salary type. In 1-3 sentences, can you help them make a decision, justify your choice, and write the narrative that should go with the plot?\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\nFigure 2: Distribution of salary type by performance rating"
  },
  {
    "objectID": "exam_review/exam-review.html#question-11",
    "href": "exam_review/exam-review.html#question-11",
    "title": "Exam 1 Review",
    "section": "Question 11",
    "text": "Question 11\nA friend with a keen eye points out that the number of observations in Figure 2 (a) seems lower than the total number of observations in blizzard_salary. What might be going on here? Explain your reasoning."
  },
  {
    "objectID": "exam_review/exam-review.html#question-12",
    "href": "exam_review/exam-review.html#question-12",
    "title": "Exam 1 Review",
    "section": "Question 12",
    "text": "Question 12\nShow the proportions of performance ratings for hourly and salaried workers in a table and ask students to place those numbers on the segments of Figure 2 (b).\n\n\n# A tibble: 4 × 3\n  performance_rating Hourly Salaried\n  &lt;fct&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1 Successful          0.686   0.521 \n2 High                0.2     0.384 \n3 Top                 0.114   0.0760\n4 Poor                0       0.0190"
  },
  {
    "objectID": "exam_review/exam-review.html#question-13",
    "href": "exam_review/exam-review.html#question-13",
    "title": "Exam 1 Review",
    "section": "Question 13",
    "text": "Question 13\nSuppose we fit a model to predict percent_incr from annual_salary and salary_type. A tidy output of the model is shown below.\n\n\n# A tibble: 3 × 5\n  term                 estimate  std.error statistic p.value\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)         1.24      0.570           2.18 0.0300 \n2 annual_salary       0.0000137 0.00000464      2.96 0.00329\n3 salary_typeSalaried 0.913     0.544           1.68 0.0938 \n\n\nWhich of the following visualizations represent this model? Explain your reasoning.\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Option 3\n\n\n\n\n\n\n\n\n\n\n\n(d) Option 4\n\n\n\n\n\n\n\nFigure 3: Visualizations of the relationship between percent increase, annual salary, and salary type"
  },
  {
    "objectID": "exam_review/exam-review.html#question-14",
    "href": "exam_review/exam-review.html#question-14",
    "title": "Exam 1 Review",
    "section": "Question 14",
    "text": "Question 14\nA professor gives a test to 100 students and determines the median score. After grading the test, they realize that the 10 students with the highest scores did exceptionally well. They decide to award these 10 students a bonus of 5 more points. The median of the new score distribution will be ____ the original median.\n\n, depending on skewness, higher or lower than\nequal to\nlower than\nhigher than"
  },
  {
    "objectID": "exam_review/exam-review.html#question-15",
    "href": "exam_review/exam-review.html#question-15",
    "title": "Exam 1 Review",
    "section": "Question 15",
    "text": "Question 15\nSuppose we want to modify the release_country variable such that the levels are “United States” and “not United States”. Fill in the blanks in the code chunk below to accomplish this.\n\nmovies____________movies |&gt;\n      ____________(\n        release_country = if_else(\n        release_country____________\"United States\", \n        \"____________\",\n        \"____________\"\n        )\n)"
  },
  {
    "objectID": "exam_review/exam-review.html#question-16",
    "href": "exam_review/exam-review.html#question-16",
    "title": "Exam 1 Review",
    "section": "Question 16",
    "text": "Question 16\nA researcher wants to build a multiple linear regression model to predict the score of a movie in from runtime for the movies in different types of genre.\nThe total sum of squares for the model \\(SS_{Total}\\) is found to be 0. You know that:\n\nevery runtime in every genre had the same amount\nevery movie had the same score\nthe model perfectly predicts score in every movie\nthe mean score must be 0"
  },
  {
    "objectID": "exam_review/exam-review.html#question-17",
    "href": "exam_review/exam-review.html#question-17",
    "title": "Exam 1 Review",
    "section": "Question 17",
    "text": "Question 17\nChoose the best answer.\nA survey based on a random sample of 2,045 American teenagers found that a 95% confidence interval for the mean number of texts sent per month was (1450, 1550). A valid interpretation of this interval is\n\n95% of all teens who text send between 1450 and 1550 text messages per month.\nIf a new survey with the same sample size were to be taken, there is a 95% chance that the mean number of texts in the sample would be between 1450 and 1550.\nWe are 95% confident that the mean number of texts per month of all American teens is between 1450 and 1550.\nWe are 95% confident that, were we to repeat this survey, the mean number of texts per month of those taking part in the survey would be between 1450 and 1550."
  },
  {
    "objectID": "exam_review/exam-review.html#question-18",
    "href": "exam_review/exam-review.html#question-18",
    "title": "Exam 1 Review",
    "section": "Question 18",
    "text": "Question 18\n\nWrite the theoretical model that regresses weight on m_age, weeks, and premature. Be sure to define each term (i.e., \\(y= -----\\)).\n\nThen, using the output below, write the fitted model.\n\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic     p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 (Intercept)      -4.35      2.10       -2.07 0.0404     \n2 m_age             0.0270    0.0142      1.90 0.0594     \n3 weeks             0.281     0.0509      5.52 0.000000153\n4 prematurepremie  -1.01      0.398      -2.54 0.0121     \n\n\n\nInterpret the intercept, in 1 sentence.\n\n\nInterpret the slope for premie, in 1 sentence."
  },
  {
    "objectID": "exam_review/exam-review.html#bonus",
    "href": "exam_review/exam-review.html#bonus",
    "title": "Exam 1 Review",
    "section": "Bonus",
    "text": "Bonus\nPick a concept we introduced in class so far that you’ve been struggling with and explain it in your own words."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#teaching-team",
    "href": "lectures_slides/01/01-welcome.html#teaching-team",
    "title": "Welcome to STA 101",
    "section": "Teaching team",
    "text": "Teaching team\n\n\nInstructor\nKat Husar\nOld Chem 406\nkat.husar@duke.edu\n\nTeaching assistant\nJohn Gillen\njohn.gillen@duke.edu"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#timetable",
    "href": "lectures_slides/01/01-welcome.html#timetable",
    "title": "Welcome to STA 101",
    "section": "Timetable",
    "text": "Timetable\n\nLectures at Perk LINK 087 (Classroom 3): Mon - Fri 11:00 - 12:15 pm\nLabs at Perkins LINK 087 (Classroom 3): Mon + Thu 9:30 - 10:45 am"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#learning-objectives",
    "href": "lectures_slides/01/01-welcome.html#learning-objectives",
    "title": "Welcome to STA 101",
    "section": "Learning objectives",
    "text": "Learning objectives\n\nRecognize the importance of data collection, identify limitations in data collection methods, and determine how they affect the scope of inference.\nUse statistical software to summarize data numerically and visually, and to perform data analysis.\nHave a conceptual understanding of the unified nature of statistical inference.\nApply estimation and testing methods to analyze single variables or the relationship between two variables in order to understand natural phenomena and make data-based decisions.\nModel numerical response variables using a single or multiple explanatory variables.\nInterpret results correctly, effectively, and in context without relying on statistical jargon.\nCritique data-based claims and evaluate data-based decisions.\nComplete research projects demonstrating mastery of statistical data analysis from exploratory analysis to inference to modeling."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#course-website",
    "href": "lectures_slides/01/01-welcome.html#course-website",
    "title": "Welcome to STA 101",
    "section": "Course website",
    "text": "Course website\n\nsta101-su2024.github.io\n\n\naka “the one link to rule them all”"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#lectures",
    "href": "lectures_slides/01/01-welcome.html#lectures",
    "title": "Welcome to STA 101",
    "section": "Lectures",
    "text": "Lectures\n\nIn person\nAttendance is required (as long as you’re healthy!)\nA little bit of everything:\n\nTraditional lecture\nLive coding + demos\nShort exercises + solution discussion"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#labs",
    "href": "lectures_slides/01/01-welcome.html#labs",
    "title": "Welcome to STA 101",
    "section": "Labs",
    "text": "Labs\n\nAttendance is required (as long as you’re healthy!)\nOpportunity to work on course assignments\nOpportunity to work on a project"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#announcements",
    "href": "lectures_slides/01/01-welcome.html#announcements",
    "title": "Welcome to STA 101",
    "section": "Announcements",
    "text": "Announcements\n\nPosted on Canvas (Announcements) and sent via email, be sure to check both regularly\nI’ll assume that you’ve read an announcement by the next “business” day"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#diversity-and-inclusion",
    "href": "lectures_slides/01/01-welcome.html#diversity-and-inclusion",
    "title": "Welcome to STA 101",
    "section": "Diversity and inclusion",
    "text": "Diversity and inclusion\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength and benefit.\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know! Add your name pronunciation to your Canvas and Slack profiles.\nPlease let me know your preferred pronouns and add these to your Canvas and Slack profiles.\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. I want to be a resource for you. If you prefer to speak with someone outside of the course, your advisers and deans are excellent resources.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please talk to me about it."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#accessibility",
    "href": "lectures_slides/01/01-welcome.html#accessibility",
    "title": "Welcome to STA 101",
    "section": "Accessibility",
    "text": "Accessibility\n\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments.\nWe will have in class exams. If you need special accommodations, please book the testing center ASAP!\nI am committed to making all course materials accessible and I’m always learning how to do this better. If any course component is not accessible to you in any way, please don’t hesitate to let me know."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#attendance-participation-5",
    "href": "lectures_slides/01/01-welcome.html#attendance-participation-5",
    "title": "Welcome to STA 101",
    "section": "Attendance + participation (5%)",
    "text": "Attendance + participation (5%)\n\nRequired throughout the semester in lecture and lab\nStudents who attend at least 80% of the lectures and participate regularly in lecture and/or other course venues (discussion board) will receive full credit for the lecture attendance\nYou are allowed to miss 2 lab meetings without penalty.\nLecture and lab attendance will be equally weighted in the final attendace grade calculation.\n\n\n\n\n\n\n\nTip\n\n\nIf you attend at least 80% of the lectures and miss at most 2 lab meetings, you’ll get all available points for this component."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#labs-35",
    "href": "lectures_slides/01/01-welcome.html#labs-35",
    "title": "Welcome to STA 101",
    "section": "Labs (35%)",
    "text": "Labs (35%)\n\nSubmitted on Gradescope, individual, can discuss with classmates\nLab sessions allocated to working on assignments\nDue by 11:59 pm ET on the indicated day on the course schedule\n\n\n\n\n\n\n\nTip\n\n\nLowest lab score is dropped, whether it’s an actual low score or a 0 from not turning it in."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#exam",
    "href": "lectures_slides/01/01-welcome.html#exam",
    "title": "Welcome to STA 101",
    "section": "Exam",
    "text": "Exam\n\nOne exams, each 30%\nThe exam comprised of two parts:\n\nIn class: 75 minute in-class exam. Closed book, one sheet of notes (“cheat sheet”, no larger than 8 1/2 x 11, both sides, must be prepared by you) – 70% of the grade\nTake home: 48 hours to complete the take home portion. The take home portion will follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam – 30% of the grade\n\n\n\n\n\n\n\n\nCaution\n\n\nExam dates cannot be changed and no make-up exams will be given. If you can’t take the exams on these dates, you should drop this class."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#project",
    "href": "lectures_slides/01/01-welcome.html#project",
    "title": "Welcome to STA 101",
    "section": "Project",
    "text": "Project\n\nProject (30%)\n\nDataset of your choice, method of your choice\nPresentation and write-up\nPresentations on the lass class date\n\nInterim deadlines\nSome lab sessions allocated to working on projects and getting feedback from the instructor\n\n\n\n\n\n\n\nCaution\n\n\nFinal presentation date cannot be changed. If you can’t present on that date, you should drop this class."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#late-work-policy",
    "href": "lectures_slides/01/01-welcome.html#late-work-policy",
    "title": "Welcome to STA 101",
    "section": "Late work policy",
    "text": "Late work policy\n\nLabs:\n\nLate, but within 24 hours of deadline: -20% of available points\nAny later: No credit, and we will not provide written feedback\nNote that lowest lab score will be dropped, even if that score is a 0\n\nProject submissions:\n\nProposal late, but within 24 hours of deadline: -20% of available points\nAny later: No credit, and we will not provide written feedback\n\nProject presentation: Late submissions not accepted\n\n\n\n\n\n\n\nCaution\n\n\nNo late submissions on the final report."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#collaboration-policy",
    "href": "lectures_slides/01/01-welcome.html#collaboration-policy",
    "title": "Welcome to STA 101",
    "section": "Collaboration policy",
    "text": "Collaboration policy\n\nExams must be completed individually, you may not discuss answers with teammates, clarification questions should only be asked to myself and the TAs\nLabs must be completed individually. You may not directly share answers / code with others, however you are welcome to discuss the problems in general and ask for advice"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#sharing-reusing-code-policy",
    "href": "lectures_slides/01/01-welcome.html#sharing-reusing-code-policy",
    "title": "Welcome to STA 101",
    "section": "Sharing / reusing code policy",
    "text": "Sharing / reusing code policy\n\nWe are aware that a huge volume of code is available on the web, and many tasks may have solutions posted\nUnless explicitly stated otherwise, this course’s policy is that you may make use of any online resources (e.g., StackOverflow) but you must explicitly cite where you obtained any code you directly use or use as inspiration in your solution(s)\nAny recycled code that is discovered and is not explicitly cited will be treated as plagiarism, regardless of source"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#generative-ai-policy",
    "href": "lectures_slides/01/01-welcome.html#generative-ai-policy",
    "title": "Welcome to STA 101",
    "section": "Generative AI policy",
    "text": "Generative AI policy\nYou should treat generative AI, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:1\n(1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning.\n(2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#academic-integrity",
    "href": "lectures_slides/01/01-welcome.html#academic-integrity",
    "title": "Welcome to STA 101",
    "section": "Academic integrity",
    "text": "Academic integrity\nTo uphold the Duke Community Standard:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\nmost importantly:\nask if you’re not sure if something violates a policy!"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#wellness",
    "href": "lectures_slides/01/01-welcome.html#wellness",
    "title": "Welcome to STA 101",
    "section": "Wellness",
    "text": "Wellness\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded."
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#rstudio",
    "href": "lectures_slides/01/01-welcome.html#rstudio",
    "title": "Welcome to STA 101",
    "section": "RStudio",
    "text": "RStudio\n\nhttps://cmgr.oit.duke.edu/containers\n\n\nRequires internet connection to access\nProvides consistency in hardware and software environments\nLocal R installations are fine but we will not guarantee support"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#discussion-board",
    "href": "lectures_slides/01/01-welcome.html#discussion-board",
    "title": "Welcome to STA 101",
    "section": "Discussion Board",
    "text": "Discussion Board\n\nOn Canvas\nAsk and answer questions related to course logistics, assignment, etc. here\nPersonal questions (e.g., extensions, illnesses, etc.) should be via email to me"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#to-do-before-1",
    "href": "lectures_slides/01/01-welcome.html#to-do-before-1",
    "title": "Welcome to STA 101",
    "section": "To do before…",
    "text": "To do before…\nthe next class tomorrow\n\nRead the syllabus\nComplete the Getting to know you survey\nComplete the readings"
  },
  {
    "objectID": "lectures_slides/01/01-welcome.html#un-votes",
    "href": "lectures_slides/01/01-welcome.html#un-votes",
    "title": "Welcome to STA 101",
    "section": "UN Votes",
    "text": "UN Votes\n\nGo to Container and upload the document titled unvotes.qmd. Review the narrative and the data visualization you just created. Then, change “Turkey” to another country of your choice. Re-render the document. Show the plot you created to your neighbor and discuss (1) why you chose that country and (2) how this new visualization is different than the original (and what that says about country politics, if anything).\nTime permitting: How were these data collected?\n\n\n\n\n\n🔗 sta101-su2024.github.io"
  },
  {
    "objectID": "course-team.html",
    "href": "course-team.html",
    "title": "Teaching team",
    "section": "",
    "text": "Kat Husar (she/her) - Hi everyone! I am a second year PhD student at the Department of Statistical Science at Duke University working with professors Alex Volfovsky and Fan Li. My research interest lies in causal inference.\nPrior to starting at Duke, I completed my undergraduate degree at The Ohio State University majoring in mathematics and data analytics.\nDuring my free time, I like to go on walks, hang out with my friends, bake, and spend time with my cat.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMon, Wed, & Fri: 3:30 - 4:30 pm\nOld Chem 203B",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#instructor",
    "href": "course-team.html#instructor",
    "title": "Teaching team",
    "section": "",
    "text": "Kat Husar (she/her) - Hi everyone! I am a second year PhD student at the Department of Statistical Science at Duke University working with professors Alex Volfovsky and Fan Li. My research interest lies in causal inference.\nPrior to starting at Duke, I completed my undergraduate degree at The Ohio State University majoring in mathematics and data analytics.\nDuring my free time, I like to go on walks, hang out with my friends, bake, and spend time with my cat.\n\n\n\nOffice hours\nLocation\n\n\n\n\nMon, Wed, & Fri: 3:30 - 4:30 pm\nOld Chem 203B",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "course-team.html#teaching-assistant",
    "href": "course-team.html#teaching-assistant",
    "title": "Teaching team",
    "section": "Teaching assistant",
    "text": "Teaching assistant\n\nJohn Gillen - Hello! I’m a second-year student in the Master of Statistical Science program here at Duke. I completed undergraduate degrees in statistics and mathematics at UC Riverside, and am hoping to pursue a PhD in statistics after completing my Master’s degree.\nOutside of school, I enjoy playing tennis, running, and reading.\n\n\n\nOffice hours\nLocation\n\n\n\n\nSun: 10 - 11 am\nZoom",
    "crumbs": [
      "Course information",
      "Teaching team"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html",
    "href": "labs/lab3/lab-3.html",
    "title": "Lab 3",
    "section": "",
    "text": "The goal of this lab is to effectively visualize numerical and categorical data.\nFor all visualizations you create, be sure to include informative titles for the plot, axes, and legend!",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-1",
    "href": "labs/lab3/lab-3.html#exercise-1",
    "title": "Lab 3",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nHow many observations and how many variables are in the dataset? Use inline code to answer this question. What does each row represent?",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-2",
    "href": "labs/lab3/lab-3.html#exercise-2",
    "title": "Lab 3",
    "section": "Exercise 2",
    "text": "Exercise 2\nThere are some observations in this dataset that we will exclude from our analysis to match the Buzzfeed results.\n\nCreate a new data frame called nobel_living that filters for\n\nlaureates for whom country is available: !is.na(country)\nlaureates who are people as opposed to organizations, i.e., organizations are denoted with \"org\" as their gender: gender != \"org\"\nlaureates who are still alive, i.e., their died_date is NA: is.na(died_date)\n\nConfirm that once you have filtered for these characteristics you are left with a data frame with 228 observations, once again using inline code.\n\n\n\nMost living Nobel laureates were based in the US when they won their prizes\n\n… says the Buzzfeed article. Let’s see if that’s true.\nFirst, we’ll create a new variable to identify whether the laureate was in the US when they won their prize. We’ll use the mutate() function for this. The following pipeline mutates the nobel_living data frame by adding a new variable called country_us. We use an if statement to create this variable. The first argument in the if_else() function we’re using to write this if statement is the condition we’re testing for. If country is equal to \"USA\", we set country_us to \"USA\". If not, we set the country_us to \"Other\".\n\nnobel_living &lt;- nobel_living |&gt;\n  mutate(\n    country_us = if_else(country == \"USA\", \"USA\", \"Other\")\n  )\n\nNext, we will limit our analysis to only the following categories: Physics, Medicine, Chemistry, and Economics.\n\nnobel_living_science &lt;- nobel_living |&gt;\n  filter(category %in% c(\"Physics\", \"Medicine\", \"Chemistry\", \"Economics\"))\n\nFor the following exercises, work with the nobel_living_science data frame you created above. This means you’ll need to define this data frame in your Quarto document, even though the next exercise doesn’t explicitly ask you to do so.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-3",
    "href": "labs/lab3/lab-3.html#exercise-3",
    "title": "Lab 3",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nCreate a faceted bar plot visualizing the relationship between the category of prize and whether the laureate was in the US when they won the nobel prize. Interpret your visualization, and say a few words about whether the Buzzfeed headline is supported by the data.\n\nYour visualization should be faceted by category.\nFor each facet you should have two bars, one for winners in the US and one for Other.\nFlip the coordinates so the bars are horizontal, not vertical.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-4",
    "href": "labs/lab3/lab-3.html#exercise-4",
    "title": "Lab 3",
    "section": "Exercise 4",
    "text": "Exercise 4\nNext, let’s investigate, of those US-based Nobel laureates, what proportion were born in other countries.\n\nCreate a new variable called born_country_us in nobel_living_science that has the value \"USA\" if the laureate is born in the US, and \"Other\" otherwise. How many of the winners are born in the US?",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-5",
    "href": "labs/lab3/lab-3.html#exercise-5",
    "title": "Lab 3",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nAdd a second variable to your visualization from Exercise 3 based on whether the laureate was born in the US or not.\nCreate two visualizations with this new variable added:\n\nPlot 1: Segmented frequency bar plot\nPlot 2: Segmented relative frequency bar plot (Hint: Add position = \"fill\" to geom_bar().)\n\nHere are some instructions that apply to both of these visualizations:\n\nYour final visualization should contain a facet for each category.\nWithin each facet, there should be two bars for whether the laureate won the award in the US or not.\nEach bar should have segments for whether the laureate was born in the US or not.\n\nWhich of these visualizations is a better fit for answering the following question: “Do the data appear to support Buzzfeed’s claim that of those US-based Nobel laureates, many were born in other countries?” First, state which plot you’re using to answer the question. Then, answer the question, explaining your reasoning in 1-2 sentences.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-6",
    "href": "labs/lab3/lab-3.html#exercise-6",
    "title": "Lab 3",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nIn a single pipeline, filter the nobel_living_science data frame for laureates who won their prize in the US, but were born outside of the US, and then create a frequency table (with the count() function) for their birth country (born_country) and arrange the resulting data frame in descending order of number of observations for each country. Which country is the most common?",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-7",
    "href": "labs/lab3/lab-3.html#exercise-7",
    "title": "Lab 3",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nIMS - Chapter 4 exercises, #4: Raise taxes.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-8",
    "href": "labs/lab3/lab-3.html#exercise-8",
    "title": "Lab 3",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nIMS - Chapter 5 exercises, #4: Office productivity.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-9",
    "href": "labs/lab3/lab-3.html#exercise-9",
    "title": "Lab 3",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nIMS - Chapter 5 exercises, #16: Distributions and appropriate statistics.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#exercise-10",
    "href": "labs/lab3/lab-3.html#exercise-10",
    "title": "Lab 3",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nIMS - Chapter 5 exercises, #26: NYC marathon winners.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#submitting",
    "href": "labs/lab3/lab-3.html#submitting",
    "title": "Lab 3",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-3.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TA can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab3/lab-3.html#grading",
    "href": "labs/lab3/lab-3.html#grading",
    "title": "Lab 3",
    "section": "Grading",
    "text": "Grading\n\n\n\nExercise\nPoints\n\n\n\n\nExercise 1\n3\n\n\nExercise 2\n4\n\n\nExercise 3\n8\n\n\nExercise 4\n6\n\n\nExercise 5\n8\n\n\nExercise 6\n8\n\n\nExercise 7\n2\n\n\nExercise 8\n2\n\n\nExercise 9\n5\n\n\nExercise 10\n4\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 3"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html",
    "href": "labs/lab7/lab-7.html",
    "title": "Lab 7",
    "section": "",
    "text": "By the end of this lab you will construct and interpret confidence intervals via bootstrapping.\nFor all visualizations you create, be sure to include informative titles for the plot, axes, and legend!",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-1",
    "href": "labs/lab7/lab-7.html#exercise-1",
    "title": "Lab 7",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nLoad the lemurs data save it as lemurs. Then, report which “types” of lemurs are represented in the sample and how many of each. Note that this information is in the taxon variable. You should refer back to the linked data dictionary to understand what the different values of taxon mean.\n\n\n\n\n\n\n\nPause and render\n\n\n\nNow that you’ve completed your first exercise, pause and render your document. If it renders without any issues, great! Move on to the next exercise. If it does not, debug the issue before moving on. Ask for help from your TA if you need. Do not proceed without rendering your document.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-2",
    "href": "labs/lab7/lab-7.html#exercise-2",
    "title": "Lab 7",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nWhat is the mean weight of ring-tailed lemurs? Calculate, visualize, and interpret a 95% bootstrap confidence interval together with your point estimate. Use set.seed(123) and reps = 1000 to create your bootstrap confidence interval.\n\nHints:\nBelow is a step-by-step recipe for constructing and visualizing a confidence interval. The code snippets shown are not “complete”, they’re intended to guide you in the right direction.\n\nStep 1: Create a dataset of ring-tailed lemurs, and call it lemurs_rt. Note, these are taxon == \"LCAT\".\nStep 2: Calculate the mean weight of ring-tailed lemurs.\n\n\nobs_stat_mean_rt &lt;- lemurs_rt |&gt;\n  specify(response = weight_g) |&gt;\n  calculate(stat = \"mean\")\n\n\nStep 3: Construct a bootstrap distribution. Note: There is a generate() step, so you also need to set a seed before running the following.\n\n\nboot_dist_mean_rt &lt;- lemurs_rt |&gt;\n  specify(response = weight_g) |&gt;\n  generate(reps = 1000, type = \"bootstrap\") |&gt;\n  calculate(stat = \"mean\")\n\n\nStep 4: Calculate the bounds of the confidence interval. Don’t forget to interpret it as well!\n\n\nci_95_mean_rt &lt;- boot_dist_mean_rt |&gt;\n  get_confidence_interval(\n    point_estimate = obs_stat_mean_rt, \n    level = 0.95\n  )\n\n\nStep 5: Visualize the confidence interval, overlaying it on the bootstrap distribution.\n\n\nvisualize(boot_dist_mean_rt) +\n  shade_confidence_interval(endpoints = ci_95_mean_rt)",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-3",
    "href": "labs/lab7/lab-7.html#exercise-3",
    "title": "Lab 7",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nWhat is the median weight of ring-tailed lemurs? What is the median weight of mongoose lemurs? Report a 95% bootstrap confidence interval together with your point estimates. Use set.seed(123) and reps = 10000 to create your bootstrap confidence intervals.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-4",
    "href": "labs/lab7/lab-7.html#exercise-4",
    "title": "Lab 7",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nYour friend has never taken a statistics course. Describe to your friend the process of “bootstrap sampling” in the previous exercise to create a bootstrap confidence interval in your own words. Walk your friend through the process of collecting a bootstrap sample, computing a statistic and then repeating). You may find it helpful to describe it as drawing pieces of paper from a bag like we did in class.\n\nHint: What would you write on the slips of paper? How many pieces of paper would be in the bag(s)? How many bag(s) would you need for the above exercise?",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-5",
    "href": "labs/lab7/lab-7.html#exercise-5",
    "title": "Lab 7",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nDo female lemurs differ in weight from male lemurs? Report the difference in mean weights between groups. Next, construct a 99% bootstrap distribution for the difference in means between groups and interpret it. If the interval covers 0, you might think there is no difference between groups. Does the interval cover 0? Use set.seed(123) and reps = 10000.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-6",
    "href": "labs/lab7/lab-7.html#exercise-6",
    "title": "Lab 7",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nCreate a new column that tells you whether or not a lemur was born in the first or second half of the year (January through June vs July through December). Create a meaningful plot to illustrate the weights of each group of lemurs. Use theme_bw() to replace the default gray plot background. Based on your figure, which group of lemurs weighs more? Is the distribution of one or both groups skewed or symmetric? See here for more information about skew vs symmetric distributions.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-7",
    "href": "labs/lab7/lab-7.html#exercise-7",
    "title": "Lab 7",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nIs there more variability in weight for lemurs born in the first half or second half of the year? Report the estimated standard deviation of each group. Report a 90% bootstrap confidence interval of s.d. for each group. Interpret the confidence intervals in context. Use set.seed(123) and remember to set reps = 10000.\n\n\n\n\n\n\n\nPause and render\n\n\n\nNow that you’ve completed a few more exercises, pause and render your document. If it renders without any issues, great! Move on to the next exercise. If it does not, debug the issue before moving on. Ask for help from your TA if you need. Do not proceed without rendering your document.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-8",
    "href": "labs/lab7/lab-7.html#exercise-8",
    "title": "Lab 7",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nIMS - Chapter 12 exercises, #2: Chronic illness.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-9",
    "href": "labs/lab7/lab-7.html#exercise-9",
    "title": "Lab 7",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nIMS - Chapter 12 exercises, #6: Bootstrap distributions of \\(\\hat{p}\\), III.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#exercise-10",
    "href": "labs/lab7/lab-7.html#exercise-10",
    "title": "Lab 7",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nIMS - Chapter 12 exercises, #8: Waiting at an ER.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#submitting",
    "href": "labs/lab7/lab-7.html#submitting",
    "title": "Lab 7",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-7.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TAs can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab7/lab-7.html#grading",
    "href": "labs/lab7/lab-7.html#grading",
    "title": "Lab 7",
    "section": "Grading",
    "text": "Grading\n\n\n\nExercise\nPoints\n\n\n\n\nExercise 1\n3\n\n\nExercise 2\n6\n\n\nExercise 3\n7\n\n\nExercise 4\n5\n\n\nExercise 5\n5\n\n\nExercise 6\n7\n\n\nExercise 7\n8\n\n\nExercise 8\n3\n\n\nExercise 9\n3\n\n\nExercise 10\n3\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 7"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html",
    "href": "labs/lab4/lab-4.html",
    "title": "Lab 4",
    "section": "",
    "text": "By the end of this lab you will create and fit regression models with a single predictor and visualize a simple regression model.\nFor all visualizations you create, b sure to include informative titles for the plot, axes, and legend!",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-1",
    "href": "labs/lab4/lab-4.html#exercise-1",
    "title": "Lab 4",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nLet’s begin by taking a look at the squat lifting records.\nTo begin, remove any observations that are negative for squat. Next, create a new column called best3_squat_lbs that converts the record from kg to lbs (you may have to google the conversion). Save your data frame as ipf_squat. Report the number of rows and columns of this new data frame using inline code.\n\n\n\n\n\n\n\nHint\n\n\n\nFirst, you’re taking a dataset and filtering it for certain records, and then you’re mutate-ing that dataset to gain a new column, and you’re assigning the resulting dataset to a new object called ipf_squat.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-2",
    "href": "labs/lab4/lab-4.html#exercise-2",
    "title": "Lab 4",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nUsing ipf_squat from the previous exercise, create a scatter plot to investigate the relationship between squat (in lbs) and age. Age should be on the x-axis. Adjust the alpha level of your points to get a better sense of the density of the data. Add a linear trend-line. Be sure to label all axes and give the plot a title. Comment on what you observe.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-3",
    "href": "labs/lab4/lab-4.html#exercise-3",
    "title": "Lab 4",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nWrite down the linear model to predict lift squat lbs from age in \\(x\\), \\(y\\), \\(\\beta\\) notation. What is \\(x\\)? What is \\(y\\)? Next, fit the linear model, and save it as age_fit. Re-write your previous equation replacing \\(\\beta\\) with the numeric estimates. This is called the “fitted” linear model. Interpret each estimate of \\(\\beta\\). Are the interpretations sensible?",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-4",
    "href": "labs/lab4/lab-4.html#exercise-4",
    "title": "Lab 4",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nBuilding on your ipf_squat data frame, create a new column called age2 that takes the age of each lifter and squares it. Save it to your data frame ipf_squat. Next, plot squat in lbs vs age2 and add a linear best fit line. Does this model look like it fits the data better?\n\n\n\n\n\n\n\nHint\n\n\n\nTo raise a value to a power, use ^ in R, e.g.: 2 ^ 2 gives you 4, 2 ^ 3 gives you 8, etc.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-5",
    "href": "labs/lab4/lab-4.html#exercise-5",
    "title": "Lab 4",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nOne metric to assess the fit of a model is the correlation squared, also known as \\(R^2\\). Fit the age\\(^2\\) model and save the object as age2_fit. Subsequently run\n\nglance(age2_fit)$r.squared\n\nto examine the \\(R^2\\). Compare \\(R^2\\) of the age\\(^2\\) model to the \\(R^2\\) of the model from Exercise 3. Which has a higher \\(R^2\\)?\n\n\n\n\n\n\n\nNote\n\n\n\n\\(R^2\\) values range from 0 to 1. Values close to 0 means weak correlation between the variables whereas \\(R^2 = 1\\) implies perfect correlation. You can (optionally) read more about \\(R^2\\) in section 7.2.5 of the book. We’ll pick up here in the next class.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-6",
    "href": "labs/lab4/lab-4.html#exercise-6",
    "title": "Lab 4",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nNext, let’s turn our attention to dead lifting records.\nRecreate the plot below. Make sure axes and title labels are exactly matching, including spelling, capitalization, etc. Based on the plot below, which impacts deadlift weight more, age category or sex?\n\n\n\n\n\n\n\nHint\n\n\n\nYou will need to create a couple of new columns. One to classify age appropriately and one to convert best3deadlift_kg to the plotted units (lbs). Notice that there are no negative deadlift values on the x-axis.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-7",
    "href": "labs/lab4/lab-4.html#exercise-7",
    "title": "Lab 4",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nFinally, let’s turn our attention to bench press records.\nTo begin, remove any observations that are negative for bench press, create two new columns: best3bench_lbs and bodyweight_lbs. Save the result in a new data frame called ipf_bench.\nThen, create a scatter plot to investigate the relationship between best bench press (in lbs) and the lifter’s bodyweight (in lbs). Bodyweight should be on the x-axis. Add a linear trend-line. Be sure to label all axes and give the plot a title. Comment on what you observe.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-8",
    "href": "labs/lab4/lab-4.html#exercise-8",
    "title": "Lab 4",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nFit the linear model displayed in the previous exercise and write down the fitted model equation only, replacing \\(\\hat{\\beta}\\)s with their fitted estimates. Interpret the \\(\\hat{\\beta}\\)s (intercept and slope). Report \\(R^2\\). Is body weight an important predictor of bench press ability? Why or why not?",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-9",
    "href": "labs/lab4/lab-4.html#exercise-9",
    "title": "Lab 4",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nIMS - Chapter 7 exercises, #18: Over-under, II.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#exercise-10",
    "href": "labs/lab4/lab-4.html#exercise-10",
    "title": "Lab 4",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nIMS - Chapter 7 exercises, #24: Cats weights.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#submitting",
    "href": "labs/lab4/lab-4.html#submitting",
    "title": "Lab 4",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-3.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TAs can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab4/lab-4.html#grading",
    "href": "labs/lab4/lab-4.html#grading",
    "title": "Lab 4",
    "section": "Grading",
    "text": "Grading\n\n\n\nExercise\nPoints\n\n\n\n\nExercise 1\n3\n\n\nExercise 2\n5\n\n\nExercise 3\n5\n\n\nExercise 4\n5\n\n\nExercise 5\n5\n\n\nExercise 6\n8\n\n\nExercise 7\n6\n\n\nExercise 8\n7\n\n\nExercise 9\n4\n\n\nExercise 10\n2\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 4"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html",
    "href": "labs/lab6/lab-6.html",
    "title": "Lab 6",
    "section": "",
    "text": "Critiquing visualizations that misrepresent data\nImproving data visualizations to better convey the right message",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html#packages",
    "href": "labs/lab6/lab-6.html#packages",
    "title": "Lab 6",
    "section": "Packages",
    "text": "Packages\nWe’ll use the tidyverse package for much of the data wrangling and visualization.\n\nlibrary(tidyverse)",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html#data",
    "href": "labs/lab6/lab-6.html#data",
    "title": "Lab 6",
    "section": "Data",
    "text": "Data\nIn this lab you’ll construct the data set!",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html#exercise-1",
    "href": "labs/lab6/lab-6.html#exercise-1",
    "title": "Lab 6",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nWhat is misleading about this visualization and how you might go about fixing it?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html#exercise-2",
    "href": "labs/lab6/lab-6.html#exercise-2",
    "title": "Lab 6",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nCreate a data frame that can be used to re-construct this visualization. You may need to guess some of the numbers, that’s ok. You should first think about how many rows and columns you’ll need and what you want to call your variables. Then, you can use the tribble() function for this. For example, if you wanted to construct the following data frame\n\ndf &lt;- tribble(\n  ~date, ~\"mask\", ~\"no mask\",\n  \"1/1/2020\", 15, 20,\n  \"2/1/2020\", 20, 18,\n  \"3/1/2020\", 22, 23\n)\n\nYou can create the data frame below. Print the first 5 rows of the data frame after creating it. You may name the data frame what you like. We often try and keep data frame names small and informative.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html#exercise-3",
    "href": "labs/lab6/lab-6.html#exercise-3",
    "title": "Lab 6",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nMake a visualization that more accurately (and honestly) tells the story. (Hint: use pivot_longer() function to change the shape of your dataset so that it has three colums: date, count, and county_type).",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html#exercise-4",
    "href": "labs/lab6/lab-6.html#exercise-4",
    "title": "Lab 6",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nWhat message is more clear in your visualization than it was in the original visualization?",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html#exercise-5",
    "href": "labs/lab6/lab-6.html#exercise-5",
    "title": "Lab 6",
    "section": "Exercise 5",
    "text": "Exercise 5\n\n\nWhat, if any, useful information do these data and your visualization tell us about mask wearing and COVID? Answers should focus only on what the visualization tells.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html#submitting",
    "href": "labs/lab6/lab-6.html#submitting",
    "title": "Lab 6",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-6.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TA can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "labs/lab6/lab-6.html#grading",
    "href": "labs/lab6/lab-6.html#grading",
    "title": "Lab 6",
    "section": "Grading",
    "text": "Grading\n\n\n\nComponent\nPoints\n\n\n\n\nEx 1\n5\n\n\nEx 2\n5\n\n\nEx 3\n15\n\n\nEx 4\n5\n\n\nEx 5\n5\n\n\nTotal\n35",
    "crumbs": [
      "Labs",
      "Lab 6"
    ]
  },
  {
    "objectID": "course-faq.html",
    "href": "course-faq.html",
    "title": "FAQ",
    "section": "",
    "text": "The short answer is, I’d rather you didn’t, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.3.1: https://cran.r-project.org\nDownload and install the preview build of RStudio: https://posit.co/download/rstudio-desktop\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "course-faq.html#can-i-use-a-local-install-of-posit-cloud",
    "href": "course-faq.html#can-i-use-a-local-install-of-posit-cloud",
    "title": "FAQ",
    "section": "",
    "text": "The short answer is, I’d rather you didn’t, to save yourself some headache. But, the long answer is, sure! But you will need to install a specific versions of R and RStudio for everything to work as expected. You will also need to install the R packages we’re using as well as have Git installed on your computer. These are not extremely challenging things to get right, but they are not trivial either, particularly on certain operating systems. Myself and the TAs are always happy to provide help with any computational questions when you’re working in the containers we have provided for you. If you’re working on your local setup, we can’t guarantee being able to resolve your issues, though we’re happy to try.\nIf you want to take this path, here is what you need to do:\n\nDownload and install R 4.3.1: https://cran.r-project.org\nDownload and install the preview build of RStudio: https://posit.co/download/rstudio-desktop\nInstall any necessary packages with install.packages(\"___\")\n\nAnd I’d like to reiterate again that successful installation of these software is not a learning goal of this course. So if any of this seems tedious or intimidating in any way, just use the computing environment we have set up for you. More on that here.",
    "crumbs": [
      "Course information",
      "FAQ"
    ]
  },
  {
    "objectID": "project/project.html",
    "href": "project/project.html",
    "title": "Project",
    "section": "",
    "text": "The deliverable for this project (what you will turn in) is a written report and a presentation. See below for more details.",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "project/project.html#criteria-for-datasets",
    "href": "project/project.html#criteria-for-datasets",
    "title": "Project",
    "section": "Criteria for datasets",
    "text": "Criteria for datasets\nThe data sets should meet the following criteria:\n\nAt least 100 observations\nAt least 5 columns\nAt least 4 of the columns must be useful and unique explanatory variables.\n\nIdentifier variables such as “name”, “social security number”, etc. are not useful explanatory variables.\nIf you have multiple columns with the same information (e.g. “state abbreviation” and “state name”), then they are not unique explanatory variables.\n\nYou may not use data that has previously been used in course, or any derivation of data that has been used in course materials (this or previous semesters of STA101).\n\n\n\n\n\n\n\nTip\n\n\n\nPlease ask a member of the teaching team if you’re unsure whether your data set meets the criteria.\n\n\nIf you set your hearts on a dataset that has fewer observations or variables than what’s suggested here, that might still be ok; use these numbers as guidance for a successful proposal, not as minimum requirements.",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "project/project.html#resources",
    "href": "project/project.html#resources",
    "title": "Project",
    "section": "Resources for datasets",
    "text": "Resources for datasets\nYou can find data wherever you like, but here are some recommendations to get you started. You shouldn’t feel constrained to datasets that are already in a tidy format, you can start with data that needs cleaning and tidying, scrape data off the web, or collect your own data.\n\nAwesome public datasets\nBikeshare data portal\nCDC\nData.gov\nData is Plural\nDurham Open Data Portal\nEdinburgh Open Data\nElection Studies\nEuropean Statistics\nCORGIS: The Collection of Really Great, Interesting, Situated Datasets\nGeneral Social Survey\nGoogle Dataset Search\nHarvard Dataverse\nInternational Monetary Fund\nIPUMS survey data from around the world\nLos Angeles Open Data\nNational Crime Victimization Survey\nNHS Scotland Open Data\nNYC OpenData\nOpen access to Scotland’s official statistics\nPew Research\nPRISM Data Archive Project\nStatistics Canada\nThe National Bureau of Economic Research\nTidyTuesday\nUCI Machine Learning Repository\nUK Government Data\nUNICEF Data\nUnited Nations Data\nUnited Nations Statistics Division\nUS Census Data\nUS Government Data\nWorld Bank Data\nYouth Risk Behavior Surveillance System (YRBSS)",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "project/project.html#proposal-grading",
    "href": "project/project.html#proposal-grading",
    "title": "Project",
    "section": "Proposal grading",
    "text": "Proposal grading\nEach component will be graded as follows:\n\nMeets expectations (full credit): Two (or more) data sets and research questions are identified. There is a plan for completing the project as envisioned.\nClose to expectations (half credit): Only one data set and/or research question identified. The plan for completing the project as envisioned is not well designed.\nDoes not meet expectations (no credit): No dataset or research question identified. There is no plan for completing the project as envisioned.\n\nEven if you earn full credit, it may not mean that your proposal is perfect.\n\n\n\n\n\n\nImportant\n\n\n\nYou will only be working with one of the data sets for your project. I ask you to find two or more to have a back-up plan in case I don’t think the first data set will result in a successful project.",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "project/project.html#intro-eda-grading",
    "href": "project/project.html#intro-eda-grading",
    "title": "Project",
    "section": "Intro + EDA grading",
    "text": "Intro + EDA grading\nYou will be graded on whether you incorporated the feedback from project proposal submission as well as whether the requirements listed above have been completed. Even if you earn full credit, it may not mean that your submission is perfect. I expect you to incorporate the feedback in the final report submission.",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "project/project.html#components",
    "href": "project/project.html#components",
    "title": "Project",
    "section": "Components",
    "text": "Components\nYou should include, at a minimum, the following sections in your report.\n\nIntroduction (10 pts)\nThe introduction provides motivation and context for your research. Write 1-2 paragraphs of background information to motivate your research question. Your writing should answer the question: “Why is this work important? What might the broader implications be?” You must cite at least two additional references to adequately support your motivation.\nThen introduce the data set in a few short sentences. What is the source of the data, how were the data collected, and what general information is contained in the data set? How many observations and variables do you have? Next, create a code book (aka a “data dictionary”) of the variables in the data set. Specifically, only include in your report a code book of the variables that you use.\nComplete the introduction by providing a concise, clear statement of your research question and hypotheses. Be sure to motivate why the research question is interesting/useful.\nExample research question and hypotheses (if we were predicting penguin weights instead of baby weights):\nCan we predict body mass with bill depth? We hypothesize that penguins with deeper bills will also have more mass.\n\n\nMethodology (15 pts)\nHere you should introduce any statistical methods you use and describe why you choose the methods you do to answer your question. This is where you might want to include any preliminary summary statistics or figures you use to explore the data. Your EDA should be supporting your choice of statistical methods (ex. if you don’t observe linear trend, you should not be fitting a linear model).\n\n\nResults (15 pts)\nPlace figure(s) here to illustrate the main results from your analysis. 1 beautiful figure is worth more than several poorly formatted figures. You must have at least 1 figure.\nProvide only the main results from your analysis. The goal is not to do an exhaustive data analysis (calculate every possible statistic and create every possible model for all variables). Rather, you should demonstrate that you are proficient at asking meaningful questions and answering them using data, that you are skilled in writing about and interpreting results, and that you can accomplish these tasks using R. More is not better.\n\n\nDiscussion (5 pts)\nThis section is a conclusion and discussion. You should\n\nSummarize your main finding in a sentence or two.\nDiscuss your finding and why it is useful (put in the context of your motivation from the introduction).\nCritique your own analyses and include a brief paragraph on what you would do differently if you were able to start the project over.\n\n\n\nFormatting (5 pts)\nYour project should be professionally formatted. For example, this means labeling graphs and figures, turning off code chunks, using proper citations and cross-references, and following typical style guidelines.",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "project/project.html#submission",
    "href": "project/project.html#submission",
    "title": "Project",
    "section": "Submission",
    "text": "Submission\n\nUpload the PDF submission to Gradescope.\nAssociate all pages with “Full report”.",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "project/project.html#slides",
    "href": "project/project.html#slides",
    "title": "Project",
    "section": "Slides",
    "text": "Slides\nFor your presentation, you must create presentation slides that summarize and showcase your project. Introduce your research question and data set, showcase visualizations, and provide some conclusions. These slides should serve as a brief visual accompaniment to your write-up and will be graded for content and quality.\nHere is a suggested outline as you think through the slides; you do not have to use this exact format for the slide deck.\n\nTitle Slide\nSlide 1: Introduce the topic and motivation\nSlide 2: Introduce the data\nSlide 3 - 4: Highlights from exploratory data analysis\nSlide 4 - 5: Highlights from inference and/or modeling\nSlide 6: Conclusions + critique/shortcomings\n\nYou can create your slides with any software you like (Keynote, PowerPoint, Google Slides, etc.).",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "project/project.html#grading-summary",
    "href": "project/project.html#grading-summary",
    "title": "Project",
    "section": "Grading summary",
    "text": "Grading summary\nGrading of the project will take into account the following:\n\nContent - What is the quality of research and/or policy question and relevancy of data to those questions?\nCorrectness - Are statistical procedures carried out and explained correctly?\nWriting and Presentation - What is the quality of the statistical presentation, writing, and explanations?\nCreativity and Critical Thought - Is the project carefully thought out? Are the limitations carefully considered? Does it appear that time and effort went into the planning and implementation of the project?\n\nA general breakdown of scoring is as follows:\n\n90%-100%: Outstanding effort. Student understands how to apply all statistical concepts, can put the results into a cogent argument, can identify weaknesses in the argument, and can clearly communicate the results to others.\n80%-89%: Good effort. Student understands most of the concepts, puts together an adequate argument, identifies some weaknesses of their argument, and communicates most results clearly to others.\n70%-79%: Passing effort. Student has misunderstanding of concepts in several areas, has some trouble putting results together in a cogent argument, and communication of results is sometimes unclear.\n60%-69%: Struggling effort. Student is making some effort, but has misunderstanding of many concepts and is unable to put together a cogent argument. Communication of results is unclear.\nBelow 60%: Student is not making a sufficient effort.",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "project/project.html#late-work-policy",
    "href": "project/project.html#late-work-policy",
    "title": "Project",
    "section": "Late work policy",
    "text": "Late work policy\nBe sure to turn in your work early to avoid any technological mishaps.\n\n\n\n\n\n\nWarning\n\n\n\nThere is no late work accepted on the final report and presentation.",
    "crumbs": [
      "Project",
      "Project"
    ]
  },
  {
    "objectID": "course-support.html",
    "href": "course-support.html",
    "title": "Course support",
    "section": "",
    "text": "Most of you will need help at some point and we want to make sure you can identify when that is without getting too frustrated and feel comfortable seeking help.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#lectures-and-labs",
    "href": "course-support.html#lectures-and-labs",
    "title": "Course support",
    "section": "Lectures and labs",
    "text": "Lectures and labs\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#office-hours",
    "href": "course-support.html#office-hours",
    "title": "Course support",
    "section": "Office hours",
    "text": "Office hours\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours during the times posted on the home page to ask questions about the course content and assignments. A lot of questions are most effectively answered in-person, so office hours are a valuable resource. I encourage each and every one of you to take advantage of this resource! Make a pledge to stop by office hours at least once during the first three weeks of class. If you truly have no questions to ask, just stop by and say hi and introduce yourself. You can find a list of everyone’s office hours here.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#discussion-board",
    "href": "course-support.html#discussion-board",
    "title": "Course support",
    "section": "Discussion Board",
    "text": "Discussion Board\nHave a question that can’t wait for office hours? Prefer to write out your question in detail rather than asking in person? The course Discussion Board on Canvas is the best venue for these! There is a chance another student has already asked a similar question, so please check the other posts before asking a new question. If you know the answer to a question that is posted, I encourage you to respond!",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#email",
    "href": "course-support.html#email",
    "title": "Course support",
    "section": "Email",
    "text": "Email\nPlease refrain from emailing any course content questions (those should go to discussion board), and only use email for questions about personal matters that may not be appropriate for the public course forum (e.g., illness, accommodations, etc.). For such matters, you may email Kat Husar at kat.husar@duke.edu.\nIf there is a question that’s not appropriate for the public forum, you are welcome to email me directly. If you email me, please include “STA 101” in the subject line. Barring extenuating circumstances, I will respond to STA 101 emails within 24 hours Monday - Friday. Response time may be slower for emails sent Friday evening - Sunday.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#academic-support",
    "href": "course-support.html#academic-support",
    "title": "Course support",
    "section": "Academic support",
    "text": "Academic support\nThere are times may need help with the class that is beyond what can be provided by the teaching team. In those instances, I encourage you to visit the Academic Resource Center. The Academic Resource Center (ARC) offers free services to all students during their undergraduate careers at Duke. Services include Learning Consultations, Peer Tutoring and Study Groups, ADHD/LD Coaching, Outreach Workshops, and more. Because learning is a process unique to every individual, they work with each student to discover and develop their own academic strategy for success at Duke. Contact the ARC to schedule an appointment. Undergraduates in any year, studying any discipline can benefit! Contact ARC@duke.edu, 919-684-5917.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#mental-health-and-wellness",
    "href": "course-support.html#mental-health-and-wellness",
    "title": "Course support",
    "section": "Mental health and wellness",
    "text": "Mental health and wellness\nStudent mental health and wellness are of primary importance at Duke, and the university offers resources to support students in managing daily stress and self-care. Duke offers several resources for students to seek assistance on coursework and to nurture daily habits that support overall well-being, some of which are listed below.\n\nThe Academic Resource Center: (919) 684-5917, theARC@duke.edu, or arc.duke.edu.\nDuWell: (919) 681-8421, provides Moments of Mindfulness (stress management and resilience building) and meditation programming to assist students in developing a daily emotional well-being practice. To see schedules for programs please see https://studentaffairs.duke.edu/duwell. All are welcome and no experience necessary.\n\nIf your mental health concerns and/or stressful events negatively affect your daily emotional state, academic performance, or ability to participate in your daily activities, many resources are available to help you through difficult times. Duke encourages all students to access these resources.\n\nDukeReach: Provides comprehensive outreach services to identify and support students in managing all aspects of well-being. If you have concerns about a student’s behavior or health visit the website for resources and assistance: http://studentaffairs.duke.edu/dukereach.\nCounseling and Psychological Services (CAPS): CAPS services include individual and group counseling services, psychiatric services, and workshops. To initiate services, walk-in/call-in 9-4 M,W,Th,F and 9-6 Tuesdays. CAPS also provides referral to off-campus resources for specialized care. (919) 660-1000 or https://students.duke.edu/wellness/caps.\nTimelyCare: (formerly known as Blue Devils Care) An online platform that is a convenient, confidential, and free way for Duke students to receive 24/7 mental health support through TalkNow and scheduled counseling: https://bluedevilscare.duke.edu.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#course-costs",
    "href": "course-support.html#course-costs",
    "title": "Course support",
    "section": "Course costs",
    "text": "Course costs\n\nTextbooks: The textbooks for this course are freely available on the web.\nLaptops: Each student is expected to have a laptop they can bring to each lecture and lab.\n\nIf you are having difficulty with costs associated with this course, here are some resources:\n\nContact the financial aid office (whether or not you are on aid). They have loans and resources for connecting students with programs on campus that might be able to help alleviate these costs.\nDukeLIFE offers course materials assistance for eligible students. Please note that students who are eligible for DukeLIFE benefits are notified prior to the start of the semester; program resources are limited.\nDuke Libraries offers textbook rentals through the Top Textbook Program, where you can rent out a textbook for 3 hours at a time.\nFor course-specific technology needs such as Digital Voice Recorder, HD Video Camera, TI-84 Plus CE, DSLR camera kit, Tripod, Shotgun Mic, iPad Mini 4, a Handheld Projector, or a GoPro, you can reserve rental equipment from the Link.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-support.html#assistance-with-canvas-and-zoom",
    "href": "course-support.html#assistance-with-canvas-and-zoom",
    "title": "Course support",
    "section": "Assistance with Canvas and Zoom",
    "text": "Assistance with Canvas and Zoom\nFor technical help with Canvas or Zoom, contact the Duke OIT Service Desk at oit.duke.edu/help. You can also access the self-service help documentation for Zoom here and for Canvas here.\nZoom will be used for online office hours as well as as a backup option should we need to hold the course online instead of in person.",
    "crumbs": [
      "Course information",
      "Support"
    ]
  },
  {
    "objectID": "course-overview.html",
    "href": "course-overview.html",
    "title": "Course overview",
    "section": "",
    "text": "This is the homepage for STA 101 - Data Analysis and Statistical Inference taught by Kat Husar in Summer 2024 at Duke University. All course materials will be posted on this site.\nYou can find the course syllabus here and the course schedule here.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#class-meetings",
    "href": "course-overview.html#class-meetings",
    "title": "Course overview",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLectures\nPerkins LINK 087 (Classroom 3)\nMon- Fri 11:00 - 12:15 pm\n\n\nLab\nPerkins LINK 087 (Classroom 3)\nMon, Thu 9:30 - 10:45 am",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#acknowledgement",
    "href": "course-overview.html#acknowledgement",
    "title": "Course overview",
    "section": "Acknowledgement",
    "text": "Acknowledgement\nThank you Dr. Mine Çetinkaya-Rundel for class material and help preparing the course and setting up this website.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "course-overview.html#license",
    "href": "course-overview.html#license",
    "title": "Course overview",
    "section": "License",
    "text": "License\n\nThis online work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International. Visit here for more information about the license.",
    "crumbs": [
      "Course information",
      "Overview"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html",
    "href": "labs/lab1/lab-1.html",
    "title": "Lab 1: Hello R!",
    "section": "",
    "text": "The goal of this lab is to acquaint you with R (the computing language), RStudio (the IDE, integrated development environment), and Posit Cloud (the browser based service we will use to access RStudio).",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#yaml",
    "href": "labs/lab1/lab-1.html#yaml",
    "title": "Lab 1: Hello R!",
    "section": "YAML",
    "text": "YAML\nThe top portion of your Quarto Markdown file (aka .qmd), you’ll find three dashed lines. Between the dashed lines is called YAML. YAML stands for “Yet Another Markup Language”. It is a human friendly data serialization standard for all programming languages. All you need to know is that this area is called the YAML (we will refer to it as such) and that it contains meta information about your document.\nChange the author name to your name and update the date with today’s date. Click the Render to render the document. What do you notice?\n\n\n\n\n\n\nNote\n\n\n\nTo avoid issues that can occur while rendering, it is a good idea to render early and often. At least after every exercise.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#packages",
    "href": "labs/lab1/lab-1.html#packages",
    "title": "Lab 1: Hello R!",
    "section": "Packages",
    "text": "Packages\nIn this lab we will work with three packages: the tidyverse package which is a collection of packages for doing data analysis in a “tidy” way, the datasauRus package which contains the data set for the first part of your lab.\n\nlibrary(tidyverse) \nlibrary(datasauRus)\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you are using R on Duke Containers, packages we use should already be installed and only need to be loaded with the function library(). If you are using a local version of R you probably have to run the following code in the console to install the packages (one time only!)\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"datasauRus\")",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-1",
    "href": "labs/lab1/lab-1.html#exercise-1",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nBased on the help file, how many rows and how many columns does the datasaurus_dozen file have? What are the variables included in the data frame? Add your responses to your lab report under “Exercise 1”.\n\nLet’s take a look at the names of the data sets inside of datasaurus_dozen. To do so this, we can make a frequency table of the “data set” variable. Run the code chunk below. Note: when you run the code chunk below, a table “prints” to the screen. In general, we say “print to screen” to mean that the output of your code should show up on your screen (when asked to ‘print to screen’ in an assignment, you should make sure the output displays in your rendered document).\n\ndatasaurus_dozen |&gt;\n  count(dataset)\n\n# A tibble: 13 × 2\n   dataset        n\n   &lt;chr&gt;      &lt;int&gt;\n 1 away         142\n 2 bullseye     142\n 3 circle       142\n 4 dino         142\n 5 dots         142\n 6 h_lines      142\n 7 high_lines   142\n 8 slant_down   142\n 9 slant_up     142\n10 star         142\n11 v_lines      142\n12 wide_lines   142\n13 x_shape      142\n\n\nThe original Datasaurus (dino) data was created by Alberto Cairo. The other Dozen were generated using simulated annealing and the process is described in the paper Same Stats, Different Graphs: Generating data sets with Varied Appearance and Identical Statistics through Simulated Annealing by Justin Matejka and George Fitzmaurice. In the paper, the authors simulate a variety of data sets that have the same summary statistics as the original Datasaurus but have very different data.\n\n\n\n\n\n\nNote\n\n\n\nYou can view the whole data frame by running the code view(datasaurus_dozen) in the console. This will open the data frame in a new tab. Try it out!",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-2",
    "href": "labs/lab1/lab-1.html#exercise-2",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nPlot y vs. x for the dino data set. Then, calculate the correlation coefficient between x and y for this data set. Make sure that this value is printed in your document.\n\nBelow is the code you will need to complete this exercise. Basically, the answer is already given, but you need to include relevant bits in your .qmd document and successfully render it and view the results.\nStart with the datasaurus_dozen and pipe it into the filter function to filter for observations where dataset == \"dino\". Store the resulting filtered data frame as a new data frame called dino_data.\n\ndino_data &lt;- datasaurus_dozen |&gt;\n  filter(dataset == \"dino\")\n\nThere is a lot going on here, so let’s slow down and unpack it a bit.\nFirst, the pipe operator: |&gt;, takes what comes before it and sends it as the first argument to what comes after it. So here, we’re saying filter the datasaurus_dozen data frame for observations where dataset == \"dino\".\nSecond, the assignment operator: &lt;-, assigns the name dino_data to the filtered data frame.\n\n\n\n\n\n\nNote\n\n\n\nNote in R you may use either &lt;- or = for an assignment operator. We’ll use &lt;- in this class as it’s the more commonly used assignment operator, but when you look for R help online, you might see = being used as well.\n\n\nNext, we need to visualize these data. We will use the ggplot function for this. Its first argument is the data you’re visualizing. Next we define the aesthetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the x axis will represent the variable called x and the y axis will represent the variable called y. Then, we add another layer to this plot where we define which geometric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence geom_point.\n\nggplot(dino_data, aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\n\n\n\n\nFor the second part of this exercise, we need to calculate a summary statistic: the correlation coefficient. The correlation coefficient (r) measures the strength and direction of the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate r only if relevant.\nIn this case, calculating a correlation coefficient really doesn’t make sense since the relationship between x and y is definitely not linear, but is instead more ‘dinosaur-esque’.\nFor illustrative purposes only, let’s calculate the correlation coefficient between x and y.\n\ndino_data |&gt;\n  summarize(r = cor(x, y))\n\n# A tibble: 1 × 1\n        r\n    &lt;dbl&gt;\n1 -0.0645",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-3",
    "href": "labs/lab1/lab-1.html#exercise-3",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nPlot y vs. x for the star dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between x and y for this dataset. How does this value compare to the r of dino?\n\nTo begin, edit the name of the code chunks from ex-3-1 and ex-3-2 to something more meaningful, e.g: plot-star and r-star respectively.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-4",
    "href": "labs/lab1/lab-1.html#exercise-4",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nFinally, let’s plot all datasets at once. In order to do this we will make use of faceting, given by the code below:\n\nggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset)) +\n  geom_point() +\n  facet_wrap(~ dataset, ncol = 3)\n\nAnd we can use the group_by function to generate all the summary correlation coefficients. We’ll see these functions again and again.\n\ndatasaurus_dozen |&gt;\n  group_by(dataset) |&gt;\n  summarize(r = cor(x, y))",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-5",
    "href": "labs/lab1/lab-1.html#exercise-5",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nDescribe what |&gt; does. Hint: run the following two code chunks. What do you notice?\n\ndino_data |&gt;\n  summarize(\n    mu_x = mean(x),\n    mu_y = mean(y)\n  )\n\n\nsummarize(dino_data, mu_x = mean(x), mu_y = mean(y))",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-6",
    "href": "labs/lab1/lab-1.html#exercise-6",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nIn the above code chunk, identify each of the following as an argument or a function:\n\nsummarize\ndino_data\nmean\nx\ny\nmu_x = mean(x)",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-7",
    "href": "labs/lab1/lab-1.html#exercise-7",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nCombine the code from exercises 4 and 5 to compute the mean(x) and mean(y) for each data set. Print your result to the screen. What do you notice? What does this say about the importance of visualizing your data as opposed to only looking at summary statistics?",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-8",
    "href": "labs/lab1/lab-1.html#exercise-8",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nIMS - Chapter 1 exercises, #4: Cheaters, study components.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-9",
    "href": "labs/lab1/lab-1.html#exercise-9",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nIMS - Chapter 1 exercises, #14: UN Votes.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#exercise-10",
    "href": "labs/lab1/lab-1.html#exercise-10",
    "title": "Lab 1: Hello R!",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nIMS - Chapter 1 exercises, #16: Shows on Netflix.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#submitting",
    "href": "labs/lab1/lab-1.html#submitting",
    "title": "Lab 1: Hello R!",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-1.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TAs can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#grading",
    "href": "labs/lab1/lab-1.html#grading",
    "title": "Lab 1: Hello R!",
    "section": "Grading",
    "text": "Grading\n\n\n\nExercise\nPoints\n\n\n\n\nExercise 1\n5\n\n\nExercise 2\n4\n\n\nExercise 3\n6\n\n\nExercise 4\n5\n\n\nExercise 5\n2\n\n\nExercise 6\n6\n\n\nExercise 7\n7\n\n\nExercise 8\n5\n\n\nExercise 9\n5\n\n\nExercise 10\n5\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab1/lab-1.html#acknowledgements",
    "href": "labs/lab1/lab-1.html#acknowledgements",
    "title": "Lab 1: Hello R!",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was adapted from a lab in Data Science in a Box.",
    "crumbs": [
      "Labs",
      "Lab 1"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html",
    "href": "labs/lab5/lab-5.html",
    "title": "Lab 5",
    "section": "",
    "text": "By the end of this lab you will create formulate and conduct hypothesis tests using randomization.\nFor all visualizations you create, be sure to include informative titles for the plot, axes, and legend!",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-1",
    "href": "labs/lab5/lab-5.html#exercise-1",
    "title": "Lab 5",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nIMS - Chapter 11 exercises, #2: Identify the parameter, II.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-2",
    "href": "labs/lab5/lab-5.html#exercise-2",
    "title": "Lab 5",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nIMS - Chapter 11 exercises, #6: Identify hypotheses, II.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-3",
    "href": "labs/lab5/lab-5.html#exercise-3",
    "title": "Lab 5",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nIMS - Chapter 11 exercises, #8: Heart transplants.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-4",
    "href": "labs/lab5/lab-5.html#exercise-4",
    "title": "Lab 5",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nRecreate the stacked bar plot in Exercise 3.\n\n\n\n\n\n\n\nHint\n\n\n\nThe colors are #569BBD and #114B5F. Use scale_fill_manual() to indicate these are the colors you want to use.\n\n\n\n\n\n\n\n\nPause and render\n\n\n\nNow that you’ve completed a few exercises, pause and render your document. If it renders without any issues, great! Move on to the next exercise. If it does not, debug the issue before moving on. Ask for help if you need. Do not proceed without rendering your document.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-5",
    "href": "labs/lab5/lab-5.html#exercise-5",
    "title": "Lab 5",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nCalculate the point estimate for the difference in proportions of patients who died between the treatment and control groups: \\(\\hat{p}_{treatment} - \\hat{p}_{control}\\), where \\(\\hat{p}\\) is the observed probability of dying in each group. Do this in two ways:\n\nConstruct a frequency table of survived by transplant and calculate the difference in proportions “by hand”.\nUse specify() and calculate() to calculate the difference in proportions as shown below.\n\n\nobs_diff_outcome &lt;- heart_transplant |&gt;\n  specify(response = outcome, explanatory = transplant, success = \"deceased\") |&gt;\n  calculate(stat = \"diff in props\", order = c(\"treatment\", \"control\"))\n\nThen, confirm that you obtained the same results with the two methods.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-6",
    "href": "labs/lab5/lab-5.html#exercise-6",
    "title": "Lab 5",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nUsing the code below, generate a null distribution for the hypothesis test for the hypothesis you formulated in Exercise 3. Use 100 resamples (reps). However, change the seed to use a different seed.\n\nset.seed(1234)\n\nnull_dist_outcome &lt;- heart_transplant |&gt;\n  specify(response = outcome, explanatory = transplant, success = \"deceased\") |&gt;\n  hypothesize(null = \"independence\") |&gt;\n  generate(reps = 100, type = \"permute\") |&gt;\n  calculate(stat = \"diff in props\", order = c(\"treatment\", \"control\"))\n\nThen, inspect the object null_dist_outcome using either glimpse() or just printing it to screen. How many rows and how many columns does it have? What does each row represent? What does each variable represent?",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-7",
    "href": "labs/lab5/lab-5.html#exercise-7",
    "title": "Lab 5",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nVisualize the distribution of simulated differences in proportions of deceased between treatment and control groups. What is the shape of this distribution? What is the center of this distribution? Are these results expected? Explain your reasoning.\n\n\n\n\n\n\n\nHint\n\n\n\nThese simulated values are in the stat column of null_dist_outcome.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-8",
    "href": "labs/lab5/lab-5.html#exercise-8",
    "title": "Lab 5",
    "section": "Exercise 8",
    "text": "Exercise 8\n\nCalculate the p-value. Do this in two ways:\n\nFilter null_dist_outcome for stat values that are at least as far away from the null value as the observed value you calculated in Exercise 4. Make sure you’re considering both directions! Note how many such values there are, and calculate the proportion out of the total number of resamples.\nUse get_p_value():\n\n\np_value_outcome &lt;- null_dist_outcome |&gt;\n  get_p_value(obs_stat = obs_diff_outcome, direction = \"two-sided\")\n\nThen, confirm that you obtained the same results with the two methods. Finally, interpret the p-value in context of the data and the research question and comment on the statistical discernability of this result using a discernability level of 5%.\n\n\n\n\n\n\n\nPause and render\n\n\n\nNow that you’ve completed a few exercises, pause and render your document. If it renders without any issues, great! Move on to the next exercise. If it does not, debug the issue before moving on. Ask for help if you need. Do not proceed without rendering your document.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-9",
    "href": "labs/lab5/lab-5.html#exercise-9",
    "title": "Lab 5",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nRecreate the side-by–side box plots in Exercise 3. The variable of interest is survtime, which is the number of days patients were alive after the date they were determined to be a candidate for a heart transplant until the termination date of the study.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#exercise-10",
    "href": "labs/lab5/lab-5.html#exercise-10",
    "title": "Lab 5",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nDo these data provide convincing evidence of a difference between average survival times of patient who did and did not get a heart transplant?\nWrite the hypotheses for answering this question and conduct the hypothesis test using randomization. Use 1,000 resamples. In order to avoid name collision, use object names like obs_diff_survtime, null_dist_survtime, and p_value_survtime. Find and interpret the p-value in context of the data and the research question and comment on the statistical discernability of this result using a discernability level of 5%.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#submitting",
    "href": "labs/lab5/lab-5.html#submitting",
    "title": "Lab 5",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-5.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TA can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab5/lab-5.html#grading",
    "href": "labs/lab5/lab-5.html#grading",
    "title": "Lab 5",
    "section": "Grading",
    "text": "Grading\n\n\n\nExercise\nPoints\n\n\n\n\nExercise 1\n5\n\n\nExercise 2\n4\n\n\nExercise 3\n6\n\n\nExercise 4\n4\n\n\nExercise 5\n4\n\n\nExercise 6\n6\n\n\nExercise 7\n5\n\n\nExercise 8\n4\n\n\nExercise 9\n5\n\n\nExercise 10\n7\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 5"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html",
    "href": "labs/lab2/lab-2.html",
    "title": "Lab 2",
    "section": "",
    "text": "The goal of this lab is to effectively visualize numerical and categorical data.\nFor all visualizations you create, be sure to include informative titles for the plot, axes, and legend!",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-1",
    "href": "labs/lab2/lab-2.html#exercise-1",
    "title": "Lab 2",
    "section": "Exercise 1",
    "text": "Exercise 1\n\nCreate a bar plot of the results of games for NC Courage. Additionally, calculate the numbers of wins, losses, and ties. Write a one sentence narrative for your findings.\n\nHint: result is a categorical variable, so use a bar plot for the visualization and the count() function for calculating the frequencies of levels of this variable.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-2",
    "href": "labs/lab2/lab-2.html#exercise-2",
    "title": "Lab 2",
    "section": "Exercise 2",
    "text": "Exercise 2\n\nCreate a new variable indicating whether the game was played at home or away for NC Courage. This variable should be called home_courage and take the value “home” if NC Courage is the home team and “away” if NC Courage is the away team. (Instructions for how to do this are given below.)\nThen, calculate the number of home and away games, and write a one sentence narrative for your findings.\n\nUse the example code below to get started.\n\ncourage &lt;- courage |&gt;\n  mutate(home_courage = if_else(home_team == \"NC\", \"home\", \"away\"))\n\nThere are two things of note here:\n\nThe use of the assignment operator (&lt;-) to assign the resulting data frame to courage, thus overwriting the courage dataset to contain this new column. We do this because we will use this new variable, home_courage, in a subsequent exercise.\nThe use of a new function, if_else() to determine whether the game is played at home or away.\n\nhome_team == \"NC\" finds all rows where the home team is NC Courage.\nIf the home team is NC Courage, then we set the value of home_courage to `“home”.\nOtherwise (else) Courage must be the away team and we set the value of home_courage to \"away\".",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-3",
    "href": "labs/lab2/lab-2.html#exercise-3",
    "title": "Lab 2",
    "section": "Exercise 3",
    "text": "Exercise 3\n\nFirst, create a visualization that displays the relationship between home_courage and result. Then, calculate the proportions of home and away games that the Courage won. Based on these, do your findings suggest a home-field advantage? Why or why not?\n\nSo far we have focused on whether the game was at home or away and whether the Courage won. Next, we dive deeper and focus on the number of points the Courage wins by, at home and away.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-4",
    "href": "labs/lab2/lab-2.html#exercise-4",
    "title": "Lab 2",
    "section": "Exercise 4",
    "text": "Exercise 4\n\nHow many points do the Courage typically win by (on average)? Use the example code below to get started. You’ll encounter a new function: abs() is the absolute value function. It takes the absolute value of a number. Why do we want to use this absolute value function here?\n\nHint: We are only interested in games the Courage wins, therefore we should filter() for those games first.\n\ncourage |&gt;\n  filter(___) |&gt;\n  mutate(win_pts = abs(home_pts - away_pts)) |&gt;\n  summarize(___)",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-5",
    "href": "labs/lab2/lab-2.html#exercise-5",
    "title": "Lab 2",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nHow many points do NC Courage score when they win (on average)? Note this is different than how many points they “win by”. How many points do the Courage score when they lose on average?\n\nTo calculate this we first need to determine how many points NC Courage scored in every game. We can use if_else() logic again to find this value for each game, and store it in a new column, courage_pts.\n\ncourage &lt;- courage |&gt;\n  mutate(courage_pts = if_else(home_team == \"NC\", home_pts, away_pts))\n\ncourage |&gt;\n  group_by(___) |&gt;\n  summarize(___)",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-6",
    "href": "labs/lab2/lab-2.html#exercise-6",
    "title": "Lab 2",
    "section": "Exercise 6",
    "text": "Exercise 6\n\nNext we’ll investigate visually whether or not NC Courage has a home-field advantage. To start, let’s build on the courage2 data frame. Add a new column called home_courage that takes the value “home” if Courage is the home team and “away” if Courage is the away team. Hint: use the ifelse logic from exercise 4.\nMutate the courage data frame to create two new variables:\n\ntotal_pts: Sum of points scored by both teams, i.e. home_pts + away_pts.\nopponent_pts: Points scored by the opposing team, i.e., total_pts - courage_pts.\n\nSave the resulting data frame as courage again and print the three points columns (total_pts, opponent_pts, courage_pts) to screen.\n\nHint:\n\nUse the mutate() function to create the columns.\n\n\ncourage &lt;- courage |&gt;\n  mutate(\n    total_pts = ___,\n    opponent_pts = ___\n    )\n\n\nUse the select() function to print them to screen:\n\n\ncourage |&gt;\n  select(total_pts, opponent_pts, courage_pts)",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-7",
    "href": "labs/lab2/lab-2.html#exercise-7",
    "title": "Lab 2",
    "section": "Exercise 7",
    "text": "Exercise 7\n\nCreate a scatter plot:\n\nopponent_pts (y) vs. courage_pts (x)\nColor the scatter plot by whether NC Courage are home or away.\nRepresent the data with “jittered” points wth geom_jitter().\nOverlay a \\(y = x\\) line with geom_abline().\nFaceted by season.\n\nWhat does the line represent? What does it mean for a point to fall above the line? Below the line?\n\n\nggplot(courage, aes(x = ___, y = ___, color = ___)) + \n  geom_jitter(width = 0.1, height = 0.1) + \n  geom_abline(slope = 1, intercept = 0) +\n  facet_wrap(~ ___) +\n  labs(\n    x = \"___\", \n    y = \"___\", \n    title = \"___\", \n    color = \"___\"\n  )",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-8",
    "href": "labs/lab2/lab-2.html#exercise-8",
    "title": "Lab 2",
    "section": "Exercise 8",
    "text": "Exercise 8\nThis exercise is a look at where we’re headed…\n\nIf we want to formally test whether the Courage have a home-field advantage, then we must first define what this means! In your own words, what do you think a home-field advantage means? Then, now that you’ve defined what it means to have a home field advantage, define what it means to not have a home-field advantage.\n\n\n\n\n\n\n\nNote\n\n\n\nWhile there is a right answer, this part is graded for completion, so don’t worry too much about answering this in exactly the right way. Although graded for completion, your response must make sense to receive full points.\n\n\nWe’ll pick-up here in a future class.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-9",
    "href": "labs/lab2/lab-2.html#exercise-9",
    "title": "Lab 2",
    "section": "Exercise 9",
    "text": "Exercise 9\n\nIMS - Chapter 2 exercises, #20: Vitamin supplements.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#exercise-10",
    "href": "labs/lab2/lab-2.html#exercise-10",
    "title": "Lab 2",
    "section": "Exercise 10",
    "text": "Exercise 10\n\nIMS - Chapter 2 exercises, #30: Screens, teens, and psychological well-being.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#submitting",
    "href": "labs/lab2/lab-2.html#submitting",
    "title": "Lab 2",
    "section": "Submitting",
    "text": "Submitting\n\n\n\n\n\n\nImportant\n\n\n\nBefore you proceed, first, make sure that you have updated the document YAML with your name! Then, render your document one last time, for good measure.\n\n\nTo submit your assignment to Gradescope:\n\nGo to your Files pane and check the box next to the PDF output of your document (lab-2.pdf).\nThen, in the Files pane, go to More &gt; Export. This will download the PDF file to your computer. Save it somewhere you can easily locate, e.g., your Downloads folder or your Desktop.\nGo to the course Canvas page and click on Gradescope and then click on the assignment. You’ll be prompted to submit it.\nMark the pages associated with each exercise. All of the papers of your lab should be associated with at least one question (i.e., should be “checked”).\n\n\n\n\n\n\n\nWarning\n\n\n\nIf you fail to mark the pages associated with an exercise, that exercise won’t be graded. This means, if you fail to mark the pages for all exercises, you will receive a 0 on the assignment. The TAs can’t mark your pages for you, and for them to be able to grade, you must mark them.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#grading",
    "href": "labs/lab2/lab-2.html#grading",
    "title": "Lab 2",
    "section": "Grading",
    "text": "Grading\n\n\n\nExercise\nPoints\n\n\n\n\nExercise 1\n5\n\n\nExercise 2\n5\n\n\nExercise 3\n6\n\n\nExercise 4\n6\n\n\nExercise 5\n6\n\n\nExercise 6\n4\n\n\nExercise 7\n6\n\n\nExercise 8\n2\n\n\nExercise 9\n5\n\n\nExercise 10\n5\n\n\nTotal\n50",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "labs/lab2/lab-2.html#acknowledgements",
    "href": "labs/lab2/lab-2.html#acknowledgements",
    "title": "Lab 2",
    "section": "Acknowledgements",
    "text": "Acknowledgements\nThis assignment was adapted from a similar exercise by Dr. Alex Fisher.",
    "crumbs": [
      "Labs",
      "Lab 2"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "STA 101: Data Analysis and Statistical Inference",
    "section": "",
    "text": "This page contains an outline of the topics, content, and assignments for the semester. Note that this schedule will be updated as the semester progresses and the timeline of topics and assignments might be updated throughout the semester.\n\n\n\n\n\n\n\n\n\nWEEK\nDATE\nTOPIC\nPREPARE\nMATERIALS\nDUE\n\n\n\n\n1\nWed, May 15\n\nWelcome to STA 101!\n\n\n\n\n📓 Welcome slides\n📓 activity\n⬇️ Canvas\n📝 survey\n\n\n\n\n\n\n\nThu, May 16\n\nHello data\n\n\n📖 ims: Chp 1\n💻 tutorial: 01-data-01\n\n\n📓 notes\n📓 filled-in notes\n⬇️ Canvas\n\n\n\n\n\n\n\nThu, May 16\n\nLab 1: Hello R!\n\n\n\n\n💻 lab-1\n⬇️ Canvas\n\n\n\n\n\n\n\nFri, May 17\n\nStudy design\n\n\n📖 ims: Chp 2\n💻 tutorial: 01-data-02\n💻 tutorial: 01-data-03\n\n\n📓 notes\n📓 filled-in notes\n⬇️ Canvas\n\n\n\n\n\n\n\nSun, May 19\n\n\n\n\n\n\n\n✅ Lab 1 at 11:59 pm\n\n\n\n2\nMon, May 20\n\nLab 2: Hello data!\n\n\n📖 ims: Chp 3\n💻 tutorial: 01-data-04\n\n\n💻 lab-2\n⬇️ Canvas\n\n\n\n\n\n\n\nMon, May 20\n\nExploring categorical data\n\n\n📖 ims: Chp 4\n💻 tutorial: 02-explore-01\n\n\n📓 notes\n📓 filled-in notes\n⬇️ Canvas\n\n\n\n\n\n\n\nTue, May 21\n\nExploring numerical data\n\n\n📖 ims: Chp 5\n💻 tutorial: 02-explore-02\n\n\n📓 notes\n📓 filled-in notes\n⬇️ Canvas\n\n\n\n\n\n\n\nWed, May 22\n\nRegression with a single predictor I\n\n\n📖 ims: Chp 7.1 - 7.2\n💻 tutorial: 03-model-01\n💻 tutorial: 03-model-02\n\n\n📓 notes\n⬇️ Canvas\n\n\n✅ Lab 2 at 11:59 pm\n\n\n\n\n\nThu, May 23\n\nLab 3: Exploratory data analysis\n\n\n📖 ims: Chp 6\n💻 tutorial: 02-explore-03\n\n\n💻 lab-3\n⬇️ Canvas\n\n\n\n\n\n\n\nThu, May 23\n\nRegression with a single predictor II\n\n\n📖 ims: Chp 7.2 - 7.4\n💻 tutorial: 03-model-03\n\n\n📓 notes\n📓 filled-in notes\n⬇️ Canvas\n\n\n\n\n\n\n\nFri, May 24\n\nRegression with multiple predictors\n\n\n📖 ims: Chp 8.1 - 8.3\n\n\n📓notes\n📓filled-in notes\n⬇️ Canvas\n\n\n\n\n\n3\nMon, May 27\n\nMemorial Day- No classes\n\n\n\n\n\n\n\n\n\n\n\nTue, May 28\n\nModel selection\n\n\n📖 ims: Chp 8.4 - 8.5\n\n\n📓 notes\n⬇️ Canvas\n\n\n📄 Project Proposal at 11:59 pm\n\n\n\n\n\nWed, May 29\n\nModel selection (cont.)\n\n\n📖 ims: Chp 8.4 - 8.5\n\n\n📓 notes\n📓 filled-in notes\n⬇️ Canvas\n\n\n✅ Lab 3 at 11:59 pm\n\n\n\n\n\nThu, May 30\n\nLab 4: Regression\n\n\n\n\n💻 lab-4\n⬇️ Canvas\n\n\n\n\n\n\n\nThu, May 30\n\nLogistic regression\n\n\n📖 ims: Chp 9.1 - 9.2\n📖 ims: Chp 9.3 - 9.5\n\n\n📓notes\n📓filled-in notes\n⬇️ Canvas\n\n\n\n\n\n\n\nFri, May 31\n\nHypothesis testing with randomization\n\n\n📖 ims: Chp 11\n💻 tutorial: 04-foundations-01\n💻 tutorial: 04-foundations-02\n\n\n📓notes\n⬇️ Canvas\n\n\n\n\n\n\n\nSun, Jun 2\n\n\n\n\n\n\n\n✅ Lab 4 at 11:59 pm\n\n\n\n4\nMon, Jun 3\n\nHypothesis testing with randomization\n\n\n\n\n📓notes (hyp. test)\n⬇️ Canvas\n\n\n\n\n\n\n\nMon, Jun 3\n\nLab 5: Hypothesis testing\n\n\n\n\n💻 lab-5\n⬇️ Canvas\n\n\n\n\n\n\n\nTue, Jun 4\n\nCatch-up day\n\n\n\n\n📓notes (hyp. test)\n📓filled-in notes (hyp. test)\n⬇️ Canvas\n\n\n\n\n\n\n\nWed, Jun 5\n\nConfidence intervals with bootstrapping + Ethics\n\n\n📖 ims: Chp 12\n💻 tutorial: 04-foundations-04\n🎥 Data privacy\n🎥 Misrepresentation\n🎥 Algorithmic bias\n🎥 Joy Buolamwini - How I’m fighting bias in algorithms\n🎥 Cathy O’Neil - Weapons of Math Destruction\n🎥 Safiya Umoja Noble - Imagining a Future Free from the Algorithms of Oppression\n\n\n📓 notes CI\n📓 notes Ethics\n⬇️ Canvas\n\n\n✅ Lab 5 at 11:59 pm\n\n\n\n\n\nThu, Jun 6\n\nExam 1 Review\n\n\n\n\n📝 exam review\n🗝️ exam review key\n\n\n\n\n\n\n\nFri, Jun 7\n\nExam - In class\n\n\n\n\n⬇️ Canvas (takehome)\n\n\n\n\n\n\n\nSun, Jun 9\n\n\n\n\n\n\n\nExam - Take home at 11:59 pm\n\n\n\n5\nMon, Jun 10\n\nInference with mathematical models\n\n\n📖 ims: Chp 13\n\n\n📓 notes\n📓 filled-in notes\n⬇️ Canvas\n\n\n\n\n\n\n\nMon, Jun 10\n\nLab 6: Ethics + Project update (Intro + EDA)\n\n\n\n\n💻 lab-6\n📄 Intro + EDA\n⬇️ Canvas\n\n\n\n\n\n\n\nTue, Jun 11\n\nMore on CLT + Decision errors\n\n\n📖 ims: Chp 13\n📖 ims: Chp 14\n💻 tutorial: 04-foundations-03\n\n\n📓notes\n⬇️ Canvas\n\n\n\n\n\n\n\nWed, Jun 12\n\nInference for a single proportion\n\n\n📖 ims: Chp 16\n💻 tutorial: 05-infer-01\n\n\n📓 notes\n📓 filled-in notes\n⬇️ Canvas\n\n\n✅ Lab 6 at 11:59 pm\n📄 Intro + EDA due at 11:59 pm\n✉️ Email your peer reviewer\n\n\n\n\n\nThu, Jun 13\n\nLab 7: Foundations of inference + Peer review\n\n\n\n\n💻 lab-7\n📄 Peer review\n\n\n\n\n\n\n\nThu, Jun 13\n\nInference for comparing two proportions\n\n\n📖 ims: Chp 17\n💻 tutorial: 05-infer-02\n\n\n📓 notes\n📓 filled-in notes\n⬇️ Canvas\n\n\n\n\n\n\n\nFri, Jun 14\n\nInference for two-way tables\n\n\n📖 ims: Chp 18\n💻 tutorial: 05-infer-03\n\n\n📓notes\n\n\n\n\n\n\n\nSun, Jun 16\n\n\n\n\n\n\n\n✅ Lab 7 at 11:59 pm\n📄 Peer review due at 11:59 pm\n\n\n\n6\nMon, Jun 17\n\nLab 8: Inference for proportions\n\n\n\n\n💻 lab-8\n\n\n\n\n\n\n\nMon, Jun 17\n\nInference for a single mean\n\n\n📖 ims: Chp 19\n💻 tutorial: 05-infer-05\n💻 tutorial: 05-infer-06\n\n\n📓 notes\n\n\n\n\n\n\n\nTue, Jun 18\n\nInference for comparing two independent means\n\n\n📖 ims: Chp 20\n💻 tutorial: 05-infer-07\n\n\n📓 notes\n\n\n\n\n\n\n\nWed, Jun 19\n\nJuneteenth - No classes\n\n\n\n\n\n\n\n\n\n\n\nThu, Jun 20\n\nInference for comparing two paired + more means\n\n\n📖 ims: Chp 21\n\n\n📓 notes\n\n\n✅ Lab 8 at 11:59 pm\n\n\n\n\n\nThu, Jun 20\n\nLab 9: Inference for means\n\n\n\n\n💻 lab-9\n\n\n\n\n\n\n\nFri, Jun 21\n\nCatch-up day\n\n\n\n\n\n\n\n\n\n\n\nSun, Jun 23\n\n\n\n\n\n\n\n✅ Lab 9 at 11:59 pm\n\n\n\n7\nMon, Jun 24\n\nProject presentations\n\n\n\n\n\n\n\n\n\n\n\nTue, Jun 25\n\nReading period\n\n\n\n\n\n\n\n\n\n\n\nWed, Jun 26\n\n\n\n\n\n\n\n📄 Project at 11:59 pm\n\n\n\n\n\n\n\n\n\n\nAcknowledgement\nThank you Dr. Mine Çetinkaya-Rundel for class material and help preparing the course and setting up this website.",
    "crumbs": [
      "Course information",
      "Schedule"
    ]
  },
  {
    "objectID": "course-syllabus.html",
    "href": "course-syllabus.html",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "",
    "text": "This course introduces students to the discipline of statistics as a science of understanding and analyzing data. Themes include data collection, exploratory analysis, inference, and modeling. Focus on principles underlying quantitative research in social sciences, humanities, and public policy. Research projects teach the process of scientific discovery and synthesis and critical evaluation of research and statistical arguments. Readings give perspective on why in 1950, S. Wilks said, “Statistical thinking will one day be as necessary a qualification for efficient citizenship as the ability to read and write.”\nIn this course, students learn how to effectively make use of data in the face of uncertainty: how to collect data, how to analyze data, and how to use data to make inferences and conclusions about real world phenomena. Critiquing data-based claims and evaluating data-based decisions is at the core of this course. Throughout the course students acquire a conceptual understanding and mastery of statistical and quantitative reasoning tools in order to be able to make such critiques and evaluations.\nIn addition, students are presented with novel data sets and application examples on a daily basis, and they use these data to model outcomes and make inferences about unknown population characteristics. Students learn that the first step of any analysis is identifying the assumptions and conditions necessary to apply the statistical technique(s) required to answer the research question at hand. Students not only learn the mechanics of the quantitative analysis, but also how to interpret conclusions based on quantitative evidence in context of the data and the research questions as well as identifying limitations due to data collection and study design.\nFor the lab component of this course students prepare lab reports twice a week presenting statistical analysis of real data. In addition, students complete an independent data analysis projects where they answer significant research questions via the analysis of real data using statistical inference and modeling tools.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-description",
    "href": "course-syllabus.html#course-description",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "",
    "text": "This course introduces students to the discipline of statistics as a science of understanding and analyzing data. Themes include data collection, exploratory analysis, inference, and modeling. Focus on principles underlying quantitative research in social sciences, humanities, and public policy. Research projects teach the process of scientific discovery and synthesis and critical evaluation of research and statistical arguments. Readings give perspective on why in 1950, S. Wilks said, “Statistical thinking will one day be as necessary a qualification for efficient citizenship as the ability to read and write.”\nIn this course, students learn how to effectively make use of data in the face of uncertainty: how to collect data, how to analyze data, and how to use data to make inferences and conclusions about real world phenomena. Critiquing data-based claims and evaluating data-based decisions is at the core of this course. Throughout the course students acquire a conceptual understanding and mastery of statistical and quantitative reasoning tools in order to be able to make such critiques and evaluations.\nIn addition, students are presented with novel data sets and application examples on a daily basis, and they use these data to model outcomes and make inferences about unknown population characteristics. Students learn that the first step of any analysis is identifying the assumptions and conditions necessary to apply the statistical technique(s) required to answer the research question at hand. Students not only learn the mechanics of the quantitative analysis, but also how to interpret conclusions based on quantitative evidence in context of the data and the research questions as well as identifying limitations due to data collection and study design.\nFor the lab component of this course students prepare lab reports twice a week presenting statistical analysis of real data. In addition, students complete an independent data analysis projects where they answer significant research questions via the analysis of real data using statistical inference and modeling tools.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#class-meetings",
    "href": "course-syllabus.html#class-meetings",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Class meetings",
    "text": "Class meetings\n\n\n\n\n\n\n\n\nMeeting\nLocation\nTime\n\n\n\n\nLectures\nPerkins LINK 087 (Classroom 3)\nMon- Fri 11:00 - 12:15 pm\n\n\nLab\nPerkins LINK 087 (Classroom 3)\nMon, Thu 9:30 - 10:45 am",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#office-hours",
    "href": "course-syllabus.html#office-hours",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Office Hours",
    "text": "Office Hours\n\n\n\n\nOffice hours\nLocation\n\n\n\n\nKat Husar\nMon, Wed, & Fri: 3:30 - 4:30 pm\nOld Chem 203B\n\n\nJohn Gillen\nSun: 10 - 11 am\nZoom",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#learning-objectives",
    "href": "course-syllabus.html#learning-objectives",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Learning objectives",
    "text": "Learning objectives\nThe course learning objectives are as follows:\n\nRecognize the importance of data collection, identify limitations in data collection methods, and determine how they affect the scope of inference.\nUse statistical software to summarize data numerically and visually, and to perform data analysis.\nHave a conceptual understanding of the unified nature of statistical inference.\nApply estimation and testing methods to analyze single variables or the relationship between two variables in order to understand natural phenomena and make data-based decisions.\nModel numerical response variables using a single or multiple explanatory variables.\nInterpret results correctly, effectively, and in context without relying on statistical jargon.\nCritique data-based claims and evaluate data-based decisions.\nComplete research projects demonstrating mastery of statistical data analysis from exploratory analysis to inference to modeling.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#prerequisites",
    "href": "course-syllabus.html#prerequisites",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Prerequisites",
    "text": "Prerequisites\nThis course has no pre-requisites.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#tips-for-success",
    "href": "course-syllabus.html#tips-for-success",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Tips for success",
    "text": "Tips for success\n\nComplete the reading before a new unit begins, and then review again after the unit is over.\nBe an active participant during lectures and labs.\nAsk questions - during class or office hours, or by email. Ask me, your TA, and your classmates.\nDo the problem sets - start early and make sure you attempt and understand all questions.\nStart your project early and and allow adequate time to complete it.\nGive yourself plenty of time time to prepare a good cheat sheet for exams. This requires going through the material and taking the time to review the concepts that you’re not comfortable with.\nDo not procrastinate - don’t let a unit go by with unanswered questions as it will just make the following unit’s material even more difficult to follow.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#textbooks",
    "href": "course-syllabus.html#textbooks",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Textbooks",
    "text": "Textbooks\nReadings for the course will come from the following textbooks. They are freely available online and you do not need to purchase a physical copy of either book to succeed in this class.\n\n[ims]: Mine Çetinkaya-Rundel and Jo Hardin. Introduction to Modern Statistics. (in progress) 2nd edition. OpenIntro, 2023.\n[r4ds]: Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund. R for Data Science. 2nd edition. O’Reilly, 2022.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-community",
    "href": "course-syllabus.html#course-community",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Course community",
    "text": "Course community\n\nDuke Community Standard\nAll students must adhere to the Duke Community Standard (DCS): Duke University is a community dedicated to scholarship, leadership, and service and to the principles of honesty, fairness, and accountability. Citizens of this community commit to reflect upon these principles in all academic and non-academic endeavors, and to protect and promote a culture of integrity.\nTo uphold the Duke Community Standard, students agree:\n\nI will not lie, cheat, or steal in my academic endeavors;\nI will conduct myself honorably in all my endeavors; and\nI will act if the Standard is compromised.\n\n\n\n\n\nInclusive community\nIt is my intent that students from all diverse backgrounds and perspectives be well-served by this course, that students’ learning needs be addressed both in and out of class, and that the diversity that the students bring to this class be viewed as a resource, strength, and benefit. It is my intent to present materials and activities that are respectful of diversity and in alignment with Duke’s Commitment to Diversity and Inclusion. Your suggestions are encouraged and appreciated. Please let me know ways to improve the effectiveness of the course for you personally, or for other students or student groups.\nFurthermore, I would like to create a learning environment for my students that supports a diversity of thoughts, perspectives and experiences, and honors your identities. To help accomplish this:\n\nIf you have a name that differs from those that appear in your official Duke records, please let me know!\nIf you feel like your performance in the class is being impacted by your experiences outside of class, please don’t hesitate to come and talk with me. If you prefer to speak with someone outside of the course, your academic dean is an excellent resource.\nI (like many people) am still in the process of learning about diverse perspectives and identities. If something was said in class (by anyone) that made you feel uncomfortable, please let me or a member of the teaching team know.\n\n\n\nPronouns\nPronouns are meaningful tools to communicate identities and experiences, and using pronouns supports a campus environment where all community members can thrive.\nPlease update your gender pronouns in Duke Hub. You can learn more at the Center for Sexual and Gender Diversity’s website.\n\n\nAccessibility\nIf there is any portion of the course that is not accessible to you due to challenges with technology or the course format, please let me know so we can make appropriate accommodations.\nThe Student Disability Access Office (SDAO) is available to ensure that students are able to engage with their courses and related assignments. Students should be in touch with the Student Disability Access Office to request or update accommodations under these circumstances.\n\n\nCommunication\nAll lecture notes, assignment instructions, an up-to-date schedule, and other course materials may be found on the course Canvas page.\nI will regularly send course announcements via email and Canvas, make sure to check one or the other of these regularly. If an announcement is sent Monday through Thursday, I will assume that you have read the announcement by the next day. If an announcement is sent on a Friday or over the weekend, I will assume that you have read it by Monday.\n\n\nWhere to get help\n\nIf you have a question during lecture or lab, feel free to ask it! There are likely other students with the same question, so by asking you will create a learning opportunity for everyone.\nThe teaching team is here to help you be successful in the course. You are encouraged to attend office hours to ask questions about the course content and assignments. Many questions are most effectively answered as you discuss them with others, so office hours are a valuable resource. Please use them!\nOutside of class and office hours, any general questions about course content or assignments should be posted to the discussion board on Canvas. There is a chance another student has already asked a similar question, so please check the other posts before adding a new question. If you know the answer to a question posted on the discussion board, I encourage you to respond!\n\nCheck out the course support page under Course Information module for more resources.\nI want to make sure that you learn everything you were hoping to learn from this class. If this requires flexibility, please don’t hesitate to ask.\n\nYou never owe me personal information about your health (mental or physical) but you’re always welcome to talk to me. If I can’t help, I likely know someone who can.\nI want you to learn lots of things from this class, but I primarily want you to stay healthy, balanced, and grounded during this crisis.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#lectures-and-lab",
    "href": "course-syllabus.html#lectures-and-lab",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Lectures and lab",
    "text": "Lectures and lab\nThe goal of both the lectures and the labs is for them to be as interactive as possible. My role as instructor is to introduce you new tools and techniques, but it is up to you to take them and make use of them. A lot of what you do in this course will involve writing code, and coding is a skill that is best learned by doing. Therefore, as much as possible, you will be working on a variety of tasks and activities throughout each lecture and lab. You are expected to attend all lecture and lab sessions and meaningfully contribute to in-class exercises and discussion.\nYou are expected to bring a laptop to each class so that you can take part in the in-class exercises. Please make sure your laptop is fully charged before you come to class as the number of outlets in the classroom will not be sufficient to accommodate everyone. See Duke LIFE loaner laptop program if you need a loaner laptop.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#assessments-and-grading",
    "href": "course-syllabus.html#assessments-and-grading",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Assessments and grading",
    "text": "Assessments and grading\nThe final course grade will be calculated as follows:\n\n\n\nCategory\nPercentage\n\n\n\n\nAttendance and participation\n5%\n\n\nLabs\n35%\n\n\nExam\n30%\n\n\nProject\n30%\n\n\n\nThe final letter grade will be determined based on the following thresholds:\n\n\n\nLetter Grade\nFinal Course Grade\n\n\n\n\nA\n&gt;= 93\n\n\nA-\n90 - 92.99\n\n\nB+\n87 - 89.99\n\n\nB\n83 - 86.99\n\n\nB-\n80 - 82.99\n\n\nC+\n77 - 79.99\n\n\nC\n73 - 76.99\n\n\nC-\n70 - 72.99\n\n\nD+\n67 - 69.99\n\n\nD\n63 - 66.99\n\n\nD-\n60 - 62.99\n\n\nF\n&lt; 60\n\n\n\nThese are upper bounds for grade cutoffs, depending on the class performance the cutoffs may be lowered but they won’t be increased.\nAll work is expected to be submitted by the deadline and there are no make ups for any missed assessments. See Section 11.2 for policies on late work.\n\nAttendance and participation\nYou are expected to be present at class meeting and actively participate in the discussion. Your attendance and participation during class, as well as your activity on the course discussion board will make up a non-insignificant portion of your grade in this class. While I might sometimes call on you during the class discussion, it is your responsibility to be an active participant without being called on. We will use Wooclap in lecture and attendance will be recorded via Wooclap participation (note: not based on answers, only completion). You will receive full credit for lecture attendance if your Wooclap participation score is at least 80%.\nYou can miss two lab meetings for any reason without penalty. Lecture and lab attendance will be equally weighted in the final attendance grade calculation.\n\n\nLabs\nIn labs, you will apply the concepts discussed in lecture to various data analysis scenarios. Labs will focus on both computation and conceptualization. Lab assignments will be completed using Quarto and submitted as PDF for grading in Gradescope. While you may collaborate with others on lab assignments, your final solution should be your own.\nLowest lab score will be dropped.\n\n\nExams\nThere will be one exam. The exam will be comprised of two components:\n\nIn class: 75 minute in-class exam. This exam is closed book, however you are allowed to use one sheet of notes (“cheat sheet”) to the exam. This sheet must be no larger than 8 1/2 x 11, and must be prepared by you. You may use both sides of the sheet. (70% of the grade)\nTake home: Following the in class exam, you’ll have 48 hours to complete the take home portion of your exam. The take home portion will follow from the in class exam and focus on the analysis of a dataset introduced in the take home exam. (30% of the grade)\n\nThrough these exams you have the opportunity to demonstrate what you’ve learned in the course thus far. Each exam will include small analyses and computational tasks related to the content in application exercises and labs. More details about the content and structure of the exams will be discussed during the semester.\nSee Section 13 for date and time of the exam. Exam date cannot be changed and no make-up exam will be given. If you can’t take the exam on this date, you should drop this class.\n\n\nProject\nThere will be a semester-long data analysis project. The project allows you to explore a question and dataset that aligns with your interests. More details about the project will be provided during the semester. The project will be completed individually.\nSee Section 13 for dates and times of project deadlines. Project deadlines cannot be changed. If you can’t be in class for the final project presentation, you should drop this class.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#course-policies",
    "href": "course-syllabus.html#course-policies",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Course policies",
    "text": "Course policies\n\nAcademic honesty\nTL;DR: Don’t cheat!\nPlease abide by the following as you work on assignments in this course:\n\nCollaboration: Only work that is clearly assigned as team work should be completed collaboratively.\n\nThe labs must also be completed individually and you are welcomed to discuss the assignment with classmates at a high level (e.g., discuss what’s the best way for approaching a problem, what functions are useful for accomplishing a particular task, etc.). However you may not directly share answers to lab questions (including any code) with anyone other than myself and the teaching assistants.\nFor the projects, communication with classmates at a high level is allowed however you may not share code or components of the project between students.\nOn individual assignments you may not directly share code with another student in this class.\n\nOnline resources: I am well aware that a huge volume of code is available on the web to solve any number of problems. Unless I explicitly tell you not to use something, the course’s policy is that you may make use of any online resources (e.g., StackOverflow) but you must explicitly cite where you obtained any code you directly use (or use as inspiration). Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism.\nUse of generative artificial intelligence (AI): You should treat generative AI, such as ChatGPT, the same as other online resources. There are two guiding principles that govern how you can use AI in this course:1 (1) Cognitive dimension: Working with AI should not reduce your ability to think clearly. We will practice using AI to facilitate—rather than hinder—learning. (2) Ethical dimension: Students using AI should be transparent about their use and make sure it aligns with academic integrity.\n\n✅ AI tools for code: You may make use of the technology for coding examples on assignments; if you do so, you must explicitly cite where you obtained the code. Any recycled code that is discovered and is not explicitly cited will be treated as plagiarism. You may use these guidelines for citing AI-generated content.\n❌ AI tools for narrative: Unless instructed otherwise, you may not use generative AI to write narrative on assignments. In general, you may use generative AI as a resource as you complete assignments but not to answer the exercises for you. You are ultimately responsible for the work you turn in; it should reflect your understanding of the course content.\n\n\nRegardless of course delivery format, it is the responsibility of all students to understand and follow all Duke policies, including academic integrity (e.g., completing one’s own work, following proper citation of sources, adhering to guidance around group work projects, and more). Ignoring these requirements is a violation of the Duke Community Standard. Any questions and/or concerns regarding academic integrity can be directed to the Office of Student Conduct and Community Standards at conduct@duke.edu.\nAny violations in academic honesty standards as outlined in the Duke Community Standard and those specific to this course will\n\nautomatically result in a 0 for the assignment,\ncan further impact your overall course grade, and\nwill be reported to the Office of Student Conduct for further action.\n\n\n\nLate work & extensions\nThe due dates for assignments are there to help you keep up with the course material and to ensure the teaching team can provide feedback within a timely manner. We understand that things come up periodically that could make it difficult to submit an assignment by the deadline.\nPolicy on late work depends on the particular course component:\n\nLabs:\n\nLate, but within 24 hours of deadline: -20% of available points.\nAny later: No credit, and we will not provide written feedback.\nNote that lowest lab score will be dropped, even if that score is a 0.\n\nExams:\n\nIn class portions of the exams can obviously not be turned in late.\nLate exams are not accepted.\n\nProjects: The following three components contribute to your project score.\n\nPresentation: Late presentations are not accepted and there are no make ups for missed presentations.\nWrite up: if you need to submit your work late, email me.\n\nLate, but within 24 hours of deadline: -20% of available points.\nAny later: No credit, and we will not provide written feedback.\n\n\n\n\n\nWaiver for extenuating circumstances\nIf there are circumstances that prevent you from completing a lab or homework assignment by the stated due date, you may email the me (kat.husar@duke.edu) before the deadline to waive the late penalty. In your email, you only need to request the waiver; you do not need to provide explanation. This waiver may only be used for once in the semester, so only use it for a truly extenuating circumstance.\nIf there are circumstances that are having a longer-term impact on your academic performance, please let your academic dean know, as they can be a resource. Please let me know if you need help contacting your academic dean.\n\n\nRegrade requests\nEvery effort will be made to mark your work accurately. We are on your side, and want you to receive every point you have worked to earn. However, sometimes grading mistakes happen. If you believe that an error has been made, return the paper to the instructor within four days, stating your claim in writing.\nThe following claims will be considered for re-grading:\n\npoints are not totaled correctly;\nthe grader did not see a correct answer that is on your paper;\nyour answer is the same as the correct answer, but in a different form (e.g., you wrote a correct answer as 1/3 and the grader was looking for 0.333);\nyour answer to a free response question is essentially correct but stated slightly differently than the grader’s expectation.\n\nThe following claims will not be considered for re-grading:\n\narguments about the number of points lost;\narguments about question wording.\n\nConsidering re-grades consumes time and resources that TA and the instructor would rather spend helping you understand material. Please bring only claims of type 1-4 to our attention.\nNote that during the regrade process your score could go up or go down or not change.\n\n\n\n\n\n\nWarning\n\n\n\nNo grades will be changed after the project presentations.\n\n\n\n\nAttendance policy\nResponsibility for class attendance rests with individual students. Since regular and punctual class attendance is expected, students must accept the consequences of failure to attend. More details on Trinity attendance policies are available here.\nHowever, there may be many reasons why you cannot be in class on a given day, particularly with possible extra personal and academic stress and health concerns this semester. All course lectures will be recorded and available to enrolled students after class. If you miss a lecture, make sure to watch the recording and review the material before the next class session. Lab time is dedicated to working on your assignments and collaborating with your teammates on your project. If you miss a lab session, make sure to communicate with your team about how you can make up your contribution. Given the technologies we use in the course, this is straightforward to do asynchronously. If you know you’re going to miss a lab session and you’re feeling well enough to do so, notify your teammates ahead of time. Overall these policies are put in place to ensure communication between team members, respect for each others’ time, and also to give you a safety net in the case of illness or other reasons that keep you away from attending class.\nNote that attendance and participation is part of your grade as well.\n\n\nAttendance policy related to COVID symptoms, exposure, or infection\nStudent health, safety, and well-being are the university’s top priorities. To help ensure your well-being and the well-being of those around you, please do not come to class if you have tested positive for COVID-19 or have possible symptoms and have not yet been tested. If any of these situations apply to you, you must follow university guidance related to the ongoing COVID-19 pandemic and current health and safety protocols. If you are experiencing any COVID-19 symptoms, contact student health (dshcheckin@duke.edu, 919- 681-9355). Learn more about current university policy related to COVID-19 at https://coronavirus.duke.edu. To keep the university community as safe and healthy as possible, you will be expected to follow these guidelines. Please reach out to me and your academic dean as soon as possible if you need to quarantine or isolate so that we can discuss arrangements for your continued participation in class.\n\n\nInclement weather policy\nIn the event of inclement weather or other connectivity-related events that prohibit class attendance, I will notify you how we will make up missed course content and work. This might entail holding the class on Zoom synchronously, we may rely on Duke’s designated make-up days, or you may be asked to watch a recording of the class.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#accommodations",
    "href": "course-syllabus.html#accommodations",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Accommodations",
    "text": "Accommodations\n\nAcademic accommodations\nIf you are a student with a disability and need accommodations for this class, it is your responsibility to register with the Student Disability Access Office (SDAO) and provide them with documentation of your disability. SDAO will work with you to determine what accommodations are appropriate for your situation. Please note that accommodations are not retroactive and disability accommodations cannot be provided until a Faculty Accommodation Letter has been given to me. Please contact SDAO for more information: sdao@duke.edu or access.duke.edu.\n\n\nReligious accommodations\nStudents are permitted by university policy to be absent from class to observe a religious holiday. Accordingly, Trinity College of Arts & Sciences and the Pratt School of Engineering have established procedures to be followed by students for notifying their instructors of an absence necessitated by the observance of a religious holiday. Please submit requests for religious accommodations at the beginning of the semester so that we can work to make suitable arrangements well ahead of time. You can find the policy and relevant notification form here: https://trinity.duke.edu/undergraduate/academic-policies/religious-holidays.\nNote: If you’ve read this far in the syllabus, email me a picture of your pet if you have one or your favorite meme!",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#sec-important-dates",
    "href": "course-syllabus.html#sec-important-dates",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Important dates",
    "text": "Important dates\n\nWednesday, May 15: Classes begin\nFriday, May 17: Drop/add ends\nMonday, May 27: Memorial Day - No lecture\nFriday, June 7: Exam - In class\nSunday, June 9: Exam - Take home due\nWednesday, June 12: Last day to withdraw with W\nMonday, June 24, 9:30 am -12:15 pm: Project presentations\nMonday, June 24: Classes end\nTuesday, June 25: Reading period\nWednesday, June 26: Project report due\n\nFor more important dates, see the full Duke Academic Calendar.",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "course-syllabus.html#footnotes",
    "href": "course-syllabus.html#footnotes",
    "title": "Syllabus: STA101 Summer 2024",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThese guiding principles are based on Course Policies related to ChatGPT and other AI Tools developed by Joel Gladd, Ph.D.↩︎",
    "crumbs": [
      "Course information",
      "Syllabus"
    ]
  },
  {
    "objectID": "exam_review/exam-review-sa.html",
    "href": "exam_review/exam-review-sa.html",
    "title": "Exam 1 Review",
    "section": "",
    "text": "In 2020, employees of Blizzard Entertainment circulated a spreadsheet to anonymously share salaries and recent pay increases amidst rising tension in the video game industry over wage disparities and executive compensation. (Source: Blizzard Workers Share Salaries in Revolt Over Pay)\nThe name of the data frame used for this analysis is blizzard_salary and the relevant variables are:\nThe top six rows of blizzard_salary are shown below:\n# A tibble: 409 × 4\n   percent_incr salary_type annual_salary performance_rating\n          &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt; &lt;chr&gt;             \n 1          1   Salaried               1  High              \n 2          1   Salaried               1  Successful        \n 3          1   Salaried               1  High              \n 4          1   Hourly             33987. Successful        \n 5         NA   Hourly             34798. High              \n 6         NA   Hourly             35360  &lt;NA&gt;              \n 7         NA   Hourly             37440  &lt;NA&gt;              \n 8          0   Hourly             37814. &lt;NA&gt;              \n 9          4   Hourly             41101. Top               \n10          1.2 Hourly             42328  &lt;NA&gt;              \n# ℹ 399 more rows"
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-1",
    "href": "exam_review/exam-review-sa.html#question-1",
    "title": "Exam 1 Review",
    "section": "Question 1",
    "text": "Question 1\nHow rows observations are there in the blizzard_salary dataset and what does each row represent?\n\nThere are 409 rows in the blizzard_salary dataset. Each row represents a Blizzard Entertainment worker who filled out the spreadsheet."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-2",
    "href": "exam_review/exam-review-sa.html#question-2",
    "title": "Exam 1 Review",
    "section": "Question 2",
    "text": "Question 2\nFigure 1 and Figure 2 show the distributions of annual salaries of hourly and salaried workers. The two figures show the same data, with the facets organized across rows and across columns. Which of the two figures is better for comparing the median annual salaries of hourly and salaried workers. Explain your reasoning.\n::: {#fig-blizzard-hist}\n\n\n\n\n\n\n\n\nFigure 1: Option 1\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Option 2\n\n\n\n\n\nDistribution of annual salaries of Blizzard employees\n\na - Figure 1 - A shared x-axis makes it easier to compare summary statistics for the variable on the x-axis."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-3",
    "href": "exam_review/exam-review-sa.html#question-3",
    "title": "Exam 1 Review",
    "section": "Question 3",
    "text": "Question 3\nSuppose your teammate wrote the following code as part of their analysis of the data.\nThey then printed out the results shown below. Unfortunately one of the number got erased from the printout, it’s indicated with _____ below.\n# A tibble: 2 × 3\n  salary_type mean_annual_salary median_annual_salary\n  &lt;chr&gt;                    &lt;dbl&gt;                &lt;dbl&gt;\n1 Hourly                  63003.               54246.\n2 Salaried                90183.               _____\nWhich of the following is the best estimate for that erased value?\n\n30,000\n50,000\n80,000\n100,000\n\n\nc - It’s a value higher than the median for hourly but lower than the mean for salaried."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-4",
    "href": "exam_review/exam-review-sa.html#question-4",
    "title": "Exam 1 Review",
    "section": "Question 4",
    "text": "Question 4\nWhich distribution has a higher standard deviation?\n\nHourly workers\nSalaried workers\nRoughly the same\n\n\nb - There is more variability around the mean compared to the hourly distribution."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-5",
    "href": "exam_review/exam-review-sa.html#question-5",
    "title": "Exam 1 Review",
    "section": "Question 5",
    "text": "Question 5\nWhich of the following alternate plots would also be useful for visualizing the distributions of annual salaries of hourly and salaried workers?\nI.  Box plot\nII. Density plot\nIII. Pie chart\n\nI\nI and II\nI, II, and III\nII and III\n\n\nb - Pie charts are for categorical data only."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-6",
    "href": "exam_review/exam-review-sa.html#question-6",
    "title": "Exam 1 Review",
    "section": "Question 6",
    "text": "Question 6\nNext, you fit a model for predicting raises (percent_incr) from salaries (annual_salary). We’ll call this model raise_1_fit. A tidy output of the model is shown below.\n\n\n# A tibble: 2 × 5\n  term           estimate  std.error statistic   p.value\n  &lt;chr&gt;             &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept)   1.87      0.432           4.33 0.0000194\n2 annual_salary 0.0000155 0.00000452      3.43 0.000669 \n\n\nWhich of the following is the best interpretation of the slope coefficient?\n\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.55%.\nFor every additional $1,000 of annual salary, the raise goes up by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 0.0155%.\nFor every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 1.87%.\n\n\nc - For every additional $1,000 of annual salary, the model predicts the raise to be higher, on average, by 0.0155%. (Note, for every additional $1 of annual salary, the model predicts the raise to be higher, on average, by 0.0000155%, so for every $1,000 (multiply by a 1000), the model predicts the raise to be higher, on average by 0.0000155*1000 = 0.0155%)."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-7",
    "href": "exam_review/exam-review-sa.html#question-7",
    "title": "Exam 1 Review",
    "section": "Question 7",
    "text": "Question 7\nYou then fit a model for predicting raises (percent_incr) from salaries (annual_salary) and performance ratings (performance_rating). We’ll call this model raise_2_fit. Which of the following is definitely true based on the information you have so far?\n\nIntercept of raise_2_fit is higher than intercept of raise_1_fit.\nRMSE of raise_2_fit is higher than RMSE of raise_1_fit.\nAdjusted \\(R^2\\) of raise_2_fit is higher than adjusted \\(R^2\\) of raise_1_fit.\n\\(R^2\\) of raise_2_fit is higher \\(R^2\\) of raise_1_fit.\n\n\nd - \\(R^2\\) of raise_2_fit is higher than \\(R^2\\) of raise_1_fit since raise_2_fit has one more predictor and \\(R^2\\) always goes up with the addition of a predictor."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-8",
    "href": "exam_review/exam-review-sa.html#question-8",
    "title": "Exam 1 Review",
    "section": "Question 8",
    "text": "Question 8\nThe tidy model output for the raise_2_fit model you fit is shown below.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic  p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;\n1 (Intercept)                   3.55       0.508           6.99 1.99e-11\n2 annual_salary                 0.00000989 0.00000436      2.27 2.42e- 2\n3 performance_ratingPoor       -4.06       1.42           -2.86 4.58e- 3\n4 performance_ratingSuccessful -2.40       0.397          -6.05 4.68e- 9\n5 performance_ratingTop         2.99       0.715           4.18 3.92e- 5\n\n\nWhen your teammate sees this model output, they remark “The coefficient for performance_ratingSuccessful is negative, that’s weird. I guess it means that people who get successful performance ratings get lower raises.” How would you respond to your teammate?\n\nThe reference level of performance_rating is High, since it’s the first level alphabetically. Therefore, the coefficient -2.40% is the predicted difference in raise comparing High to Successful. In this context a negative coefficient makes sense since we would expect those with High performance rating to get higher raises than those with Successful performance."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-9",
    "href": "exam_review/exam-review-sa.html#question-9",
    "title": "Exam 1 Review",
    "section": "Question 9",
    "text": "Question 9\nUltimately, your teammate decides they don’t like the negative slope coefficients in the model output you created (not that there’s anything wrong with negative slope coefficients!), does something else, and comes up with the following model output.\n\n\n# A tibble: 5 × 5\n  term                            estimate  std.error statistic    p.value\n  &lt;chr&gt;                              &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)                  -0.511      1.47          -0.347 0.729     \n2 annual_salary                 0.00000989 0.00000436     2.27  0.0242    \n3 performance_ratingSuccessful  1.66       1.42           1.17  0.242     \n4 performance_ratingHigh        4.06       1.42           2.86  0.00458   \n5 performance_ratingTop         7.05       1.53           4.60  0.00000644\n\n\nUnfortunately they didn’t write their code in a Quarto document, instead just wrote some code in the Console and then lost track of their work. They remember using the fct_relevel() function and doing something like the following:\nWhat should they put in the blanks to get the same model output as above?\n\n“Poor”, “Successful”, “High”, “Top”\n“Successful”, “High”, “Top”\n“Top”, “High”, “Successful”, “Poor”\nPoor, Successful, High, Top\n\n\na - “Poor”, “Successful”, “High”, “Top”"
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-10",
    "href": "exam_review/exam-review-sa.html#question-10",
    "title": "Exam 1 Review",
    "section": "Question 10",
    "text": "Question 10\nFinally, your teammate creates the following two plots and ask you for help deciding which one to use in the final report for visualizing the relationship between performance rating and salary type. In 1-3 sentences, can you help them make a decision, justify your choice, and write the narrative that should go with the plot?\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\nFigure 3: Distribution of salary type by performance rating\n\n\n\n\nChoose Option 2 since it shows the proportions of employees with top, high, successful, and poor performance within each salary type, and is not affected by there being much fewer hourly paid employees. Proportions of employees with top and successful performance ratings are higher for employees paid hourly than salaried."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-11",
    "href": "exam_review/exam-review-sa.html#question-11",
    "title": "Exam 1 Review",
    "section": "Question 11",
    "text": "Question 11\nA friend with a keen eye points out that the number of observations in Figure 3 (a) seems lower than the total number of observations in blizzard_salary. What might be going on here? Explain your reasoning.\n\nThere may be some NAs in these two variables that are not visible in the plot."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-12",
    "href": "exam_review/exam-review-sa.html#question-12",
    "title": "Exam 1 Review",
    "section": "Question 12",
    "text": "Question 12\nShow the proportions of performance ratings for hourly and salaried workers in a table and ask students to place those numbers on the segments of Figure 3 (b).\n\n\n# A tibble: 4 × 3\n  performance_rating Hourly Salaried\n  &lt;fct&gt;               &lt;dbl&gt;    &lt;dbl&gt;\n1 Successful          0.686   0.521 \n2 High                0.2     0.384 \n3 Top                 0.114   0.0760\n4 Poor                0       0.0190\n\n\n\nThe proportions under Hourly would go in the Hourly bar, and those under Salaried would go in the Salaried bar."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-13",
    "href": "exam_review/exam-review-sa.html#question-13",
    "title": "Exam 1 Review",
    "section": "Question 13",
    "text": "Question 13\nSuppose we fit a model to predict percent_incr from annual_salary and salary_type. A tidy output of the model is shown below.\n\n\n# A tibble: 3 × 5\n  term                 estimate  std.error statistic p.value\n  &lt;chr&gt;                   &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 (Intercept)         1.24      0.570           2.18 0.0300 \n2 annual_salary       0.0000137 0.00000464      2.96 0.00329\n3 salary_typeSalaried 0.913     0.544           1.68 0.0938 \n\n\nWhich of the following visualizations represent this model? Explain your reasoning.\n\n\n\n\n\n\n\n\n\n\n\n(a) Option 1\n\n\n\n\n\n\n\n\n\n\n\n(b) Option 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n(c) Option 3\n\n\n\n\n\n\n\n\n\n\n\n(d) Option 4\n\n\n\n\n\n\n\nFigure 4: Visualizations of the relationship between percent increase, annual salary, and salary type\n\n\n\n\nc - Option 3. Parallel lines and salaried line has a higher intercept since Hourly is the reference level in raise_3_fit and the slope for salary_typeSalaried is positive."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-14",
    "href": "exam_review/exam-review-sa.html#question-14",
    "title": "Exam 1 Review",
    "section": "Question 14",
    "text": "Question 14\nA professor gives a test to 100 students and determines the median score. After grading the test, they realize that the 10 students with the highest scores did exceptionally well. They decide to award these 10 students a bonus of 5 more points. The median of the new score distribution will be ____ the original median.\n\n, depending on skewness, higher or lower than\nequal to\nlower than\nhigher than\n\n\nb - equal to"
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-15",
    "href": "exam_review/exam-review-sa.html#question-15",
    "title": "Exam 1 Review",
    "section": "Question 15",
    "text": "Question 15\nSuppose we want to modify the release_country variable such that the levels are “United States” and “not United States”. Fill in the blanks in the code chunk below to accomplish this.\n\nmovies____________movies |&gt;\n      ____________(\n        release_country = if_else(\n        release_country____________\"United States\", \n        \"____________\",\n        \"____________\"\n        )\n)\n\n\n    movies &lt;- movies |&gt;\n      mutate(\n        release_country = if_else(\n          release_country == \"United States\", \n          \"United States\", \n          \"not United States\"\n        )\n     )"
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-16",
    "href": "exam_review/exam-review-sa.html#question-16",
    "title": "Exam 1 Review",
    "section": "Question 16",
    "text": "Question 16\nA researcher wants to build a multiple linear regression model to predict the score of a movie in from runtime for the movies in different types of genre.\nThe total sum of squares for the model \\(SS_{Total}\\) is found to be 0. You know that:\n\nevery runtime in every genre had the same amount\nevery movie had the same score\nthe model perfectly predicts score in every movie\nthe mean score must be 0\n\n\nb - every movie had the same score"
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-17",
    "href": "exam_review/exam-review-sa.html#question-17",
    "title": "Exam 1 Review",
    "section": "Question 17",
    "text": "Question 17\nChoose the best answer.\nA survey based on a random sample of 2,045 American teenagers found that a 95% confidence interval for the mean number of texts sent per month was (1450, 1550). A valid interpretation of this interval is\n\n95% of all teens who text send between 1450 and 1550 text messages per month.\nIf a new survey with the same sample size were to be taken, there is a 95% chance that the mean number of texts in the sample would be between 1450 and 1550.\nWe are 95% confident that the mean number of texts per month of all American teens is between 1450 and 1550.\nWe are 95% confident that, were we to repeat this survey, the mean number of texts per month of those taking part in the survey would be between 1450 and 1550.\n\n\nc - We are 95% confident that the mean number of texts per month of all American teens is between 1450 and 1550."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#question-18",
    "href": "exam_review/exam-review-sa.html#question-18",
    "title": "Exam 1 Review",
    "section": "Question 18",
    "text": "Question 18\n\nWrite the theoretical model that regresses weight on m_age, weeks, and premature. Be sure to define each term (i.e., \\(y= -----\\)).\n\nThen, using the output below, write the fitted model.\n\n\n# A tibble: 4 × 5\n  term            estimate std.error statistic     p.value\n  &lt;chr&gt;              &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;\n1 (Intercept)      -4.35      2.10       -2.07 0.0404     \n2 m_age             0.0270    0.0142      1.90 0.0594     \n3 weeks             0.281     0.0509      5.52 0.000000153\n4 prematurepremie  -1.01      0.398      -2.54 0.0121     \n\n\n\n\\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_3\\)\nwhere \\(y\\) is the weight of the baby, \\(x_1\\) is the mother’s age, \\(x_2\\) is weeks at which mom gave birth, and \\(x_3\\) is an indicator of whether the baby was a premie.\n\\(\\widehat{weight} = -4.35 + 0.027 \\times m\\_age + 0.281\\times weeks - 1.01 premature_{premie}\\)\n\n\nInterpret the intercept, in 1 sentence.\n\n\nNon-premie babies that were born at zero weeks to a moms aged 0 weight, on average, -4.35 lbs. (note, doesn’t make much sense in the context of this problem)\n\n\nInterpret the slope for premie, in 1 sentence.\n\n\nAll else held constant, premies are expected to weigh 1.01 less than non premature babies, on average."
  },
  {
    "objectID": "exam_review/exam-review-sa.html#bonus",
    "href": "exam_review/exam-review-sa.html#bonus",
    "title": "Exam 1 Review",
    "section": "Bonus",
    "text": "Bonus\nPick a concept we introduced in class so far that you’ve been struggling with and explain it in your own words."
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html",
    "title": "Confidence intervals with bootstrapping",
    "section": "",
    "text": "Exam:\n\nIn class: Fri, June 7th (1 sheet of notes allowed)\nTake home due Sun, June 9th\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::%||%()   masks base::%||%()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5          ✔ rsample      1.2.0     \n✔ dials        1.2.0          ✔ tune         1.1.2     \n✔ infer        1.0.5.9000     ✔ workflows    1.1.3     \n✔ modeldata    1.2.0          ✔ workflowsets 1.0.1     \n✔ parsnip      1.1.1          ✔ yardstick    1.2.0     \n✔ recipes      1.0.8          \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::%||%()     masks base::%||%()\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#announcements",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#announcements",
    "title": "Confidence intervals with bootstrapping",
    "section": "",
    "text": "Exam:\n\nIn class: Fri, June 7th (1 sheet of notes allowed)\nTake home due Sun, June 9th"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#packages",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#packages",
    "title": "Confidence intervals with bootstrapping",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::%||%()   masks base::%||%()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5          ✔ rsample      1.2.0     \n✔ dials        1.2.0          ✔ tune         1.1.2     \n✔ infer        1.0.5.9000     ✔ workflows    1.1.3     \n✔ modeldata    1.2.0          ✔ workflowsets 1.0.1     \n✔ parsnip      1.1.1          ✔ yardstick    1.2.0     \n✔ recipes      1.0.8          \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::%||%()     masks base::%||%()\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Dig deeper into tidy modeling with R at https://www.tmwr.org\n\nlibrary(openintro)\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#case-study-3-airbnb-in-asheville-nc",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#case-study-3-airbnb-in-asheville-nc",
    "title": "Confidence intervals with bootstrapping",
    "section": "Case study 3: Airbnb in Asheville, NC",
    "text": "Case study 3: Airbnb in Asheville, NC\nWe have data on the price per guest (ppg) for a random sample of 50 Airbnb listings in 2020 for Asheville, NC. We are going to use these data to investigate what we would of expected to pay for an Airbnb in in Asheville, NC in June 2020.\n\nabb &lt;- read_csv(\"asheville.csv\")\n\nglimpse(abb)\n\nRows: 50\nColumns: 1\n$ ppg &lt;dbl&gt; 48.00000, 40.00000, 99.00000, 13.00000, 55.00000, 75.00000, 74.000…"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#terminology",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#terminology",
    "title": "Confidence intervals with bootstrapping",
    "section": "Terminology",
    "text": "Terminology\n\nPopulation parameter - What we are interested in. Statistical measure that describes an entire population.\nSample statistic (point estimate) - describes a sample. A piece of information you get from a fraction of the population.\n\n\nabb |&gt; \n  summarize(ppg.mean = mean(ppg))\n\n# A tibble: 1 × 1\n  ppg.mean\n     &lt;dbl&gt;\n1     76.6"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#catching-a-fish",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#catching-a-fish",
    "title": "Confidence intervals with bootstrapping",
    "section": "Catching a fish",
    "text": "Catching a fish\n\nSuppose you’re fishing in a murky lake. Are you more likely to catch a fish using a spear or a net?\n\n\nSpear \\(\\rightarrow\\) point estimate\nNet \\(\\rightarrow\\) interval estimate"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#constructing-confidence-intervals",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#constructing-confidence-intervals",
    "title": "Confidence intervals with bootstrapping",
    "section": "Constructing confidence intervals",
    "text": "Constructing confidence intervals\nQuantifying the variability of the sample statistics to help calculate a range of plausible values for the population parameter of interest:\n\nVia simulation \\(\\rightarrow\\) using bootstrapping – using a statistical procedure that re samples a single data set to create many simulated samples.\nVia mathematical formulas \\(\\rightarrow\\) using the Central Limit Theorem"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#bootstrapping-what",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#bootstrapping-what",
    "title": "Confidence intervals with bootstrapping",
    "section": "Bootstrapping, what?",
    "text": "Bootstrapping, what?\n\nThe term bootstrapping comes from the phrase “pulling oneself up by one’s bootstraps”, which is a metaphor for accomplishing an impossible task without any outside help.\nImpossible task: estimating a population parameter using data from only the given sample.\n\n\n\n\n\n\n\nNote\n\n\n\nNote: This notion of saying something about a population parameter using only information from an observed sample is the crux of statistical inference, it is not limited to bootstrapping."
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#bootstrapping-how",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#bootstrapping-how",
    "title": "Confidence intervals with bootstrapping",
    "section": "Bootstrapping, how?",
    "text": "Bootstrapping, how?\n\nResample with replacement from our data \\(n\\) times, where \\(n\\) is the sample size\nCalculate the sample statistic of interest of the new, resampled (bootstrapped) sample and record the value\nDo this entire process many many times to build the bootstrap distribution"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#bootstrapping-airbnb-rentals",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#bootstrapping-airbnb-rentals",
    "title": "Confidence intervals with bootstrapping",
    "section": "Bootstrapping Airbnb rentals",
    "text": "Bootstrapping Airbnb rentals\n\nset.seed(25) \n\nboot_dist_abb &lt;- abb |&gt;\n  specify(response = ppg) |&gt;\n  generate(reps = 100, type = \"bootstrap\") |&gt;\n  calculate(stat = \"mean\")"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#the-bootstrap-distribution",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#the-bootstrap-distribution",
    "title": "Confidence intervals with bootstrapping",
    "section": "The bootstrap distribution",
    "text": "The bootstrap distribution\n\nglimpse(boot_dist_abb)\n\nRows: 100\nColumns: 2\n$ replicate &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1…\n$ stat      &lt;dbl&gt; 73.11500, 78.78333, 80.19333, 83.42000, 70.15000, 73.03667, …"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#visualzing-the-bootstrap-distribution",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#visualzing-the-bootstrap-distribution",
    "title": "Confidence intervals with bootstrapping",
    "section": "Visualzing the bootstrap distribution",
    "text": "Visualzing the bootstrap distribution\n\nWhat do you expect the center of the bootstrap distribution to be? Why? Check your guess by visualizing the distribution.\n\n\nggplot(boot_dist_abb, aes(x = stat)) + \n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#calculating-the-bootstrap-distribution",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#calculating-the-bootstrap-distribution",
    "title": "Confidence intervals with bootstrapping",
    "section": "Calculating the bootstrap distribution",
    "text": "Calculating the bootstrap distribution\n\nboot_dist_abb |&gt;\n  summarize(\n    lower = quantile(stat, 0.025),\n    upper = quantile(stat, 0.975)\n  )\n\n# A tibble: 1 × 2\n  lower upper\n  &lt;dbl&gt; &lt;dbl&gt;\n1  64.7  89.6"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#interpretation",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#interpretation",
    "title": "Confidence intervals with bootstrapping",
    "section": "Interpretation",
    "text": "Interpretation\n\nWhich of the following is the correct interpretation of the bootstrap interval?\n\n\nThere is a 95% probability the true mean price per night for an Airbnb in Asheville is between $64.7 and $89.6.\nThere is a 95% probability the price per night for an Airbnb in Asheville is between $64.7 and $89.6.\nWe are 95% confident the true mean price per night for Airbnbs in Asheville is between $64.7 and $89.6.\nWe are 95% confident the price per night for an Airbnb in Asheville is between $64.7 and $89.6."
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#leveraging-tidymodels-tools-further",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#leveraging-tidymodels-tools-further",
    "title": "Confidence intervals with bootstrapping",
    "section": "Leveraging tidymodels tools further",
    "text": "Leveraging tidymodels tools further\nCalculating the observed sample statistic:\n\nobs_stat_abb &lt;- abb |&gt;\n  specify(response = ppg) |&gt;\n  calculate(stat = \"mean\")  \n\nobs_stat_abb\n\nResponse: ppg (numeric)\n# A tibble: 1 × 1\n   stat\n  &lt;dbl&gt;\n1  76.6"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#leveraging-tidymodels-tools-further-1",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#leveraging-tidymodels-tools-further-1",
    "title": "Confidence intervals with bootstrapping",
    "section": "Leveraging tidymodels tools further",
    "text": "Leveraging tidymodels tools further\nCalculating the interval:\n\nci_95_abb &lt;- boot_dist_abb |&gt;\n  get_confidence_interval(\n    point_estimate = obs_stat_abb, \n    level = 0.95\n  )\n\nci_95_abb\n\n# A tibble: 1 × 2\n  lower_ci upper_ci\n     &lt;dbl&gt;    &lt;dbl&gt;\n1     64.7     89.6"
  },
  {
    "objectID": "lectures/11/11-confidence-intervals-bootstrapping.html#leveraging-tidymodels-tools-further-2",
    "href": "lectures/11/11-confidence-intervals-bootstrapping.html#leveraging-tidymodels-tools-further-2",
    "title": "Confidence intervals with bootstrapping",
    "section": "Leveraging tidymodels tools further",
    "text": "Leveraging tidymodels tools further\nVisualizing the interval:\n\nvisualize(boot_dist_abb) +\n  shade_confidence_interval(ci_95_abb)"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html",
    "href": "lectures/05/05-explore-numerical.html",
    "title": "Explore numerical data",
    "section": "",
    "text": "Lab 2 is due Wed, May 22 at 11:59 pm on Gradescope\nPlease, come to class on time!\n\n\n\n\n\nSuppose you have a data frame called df and a single variable in it called x. How many variables will df have after running the following code?\n\ndf |&gt;\n  mutate(y = x + 2)\n\n\n. . .\n\nSuppose you have a data frame called df and a single variable in it called x. How many variables will df have after running the following code?\n\ndf &lt;- df |&gt;\n  mutate(y = x + 2)\n\n\n. . .\n\nWhat is the &lt;- operator called and what does it do?"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#announcements",
    "href": "lectures/05/05-explore-numerical.html#announcements",
    "title": "Explore numerical data",
    "section": "",
    "text": "Lab 2 is due Wed, May 22 at 11:59 pm on Gradescope\nPlease, come to class on time!"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#recap-from-last-time",
    "href": "lectures/05/05-explore-numerical.html#recap-from-last-time",
    "title": "Explore numerical data",
    "section": "",
    "text": "Suppose you have a data frame called df and a single variable in it called x. How many variables will df have after running the following code?\n\ndf |&gt;\n  mutate(y = x + 2)\n\n\n. . .\n\nSuppose you have a data frame called df and a single variable in it called x. How many variables will df have after running the following code?\n\ndf &lt;- df |&gt;\n  mutate(y = x + 2)\n\n\n. . .\n\nWhat is the &lt;- operator called and what does it do?"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#durham-city-and-county-resident-survey",
    "href": "lectures/05/05-explore-numerical.html#durham-city-and-county-resident-survey",
    "title": "Explore numerical data",
    "section": "2020 Durham City and County Resident Survey",
    "text": "2020 Durham City and County Resident Survey\nWe’ll continue working with this dataset."
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#services",
    "href": "lectures/05/05-explore-numerical.html#services",
    "title": "Explore numerical data",
    "section": "Services",
    "text": "Services"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#demographics",
    "href": "lectures/05/05-explore-numerical.html#demographics",
    "title": "Explore numerical data",
    "section": "Demographics",
    "text": "Demographics\n\n\n\n\n\nThe main questions we’ll explore today are:\n\n“What are the demographics and priorities of City of Durham residents?”\n“How do City of Durham residents feel about quality of services by the city and how, if at all, does that vary by income?”"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#exercise-1",
    "href": "lectures/05/05-explore-numerical.html#exercise-1",
    "title": "Explore numerical data",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize and describe the relationship between income and home ownership of Durham residents.\nStretch goal: Customize the colors using named colors from http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#exercise-2",
    "href": "lectures/05/05-explore-numerical.html#exercise-2",
    "title": "Explore numerical data",
    "section": "Exercise 2",
    "text": "Exercise 2\nCalculate the proportions of home owners for each category of Durham residents. Describe the relationship between these two variables, this time with the actual values from the conditional distribution of home ownership based on income level.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#exercise-3",
    "href": "lectures/05/05-explore-numerical.html#exercise-3",
    "title": "Explore numerical data",
    "section": "Exercise 3",
    "text": "Exercise 3\nRecode the levels of these two variables to be more informatively labeled and calculate the proportions from the previous exercise again.\n\n# add code here"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#exercise-4",
    "href": "lectures/05/05-explore-numerical.html#exercise-4",
    "title": "Explore numerical data",
    "section": "Exercise 4",
    "text": "Exercise 4\nOne of the questions on the survey is “How satisfied are you with the overall quality of services provided by the city?” A response of 1 indicates Very Dissatisfied and a response of 5 indicates Very Satisfied. The responses for this question are in the variable qos_city. This could be considered an ordinal, categorical variable but can also be treated as a numerical variable in an analysis. Let’s do the latter!\nVisualize and describe the distribution of qos_city. If you get a warning with your visualization, comment on what it means.\nAdd your response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#exercise-5",
    "href": "lectures/05/05-explore-numerical.html#exercise-5",
    "title": "Explore numerical data",
    "section": "Exercise 5",
    "text": "Exercise 5\nCalculate the mean and median of the distribution of qos_city. If these values are not exactly the same, can you explain what the difference might be attributed to?\nAdd your response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#exercise-6",
    "href": "lectures/05/05-explore-numerical.html#exercise-6",
    "title": "Explore numerical data",
    "section": "Exercise 6",
    "text": "Exercise 6\nBased on the shape of the distribution of qos_city, which measure of spread (variability) is more appropriate? Calculate that value and interpret it in context of the data.\n\n# add code here"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#exercise-7",
    "href": "lectures/05/05-explore-numerical.html#exercise-7",
    "title": "Explore numerical data",
    "section": "Exercise 7",
    "text": "Exercise 7\nMake a box plot of qos_city and comment on how the values you calculated map on to the box plot.\n\n# add code here"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#exercise-8",
    "href": "lectures/05/05-explore-numerical.html#exercise-8",
    "title": "Explore numerical data",
    "section": "Exercise 8",
    "text": "Exercise 8\nHow the average level of happiness with quality of services provided by the city vary by income group?\nStretch goal: Visualize mean qos_city by income group.\nAdd your response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#conceptual",
    "href": "lectures/05/05-explore-numerical.html#conceptual",
    "title": "Explore numerical data",
    "section": "Conceptual",
    "text": "Conceptual\nSome of the terms we introduced are:\n\nMarginal distribution: Distribution of a single variable.\nConditional distribution: Distribution of a variable conditioned on the values (or levels, in the context of categorical data) of another."
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#r",
    "href": "lectures/05/05-explore-numerical.html#r",
    "title": "Explore numerical data",
    "section": "R",
    "text": "R\nIn this lecture we:\n\nDefined factors – the data type that R uses for categorical variables, i.e., variables that can take on values from a finite set of levels.\nReviewed data imports, visualization, and wrangling functions encountered before:\n\nImport: read_csv(): Read data from a CSV (comma separated values) file\nVisualization:\n\nggplot(): Create a plot using the ggplot2 package\naes(): Map variables from the data to aesthetic elements of the plot, generally passed as an argument to ggplot() or to geom_*() functions (define only x or y aesthetic)\ngeom_bar(): Represent data with bars, after calculating heights of bars under the hood\ngeom_histogram(): Represent data with a histogram\ngeom_boxplot(): Represent data with a box plot\ngeom_point(): Represent data with points\nlabs(): Label x axis, y axis, legend for color of plot, title` of plot, etc.\n\nWrangling:\n\nmutate(): Mutate the data frame by creating a new column or overwriting one of the existing columns\ncount(): Count the number of observations for each level of a categorical variable (factor) or each distinct value of any other type of variable\ngroup_by(): Perform each subsequent action once per each group of the variable, where groups can be defined based on the levels of one or more variables\nsummarize(): Calculate summary statistics\n\n\nIntroduced new data wrangling functions:\n\nrename(): Rename columns in a data frame\nas_factor(): Convert a variable to a factor\ndrop_na(): Drop rows that have NA in one ore more specified variables\nif_else(): Write logic for what happens if a condition is true and what happens if it’s not\ncase_when(): Write a generalized if_else() logic for more than one condition\nfct_relevel: Change the order of levels in a factor\n\nIntroduced new data visualization functions:\n\ngeom_col(): Represent data with bars (columns), for heights that have already been calculated (must define x and y aesthetics)\nscale_fill_viridis_d(): Customize the discrete fill scale, using a color-blind friendly, ordinal discrete color scale\nscale_y_discrete(): Customize the discrete y scale\nscale_fill_manual(): Customize the fill scale by manually adjusting values for colors"
  },
  {
    "objectID": "lectures/05/05-explore-numerical.html#quarto",
    "href": "lectures/05/05-explore-numerical.html#quarto",
    "title": "Explore numerical data",
    "section": "Quarto",
    "text": "Quarto\nWe also introduced chunk options for managing figure sizes:\n\nfig-width: Width of figure\nfig-asp: Aspect ratio of figure (height / width)\nfig-height: Height of figure – but I recommend using fig-width and fig-asp, instead of fig-width and fig-height"
  },
  {
    "objectID": "lectures/08/08-model-selection.html",
    "href": "lectures/08/08-model-selection.html",
    "title": "Model selection",
    "section": "",
    "text": "Project proposal due Tuesday, May 28th.\nLab 3 due Wednesday, May 29th.\nOffice Hours tomorrow: 3:00 - 4:00 pm instead."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#announcements",
    "href": "lectures/08/08-model-selection.html#announcements",
    "title": "Model selection",
    "section": "",
    "text": "Project proposal due Tuesday, May 28th.\nLab 3 due Wednesday, May 29th.\nOffice Hours tomorrow: 3:00 - 4:00 pm instead."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#two-r2s",
    "href": "lectures/08/08-model-selection.html#two-r2s",
    "title": "Model selection",
    "section": "Two \\(R^2\\)s",
    "text": "Two \\(R^2\\)s\n\n\\(R^2\\) measures the proportion of variability in the outcome variable that is explained by the model.\n\nAlways goes up with the addition of a predictor.\nAdjusted \\(R^2\\) is this value adjusted to penalize for the number of predictors in the model.\nGoes up if the added predictor is “useful”, i.e. actually increases the predictive performance of the model.\nTherefore we use this metric for choosing between models. Today we’ll explore the question “What best predicts what percent of the bill amount people tip at restaurants?”"
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-1",
    "href": "lectures/08/08-model-selection.html#exercise-1",
    "title": "Model selection",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize the relationship between these variables.\n\n# add code here"
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-2",
    "href": "lectures/08/08-model-selection.html#exercise-2",
    "title": "Model selection",
    "section": "Exercise 2",
    "text": "Exercise 2\nIn a couple of sentences, describe any apparent patterns.\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-3",
    "href": "lectures/08/08-model-selection.html#exercise-3",
    "title": "Model selection",
    "section": "Exercise 3",
    "text": "Exercise 3\nFit a model predicting tip percentage from bill amount. Display and interpret the model coefficients. Additionally, calculate and interpret the \\(R^2\\) of this model.\n\n# add code here\n\n\nAdd response here.\n\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-4",
    "href": "lectures/08/08-model-selection.html#exercise-4",
    "title": "Model selection",
    "section": "Exercise 4",
    "text": "Exercise 4\nSuppose we next add meal as a predictor and interpret the model coefficients again.\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-5",
    "href": "lectures/08/08-model-selection.html#exercise-5",
    "title": "Model selection",
    "section": "Exercise 5",
    "text": "Exercise 5\nWould you expect the \\(R^2\\) of the second model (with bill and meal as predictors) to be higher, lower, or the same as the \\(R^2\\) for the first model (with only bill as the predictor)? Explain your reasoning.\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-6",
    "href": "lectures/08/08-model-selection.html#exercise-6",
    "title": "Model selection",
    "section": "Exercise 6",
    "text": "Exercise 6\nFit a model predicting tip percentage from bill amount and meal, calculate its \\(R^2\\), and comment on your guess from the previous exercise.\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-7",
    "href": "lectures/08/08-model-selection.html#exercise-7",
    "title": "Model selection",
    "section": "Exercise 7",
    "text": "Exercise 7\nCalculate adjusted \\(R^2\\) for the two models. Is adding meal to a model predicting tip_percentage from bill useful?\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#backward-elimination",
    "href": "lectures/08/08-model-selection.html#backward-elimination",
    "title": "Model selection",
    "section": "Backward elimination",
    "text": "Backward elimination\nBackward elimination starts with the full model (the model that includes all potential predictor variables). Variables are eliminated one-at-a-time from the model until we cannot improve the model any further.\nProcedure:\n\nStart with a model that has all predictors we consider and compute the adjusted \\(R^2\\).\nNext fit every possible model with 1 fewer predictor.\nCompare adjusted \\(R^2\\)s to select the best model (highest adjusted \\(R^2\\)) with 1 fewer predictor.\nRepeat steps 2 and 3 until adjusted \\(R^2\\) no longer increases."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#forward-selection",
    "href": "lectures/08/08-model-selection.html#forward-selection",
    "title": "Model selection",
    "section": "Forward selection",
    "text": "Forward selection\nForward selection is the reverse of the backward elimination technique. Instead, of eliminating variables one-at-a-time, we add variables one-at-a-time until we cannot find any variables that improve the model any further.\nProcedure:\n\nStart with a model that has no predictors.\nNext fit every possible model with 1 additional predictor and calculate adjusted \\(R^2\\) of each model.\nCompare adjusted \\(R^2\\) values to select the best model (highest adjusted \\(R^2\\)) with 1 additional predictor.\nRepeat steps 2 and 3 until adjusted \\(R^2\\) no longer increases."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-8",
    "href": "lectures/08/08-model-selection.html#exercise-8",
    "title": "Model selection",
    "section": "Exercise 8",
    "text": "Exercise 8\nPerform backward elimination to find the best model for predicting tip_percentage from meal, party, alcohol, bill.\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-9",
    "href": "lectures/08/08-model-selection.html#exercise-9",
    "title": "Model selection",
    "section": "Exercise 9",
    "text": "Exercise 9\nPerform forward selection to find the best model for predicting tip_percentage from meal, party, alcohol, bill.\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#exercise-10",
    "href": "lectures/08/08-model-selection.html#exercise-10",
    "title": "Model selection",
    "section": "Exercise 10",
    "text": "Exercise 10\nFit the “best” model and interpret it.\n\n# add code here\n\n\nAdd response here."
  },
  {
    "objectID": "lectures/08/08-model-selection.html#footnotes",
    "href": "lectures/08/08-model-selection.html#footnotes",
    "title": "Model selection",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDahlquist, Samantha, and Jin Dong. 2011. “The Effects of Credit Cards on Tipping.” Project for Statistics 212-Statistics for the Sciences, St. Olaf College.↩︎"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html",
    "href": "lectures/04/04-explore-categorical.html",
    "title": "Explore categorical data",
    "section": "",
    "text": "The main question we’ll explore today is “What are the demographics and priorities of City of Durham residents?”"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#sample-survey-questions---demographics-todays-focus",
    "href": "lectures/04/04-explore-categorical.html#sample-survey-questions---demographics-todays-focus",
    "title": "Explore categorical data",
    "section": "",
    "text": "The main question we’ll explore today is “What are the demographics and priorities of City of Durham residents?”"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-1",
    "href": "lectures/04/04-explore-categorical.html#exercise-1",
    "title": "Explore categorical data",
    "section": "Exercise 1",
    "text": "Exercise 1\nHow many rows and columns are in this dataset? Answer in a full sentence using inline code. What does each row represent and what does each column represent?\nAdd your answer here."
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-2",
    "href": "lectures/04/04-explore-categorical.html#exercise-2",
    "title": "Explore categorical data",
    "section": "Exercise 2",
    "text": "Exercise 2\nThe variables we’ll use in this analysis are as follows. Rename the variables to the updated names shown below.\n\n\n\nOriginal name\nUpdated name\n\n\n\n\nprimary_language\nprimary_language\n\n\ndo_you_own_or_rent_your_current_resi_31\nown_rent\n\n\nwould_you_say_your_total_annual_hous_35\nincome\n\n\n\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-3",
    "href": "lectures/04/04-explore-categorical.html#exercise-3",
    "title": "Explore categorical data",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat language do Durham residents speak: primary_language?\n\nWhat is the primary language used in your household?\n\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-4",
    "href": "lectures/04/04-explore-categorical.html#exercise-4",
    "title": "Explore categorical data",
    "section": "Exercise 4",
    "text": "Exercise 4\nMake similar bar plots of own_rent and income. What distinct values do these variables take?\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-5",
    "href": "lectures/04/04-explore-categorical.html#exercise-5",
    "title": "Explore categorical data",
    "section": "Exercise 5",
    "text": "Exercise 5\nThe variables own_rent and income are both categorical, but they’re stored as numbers. In R, categorical data are called factors. Recode these variables as factors with the as_factor() function.\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-6",
    "href": "lectures/04/04-explore-categorical.html#exercise-6",
    "title": "Explore categorical data",
    "section": "Exercise 6",
    "text": "Exercise 6\nRecreate the visualization from the previous exerciseincome` barplot, improving it for both visual appeal and better communication of findings.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-7",
    "href": "lectures/04/04-explore-categorical.html#exercise-7",
    "title": "Explore categorical data",
    "section": "Exercise 7",
    "text": "Exercise 7\nRecreate the visualization from the previous exercise, but first calculate relative frequencies (proportions) of income (the marginal distribution) and plot the proportions instead of counts.\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-8",
    "href": "lectures/04/04-explore-categorical.html#exercise-8",
    "title": "Explore categorical data",
    "section": "Exercise 8",
    "text": "Exercise 8\nVisualize and describe the relationship between income and home ownership of Durham residents.\nStretch goal: Customize the colors using named colors from http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-9",
    "href": "lectures/04/04-explore-categorical.html#exercise-9",
    "title": "Explore categorical data",
    "section": "Exercise 9",
    "text": "Exercise 9\nCalculate the proportions of home owners for each category of Durham residents. Describe the relationship between these two variables, this time with the actual values from the conditional distribution of home ownership based on income level.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#exercise-10",
    "href": "lectures/04/04-explore-categorical.html#exercise-10",
    "title": "Explore categorical data",
    "section": "Exercise 10",
    "text": "Exercise 10\nStretch goal: Recode the levels of these two variables to be more informatively labeled and calculate the proportions from the previous exercise again.\n\n# add code here"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#conceptual",
    "href": "lectures/04/04-explore-categorical.html#conceptual",
    "title": "Explore categorical data",
    "section": "Conceptual",
    "text": "Conceptual\nSome of the terms we introduced are:\n\nMarginal distribution: Distribution of a single variable.\nConditional distribution: Distribution of a variable conditioned on the values (or levels, in the context of categorical data) of another."
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#r",
    "href": "lectures/04/04-explore-categorical.html#r",
    "title": "Explore categorical data",
    "section": "R",
    "text": "R\nIn this application exercise we:\n\nDefined factors – the data type that R uses for categorical variables, i.e., variables that can take on values from a finite set of levels.\n\n\n\nReviewed data imports, visualization, and wrangling functions encountered before:\n\nImport: read_csv(): Read data from a CSV (comma separated values) file\nVisualization:\n\nggplot(): Create a plot using the ggplot2 package\naes(): Map variables from the data to aesthetic elements of the plot, generally passed as an argument to ggplot() or to geom_*() functions (define only x or y aesthetic)\ngeom_bar(): Represent data with bars, after calculating heights of bars under the hood\nlabs(): Label x axis, y axis, legend for color of plot, title` of plot, etc.\n\nWrangling:\n\nmutate(): Mutate the data frame by creating a new column or overwriting one of the existing columns\ncount(): Count the number of observations for each level of a categorical variable (factor) or each distinct value of any other type of variable\ngroup_by(): Perform each subsequent action once per each group of the variable, where groups can be defined based on the levels of one or more variables\n\n\nIntroduced new data wrangling functions:\n\nrename(): Rename columns in a data frame\nas_factor(): Convert a variable to a factor\ndrop_na(): Drop rows that have NA in one ore more specified variables\nif_else(): Write logic for what happens if a condition is true and what happens if it’s not\ncase_when(): Write a generalized if_else() logic for more than one codition\n\nIntroduced new data visualization functions:\n\ngeom_col(): Represent data with bars (columns), for heights that have already been calculated (must define x and y aesthetics)\nscale_fill_viridis_d(): Customize the discrete fill scale, using a color-blind friendly, ordinal discrete color scale\nscale_y_discrete(): Customize the discrete y scale\nscale_fill_manual(): Customize the fill scale by manually adjusting values for colors"
  },
  {
    "objectID": "lectures/04/04-explore-categorical.html#quarto",
    "href": "lectures/04/04-explore-categorical.html#quarto",
    "title": "Explore categorical data",
    "section": "Quarto",
    "text": "Quarto\nWe also introduced chunk options for managing figure sizes:\n\nfig-width: Width of figure\nfig-asp: Aspect ratio of figure (height / width)\nfig-height: Height of figure – but I recommend using fig-width and fig-asp, instead of fig-width and fig-height"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html",
    "href": "lectures/13/13-inference-mathematical-models_clean.html",
    "title": "Inference with mathematical models",
    "section": "",
    "text": "Last day to drop with a W is tomorrow!"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#announcements",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#announcements",
    "title": "Inference with mathematical models",
    "section": "",
    "text": "Last day to drop with a W is tomorrow!"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#the-distribution-of-the-sample-statistic",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#the-distribution-of-the-sample-statistic",
    "title": "Inference with mathematical models",
    "section": "The distribution of the sample statistic",
    "text": "The distribution of the sample statistic\nYou can build the distribution of the sample statistic by repeatedly taking samples of size n (original sample size) from the population and calculating and recording the sample statistic for each of these samples.\n\nBut, you would never do this in reality!\nYou’d either use simulation (randomization, bootstrapping, stuff we’ve done so far!) or you would leverage mathematical theory to know what to expect if we had taken repeated samples."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#the-technical-conditions",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#the-technical-conditions",
    "title": "Inference with mathematical models",
    "section": "The (technical) conditions",
    "text": "The (technical) conditions\n\nIndependent observations: Observations in the sample are independent. Independence is guaranteed when we take a random sample from a population. Independence can also be guaranteed if we randomly divide individuals into treatment and control groups.\nLarge enough sample: The sample size cannot be too small. What qualifies as “small” differs from one context (i.e., from sample statistic to sample statistic)."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#more-to-the-clt",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#more-to-the-clt",
    "title": "Inference with mathematical models",
    "section": "More to the CLT",
    "text": "More to the CLT\n\nThere is more to the CLT than just the shape of the distribution – normal.\nThe CLT says that the center of the sampling distribution will be at the true population parameter.\nThe CLT also says something about the spread of the sampling distribution, measured by the standard error. For each sample statistic (\\(\\bar{x}\\) – the sample mean, \\(\\hat{p}\\) – the sample proportion, \\(\\bar{x}_1 - \\bar{x}_2\\) – the difference in sample means, etc.) the CLT provides a formula for its standard error.\n\nYou won’t be asked to memorize these formulas.\nIn fact, you’ll rarely use the CLT to calculate the variability of sample statistics, you’ll simulate their distributions directly."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#the-68-95-99.7-rule",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#the-68-95-99.7-rule",
    "title": "Inference with mathematical models",
    "section": "The 68-95-99.7 rule",
    "text": "The 68-95-99.7 rule\nThe normal distribution is not just any unimodal and symmetric distribution, it follows the 68-95-99.7 rule."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#using-the-normal-distribution",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#using-the-normal-distribution",
    "title": "Inference with mathematical models",
    "section": "Using the normal distribution…",
    "text": "Using the normal distribution…\n\nTo make decisions \\(\\rightarrow\\) hypothesis testing\n\nUse properties of the normal distribution to determine the probability of the observed sample statistic (or something more extreme, in the direction of the alternative hypothesis), i.e. the p-value\n\nTo make estimations \\(\\rightarrow\\) confidence intervals\n\nUse properties of the normal distribution to calculate the bounds of the confidence interval, adding and subtracting a margin of error to the observed sample statistic"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-1",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-1",
    "title": "Inference with mathematical models",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize the distribution of bone density of 65-year-old women.\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-2",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-2",
    "title": "Inference with mathematical models",
    "section": "Exercise 2",
    "text": "Exercise 2\nBefore typing any code, based on what you know about the normal distribution, what do you expect the median bone density to be?\nAdd response here."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-3",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-3",
    "title": "Inference with mathematical models",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat bone densities correspond to Q1 (25th percentile), Q2 (50th percentile), and Q3 (the 75th percentile) of this distribution? Use the qnorm() function to calculate these values.\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-4",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-4",
    "title": "Inference with mathematical models",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe densities of three woods are below:\n\nPlywood: 540 \\(mg/cm^3\\)\nPine: 600 \\(mg/cm^3\\)\nMahogany: 710 \\(mg/cm^3\\)\n\nLet’s set these as variables we can use later:\n\nplywood &lt;- 540\npine &lt;- 600\nmahogany &lt;- 710\n\nWhat is the probability that a randomly selected 65-year-old woman has bones less dense than Pine?\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-5",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-5",
    "title": "Inference with mathematical models",
    "section": "Exercise 5",
    "text": "Exercise 5\nWould you be surprised if a randomly selected 65-year-old woman had bone density less than Mahogany? What if she had bone density less than Plywood? Use the respective probabilities to support your response.\nAdd response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-6",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-6",
    "title": "Inference with mathematical models",
    "section": "Exercise 6",
    "text": "Exercise 6\nAre the conditions for the Central Limit Theorem met?\nAdd response here."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-7",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-7",
    "title": "Inference with mathematical models",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhat is the shape, center, and spread of the distribution of the mean bone density for a group of 10 randomly selected 65-year-old women?\nAdd response here."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-8",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-8",
    "title": "Inference with mathematical models",
    "section": "Exercise 8",
    "text": "Exercise 8\nWhat is the probability that the mean bone density for the group of 10 randomly-selected 65-year-old women is less dense than Pine?\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-9",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-9",
    "title": "Inference with mathematical models",
    "section": "Exercise 9",
    "text": "Exercise 9\nWould you be surprised if a group of 10 randomly-selected 65-year old women had a mean bone density less than Mahogany? What the group had a mean bone density less than Plywood? Use the respective probabilities to support your response.\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models_clean.html#exercise-10",
    "href": "lectures/13/13-inference-mathematical-models_clean.html#exercise-10",
    "title": "Inference with mathematical models",
    "section": "Exercise 10",
    "text": "Exercise 10\nExplain how your answers differ in similar sounding earlier vs. later exercises.\nAdd response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html",
    "title": "Inference with mathematical models",
    "section": "",
    "text": "Last day to drop with a W is tomorrow!"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#announcements",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#announcements",
    "title": "Inference with mathematical models",
    "section": "",
    "text": "Last day to drop with a W is tomorrow!"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#that-familiar-shape",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#that-familiar-shape",
    "title": "Inference with mathematical models",
    "section": "That familiar shape…",
    "text": "That familiar shape…\n\nDescribe the shape of the distributions."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#its-not-happenstance",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#its-not-happenstance",
    "title": "Inference with mathematical models",
    "section": "It’s not happenstance!",
    "text": "It’s not happenstance!\nIt’s the Central Limit Theorem (or CLT), which says that the distribution of the sample statistic is normal, if certain conditions are met.\n\nTwo questions:\n\nWhat do we mean by the distribution of the sample statistic?\nWhat conditions need to be met?"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#the-distribution-of-the-sample-statistic",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#the-distribution-of-the-sample-statistic",
    "title": "Inference with mathematical models",
    "section": "The distribution of the sample statistic",
    "text": "The distribution of the sample statistic\n\nYou can build the distribution of the sample statistic by repeatedly taking samples of size \\(n\\) (original sample size) from the population and calculating and recording the sample statistic for each of these samples.\nBut, you would never do this in reality!\nYou’d either use simulation (randomization, bootstrapping, stuff we’ve done so far!) or you would leverage mathematical theory to know what to expect if we had taken repeated samples."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#the-technical-conditions",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#the-technical-conditions",
    "title": "Inference with mathematical models",
    "section": "The (technical) conditions",
    "text": "The (technical) conditions\n\nIndependent observations: Observations in the sample are independent. Independence is guaranteed when we take a random sample from a population. Independence can also be guaranteed if we randomly divide individuals into treatment and control groups.\nLarge enough sample: The sample size cannot be too small. What qualifies as “small” differs from one context (i.e., from sample statistic to sample statistic).\n\n\n\n\n\n\n\nImportant\n\n\n\nNOTE: if the population distribution is normal, the sampling distribution will be normal (can use CLT even if the sample size is small)."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#more-to-the-clt",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#more-to-the-clt",
    "title": "Inference with mathematical models",
    "section": "More to the CLT",
    "text": "More to the CLT\n\nThere is more to the CLT than just the shape of the distribution – normal.\nThe CLT says that the center of the sampling distribution will be at the true population parameter.\nThe CLT also says something about the spread of the sampling distribution, measured by the standard error. For each sample statistic (\\(\\bar{x}\\) – the sample mean, \\(\\hat{p}\\) – the sample proportion, \\(\\bar{x}_1 - \\bar{x}_2\\) – the difference in sample means, etc.) the CLT provides a formula for its standard error.\n\nYou won’t be asked to memorize these formulas.\nIn fact, you’ll rarely use the CLT to calculate the variability of sample statistics, you’ll simulate their distributions directly."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#clt-for-proportions",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#clt-for-proportions",
    "title": "Inference with mathematical models",
    "section": "CLT for proportions",
    "text": "CLT for proportions\n\nIf we look at a proportion (or difference in proportions) and the scenario satisfies certain conditions, then the sample proportion (or difference in proportions) will appear to follow a bell-shaped curve called the normal distribution."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#clt-for-means",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#clt-for-means",
    "title": "Inference with mathematical models",
    "section": "CLT for means",
    "text": "CLT for means\n\nLet \\(x\\) be the variable of interest. Suppose \\(x\\) follows a distribution with mean \\(\\mu\\) and standard deviation is \\(\\sigma\\). When certain criteria are satisfied, the sample mean \\(\\bar x\\) of sample of size \\(n\\) is normally distributed. Specifically \\[\\bar x \\sim N(\\mu, \\sigma/\\sqrt{n}),\\] i.e. \\(\\bar x\\) is normally distributed with mean \\(\\mu\\) and standard deviation \\(\\sigma/\\sqrt{n}\\). The standard deviation of the sampling distribution is called the standard error."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#normal-distributions",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#normal-distributions",
    "title": "Inference with mathematical models",
    "section": "Normal distributions",
    "text": "Normal distributions\n\nHow are these normal distributions similar? How are they different? Which one is \\(N(\\mu = 0, \\sigma = 1)\\) and which \\(N(\\mu = 19, \\sigma = 4)\\)?"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#the-68-95-99.7-rule",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#the-68-95-99.7-rule",
    "title": "Inference with mathematical models",
    "section": "The 68-95-99.7 rule",
    "text": "The 68-95-99.7 rule\nThe normal distribution is not just any unimodal and symmetric distribution, it follows the 68-95-99.7 rule."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#using-the-normal-distribution",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#using-the-normal-distribution",
    "title": "Inference with mathematical models",
    "section": "Using the normal distribution…",
    "text": "Using the normal distribution…\n\nTo make decisions \\(\\rightarrow\\) hypothesis testing\n\nUse properties of the normal distribution to determine the probability of the observed sample statistic (or something more extreme, in the direction of the alternative hypothesis), i.e. the p-value\n\nTo make estimations \\(\\rightarrow\\) confidence intervals\n\nUse properties of the normal distribution to calculate the bounds of the confidence interval, adding and subtracting a margin of error to the observed sample statistic"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-1",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-1",
    "title": "Inference with mathematical models",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize the distribution of bone density of 65-year-old women.\n\n# option 1: ggplot2\n\ndf &lt;- tibble(x = c(bone_density_mean - bone_density_sd*3, \n                   bone_density_mean + bone_density_sd*3))\n\nggplot(df, aes(x = x)) +\n  stat_function(\n    fun = dnorm,\n    args = list(mean = bone_density_mean, \n                sd = bone_density_sd))\n\n\n\n\n\n\n\n# option 2: openintro -- shortcut\n\nnormTail(m = bone_density_mean, s = bone_density_sd)"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-2",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-2",
    "title": "Inference with mathematical models",
    "section": "Exercise 2",
    "text": "Exercise 2\nBefore typing any code, based on what you know about the normal distribution, what do you expect the median bone density to be?\n\n\\(809 mg/cm^3\\) since the mean and median are equal for symmetric distributions."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-3",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-3",
    "title": "Inference with mathematical models",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat bone densities correspond to Q1 (25th percentile), Q2 (50th percentile), and Q3 (the 75th percentile) of this distribution? Use the qnorm() function to calculate these values.\n\nqnorm(p = 0.25, mean = bone_density_mean, sd = bone_density_sd)\n\n[1] 714.5714\n\nqnorm(p = 0.5, mean = bone_density_mean, sd = bone_density_sd)\n\n[1] 809\n\nqnorm(p = 0.75, mean = bone_density_mean, sd = bone_density_sd)\n\n[1] 903.4286\n\n\n\n809 - 714.5414\n\n[1] 94.4586\n\n903.4286 - 809\n\n[1] 94.4286"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-4",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-4",
    "title": "Inference with mathematical models",
    "section": "Exercise 4",
    "text": "Exercise 4\nThe densities of three woods are below:\n\nPlywood: 540 \\(mg/cm^3\\)\nPine: 600 \\(mg/cm^3\\)\nMahogany: 710 \\(mg/cm^3\\)\n\nLet’s set these as variables we can use later:\n\nplywood &lt;- 540\npine &lt;- 600\nmahogany &lt;- 710\n\nWhat is the probability that a randomly selected 65-year-old woman has bones less dense than Pine?\n\nnormTail(m = bone_density_mean, s = bone_density_sd, L = pine)\n\n\n\n\n\n\n\n\n\npnorm(q = pine, mean = bone_density_mean, sd = bone_density_sd)\n\n[1] 0.06773729"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-5",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-5",
    "title": "Inference with mathematical models",
    "section": "Exercise 5",
    "text": "Exercise 5\nWould you be surprised if a randomly selected 65-year-old woman had bone density less than Mahogany? What if she had bone density less than Plywood? Use the respective probabilities to support your response.\nAdd response here.\n\nnormTail(m = bone_density_mean, s = bone_density_sd, L = mahogany)\n\n\n\n\n\n\n\npnorm(q = mahogany, mean = bone_density_mean, sd = bone_density_sd)\n\n[1] 0.2397389\n\nnormTail(m = bone_density_mean, s = bone_density_sd, L = plywood)\n\n\n\n\n\n\n\npnorm(q = plywood, mean = bone_density_mean, sd = bone_density_sd)\n\n[1] 0.02733885"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-6",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-6",
    "title": "Inference with mathematical models",
    "section": "Exercise 6",
    "text": "Exercise 6\nAre the conditions for the Central Limit Theorem met?\n\nIndependence - yes because individuals are randomly selected\nSample size/ distribution: Yes, sample size is small, but the population distribution is normal, so the sampling distribution will be normal as well."
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-7",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-7",
    "title": "Inference with mathematical models",
    "section": "Exercise 7",
    "text": "Exercise 7\nWhat is the shape, center, and spread of the distribution of the mean bone density for a group of 10 randomly selected 65-year-old women?\n\nShape: bell curve, symmetric\nCenter: population mean: 809\nStandard deviation: smaller than 140\n\n\\(\\bar x \\sim N(\\mu = 809, SE = 140/\\sqrt{10})\\)"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-8",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-8",
    "title": "Inference with mathematical models",
    "section": "Exercise 8",
    "text": "Exercise 8\nWhat is the probability that the mean bone density for the group of 10 randomly-selected 65-year-old women is less dense than Pine?\n\nbone_density_se = 140/sqrt(10)\n\n\nnormTail(m = bone_density_mean, s = bone_density_se, L = pine)\n\n\n\n\n\n\n\npnorm(q = pine, mean = bone_density_mean, sd = bone_density_se)\n\n[1] 1.174428e-06"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-9",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-9",
    "title": "Inference with mathematical models",
    "section": "Exercise 9",
    "text": "Exercise 9\nWould you be surprised if a group of 10 randomly-selected 65-year old women had a mean bone density less than Mahogany? What the group had a mean bone density less than Plywood? Use the respective probabilities to support your response.\n\nnormTail(m = bone_density_mean, s = bone_density_se, L = mahogany)\n\n\n\n\n\n\n\npnorm(q = mahogany, mean = bone_density_mean, sd = bone_density_se)\n\n[1] 0.01266992\n\nnormTail(m = bone_density_mean, s = bone_density_se, L = plywood)\n\n\n\n\n\n\n\npnorm(q = plywood, mean = bone_density_mean, sd = bone_density_se)\n\n[1] 6.157391e-10"
  },
  {
    "objectID": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-10",
    "href": "lectures/13/13-inference-mathematical-models-filled-in.html#exercise-10",
    "title": "Inference with mathematical models",
    "section": "Exercise 10",
    "text": "Exercise 10\nExplain how your answers differ in similar sounding earlier vs. later exercises.\nAdd response here.\n\nggplot(\n  data = tibble(x = c(bone_density_mean - bone_density_sd*3, bone_density_mean + bone_density_sd*3)),\n  aes(x = x)) +\n  stat_function(\n    fun = dnorm, \n    args = list(mean = bone_density_mean, sd = bone_density_sd)\n  ) +\n  stat_function(\n    fun = dnorm, \n    args = list(mean = bone_density_mean, sd = 44),\n    linetype = \"dashed\",\n    color = \"blue\"\n  ) +\n  geom_vline(\n    xintercept = c(plywood, pine, mahogany),\n    color = c(\"#deb887\", \"#01796f\", \"#c04000\"),\n    linewidth = 1\n  ) +\n  annotate(\n    geom = \"label\",\n    x = c(plywood, pine, mahogany),\n    y = c(0.006, 0.007, 0.008),\n    color = c(\"#deb887\", \"#01796f\", \"#c04000\"),\n    label = c(\"plywood\", \"pine\", \"mahogany\")\n  ) +\n  annotate(\n    geom = \"text\",\n    x = 1000, y = 0.0018,\n    label = \"Population\\ndistribution\",\n    hjust = 0,\n    fontface = \"bold\"\n  ) +\n  annotate(\n    geom = \"text\",\n    x = 875, y = 0.005,\n    label = \"Sampling\\ndistribution\",\n    hjust = 0,\n    fontface = \"bold\",\n    color = \"blue\"\n  )"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html",
    "href": "lectures/15/15-inference-one-proportion.html",
    "title": "Inference for a proportion",
    "section": "",
    "text": "Lab 6 due 11:59 pm\nIntro and EDA due 11:59 pm\nEmail your reviewer!"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#announcements",
    "href": "lectures/15/15-inference-one-proportion.html#announcements",
    "title": "Inference for a proportion",
    "section": "",
    "text": "Lab 6 due 11:59 pm\nIntro and EDA due 11:59 pm\nEmail your reviewer!"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#proportions",
    "href": "lectures/15/15-inference-one-proportion.html#proportions",
    "title": "Inference for a proportion",
    "section": "Proportions",
    "text": "Proportions\n\nIf the parameter of interest is a single population proportion, what type of and how many variables are being studied?"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-1",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-1",
    "title": "Inference for a proportion",
    "section": "Exercise 1",
    "text": "Exercise 1\nWhat, if anything, do you know about voter turnout in the US?\nAdd response here."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-2",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-2",
    "title": "Inference for a proportion",
    "section": "Exercise 2",
    "text": "Exercise 2\nLoad the data and visualize the distribution of responses. Also calculate the proportion of respondents who are certain to vote in the next presidential election.\n\n# add code here"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-3",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-3",
    "title": "Inference for a proportion",
    "section": "Exercise 3",
    "text": "Exercise 3\nWhat is the parameter of interest?\nAdd response here."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-4",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-4",
    "title": "Inference for a proportion",
    "section": "Exercise 4",
    "text": "Exercise 4\nEstimate using a 95% bootstrap interval.\n\n# add code here"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-5",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-5",
    "title": "Inference for a proportion",
    "section": "Exercise 5",
    "text": "Exercise 5\nSuppose the bounds of this interval are L and U, your friend interprets the interval as\n\n95% of the time, the true proportion of proportion of registered US voters who are certain to vote in the next presidential election is between L and U.\n\nComment on this interpretation. Is it correct? If not, how would ix it?\nAdd response here."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-6",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-6",
    "title": "Inference for a proportion",
    "section": "Exercise 6",
    "text": "Exercise 6\nWhat are the hypotheses?\nAdd response here."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-7",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-7",
    "title": "Inference for a proportion",
    "section": "Exercise 7",
    "text": "Exercise 7\nConduct a randomization test, at 5% discernability level, for this claim. What is the conclusion of the test?\n\n# add code here"
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-8",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-8",
    "title": "Inference for a proportion",
    "section": "Exercise 8",
    "text": "Exercise 8\nSuppose the p-value you found is P, and your friends are in disagreement about the interpretation about this value. One friend claims:\n\nThe probability that 60% of all of registered US voters are certain to vote in the next presidential election is P.\n\nAnother friend claims:\n\nThe probability that more than 60% of all of registered US voters are certain to vote in the next presidential election is P.\n\nWho is right? Explain your reasoning.\nAdd response here."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-9",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-9",
    "title": "Inference for a proportion",
    "section": "Exercise 9",
    "text": "Exercise 9\nWhat is \\(p\\) vs. \\(\\hat{p}\\) vs. p-value. Explain generically as well as in the context of these data and research question.\nAdd response here."
  },
  {
    "objectID": "lectures/15/15-inference-one-proportion.html#exercise-10",
    "href": "lectures/15/15-inference-one-proportion.html#exercise-10",
    "title": "Inference for a proportion",
    "section": "Exercise 10",
    "text": "Exercise 10\nWhat is sampling distribution vs. bootstrap distribution vs. null distribution? Explain generically as well as in the context of these data and research question.\nAdd response here."
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html",
    "href": "lectures/09/09-logistic-regression.html",
    "title": "Logistic regression",
    "section": "",
    "text": "Feedback on project proposals by the end of the week.\nExam review will be posted by the end of the week.\nExam:\n\nIn class: Fri, June 7th (1 sheet of notes allowed)\nTake home due Sun, June 9th"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#check-in",
    "href": "lectures/09/09-logistic-regression.html#check-in",
    "title": "Logistic regression",
    "section": "",
    "text": "Feedback on project proposals by the end of the week.\nExam review will be posted by the end of the week.\nExam:\n\nIn class: Fri, June 7th (1 sheet of notes allowed)\nTake home due Sun, June 9th"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#so-far-in-regression",
    "href": "lectures/09/09-logistic-regression.html#so-far-in-regression",
    "title": "Logistic regression",
    "section": "So far in regression",
    "text": "So far in regression\n\nOutcome: Numerical, Predictor: One numerical or one categorical with only two levels \\(\\rightarrow\\) Simple linear regression\nOutcome: Numerical, Predictors: Any number of numerical or categorical variables with any number of levels \\(\\rightarrow\\) Multiple linear regression\nOutcome: Categorical with only two levels, Predictors: Any number of numerical or categorical variables with any number of levels \\(\\rightarrow\\) Logistic regression\nOutcome: Categorical with any number of levels, Predictors: Any number of numerical or categorical variables with any number of levels \\(\\rightarrow\\) Generalized linear models – Not covered in STA 101"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#data-packages",
    "href": "lectures/09/09-logistic-regression.html#data-packages",
    "title": "Logistic regression",
    "section": "Data + packages",
    "text": "Data + packages\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nhp_spam &lt;- read_csv(\"hp-spam.csv\")\n\n\n4601 emails collected at Hewlett-Packard labs and contains 58 variables\nOutcome: type\n\ntype = 1 is spam\ntype = 0 is non-spam\n\nPredictors of interest:\n\ncapitalTotal: Number of capital letters in email\nPercentages are calculated as (100 * number of times the WORD appears in the e-mail) / total number of words in email\n\ngeorge: Percentage of “george”s in email (these were George’s emails)\nyou: Percentage of “you”s in email"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#glimpse-at-data",
    "href": "lectures/09/09-logistic-regression.html#glimpse-at-data",
    "title": "Logistic regression",
    "section": "Glimpse at data",
    "text": "Glimpse at data\n\nWhat type of data is type? What type should it be in order to use logistic regression?\n\n\nhp_spam |&gt;\n  select(type, george, capitalTotal, you)\n\n# A tibble: 4,601 × 4\n    type george capitalTotal   you\n   &lt;dbl&gt;  &lt;dbl&gt;        &lt;dbl&gt; &lt;dbl&gt;\n 1     1      0          278  1.93\n 2     1      0         1028  3.47\n 3     1      0         2259  1.36\n 4     1      0          191  3.18\n 5     1      0          191  3.18\n 6     1      0           54  0   \n 7     1      0          112  3.85\n 8     1      0           49  0   \n 9     1      0         1257  1.23\n10     1      0          749  1.67\n# ℹ 4,591 more rows"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#eda-how-much-spam",
    "href": "lectures/09/09-logistic-regression.html#eda-how-much-spam",
    "title": "Logistic regression",
    "section": "EDA: How much spam?",
    "text": "EDA: How much spam?\n\nhp_spam |&gt;\n  count(type) |&gt;\n  mutate(p = n / sum(n))\n\n# A tibble: 2 × 3\n   type     n     p\n  &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt;\n1     0  2788 0.606\n2     1  1813 0.394"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#eda-am-i-screaming-capitaltotal",
    "href": "lectures/09/09-logistic-regression.html#eda-am-i-screaming-capitaltotal",
    "title": "Logistic regression",
    "section": "EDA: AM I SCREAMING? capitalTotal",
    "text": "EDA: AM I SCREAMING? capitalTotal\n\nggplot(hp_spam, aes(x = capitalTotal)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#eda-george-is-that-you",
    "href": "lectures/09/09-logistic-regression.html#eda-george-is-that-you",
    "title": "Logistic regression",
    "section": "EDA: george, is that you?",
    "text": "EDA: george, is that you?\nggplot(hp_spam, aes(x = george)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\nggplot(hp_spam, aes(x = you)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#logistic-regression-1",
    "href": "lectures/09/09-logistic-regression.html#logistic-regression-1",
    "title": "Logistic regression",
    "section": "Logistic regression",
    "text": "Logistic regression\n\nLogistic regression takes in a number of predictors and outputs the probability of a “success” (an outcome of 1) in a binary outcome variable.\nThe probability is related to the predictors via a sigmoid link function, \\[\np(y_i = 1) = \\frac{1}{1+\\text{exp}({- \\sum \\beta_i x_i })},\n\\]whose output is in \\((0,1)\\) (a probability).\nCan also be written as\n\n\\[\np(y_i = 1) = \\frac{\\text{exp}({\\sum \\beta_ix_i})}{1 + \\text{exp}({\\sum \\beta_ix_i})}\n\\]\nor in logit form\n\\[\n\\text{logit}(p) = \\log(\\frac{p}{1 - p}) = \\sum\\beta_ix_i\n\\]\nwhere \\(p = p(y_i = 1)\\).\n\nIn this modeling scheme, one typically finds \\(\\hat{\\beta}\\) by maximizing the likelihood function, another objective function, different than our previous “least squares” objective (we do not need to worry about these details in this class)."
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#logistic-regression-visualized",
    "href": "lectures/09/09-logistic-regression.html#logistic-regression-visualized",
    "title": "Logistic regression",
    "section": "Logistic regression, visualized",
    "text": "Logistic regression, visualized"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#using-data-to-estimate-beta_i",
    "href": "lectures/09/09-logistic-regression.html#using-data-to-estimate-beta_i",
    "title": "Logistic regression",
    "section": "Using data to estimate \\(\\beta_i\\)",
    "text": "Using data to estimate \\(\\beta_i\\)\nTo proceed with building our email classifier, we will, as usual, use our data (outcome \\(y_i\\) and predictor \\(x_i\\) pairs), to estimate \\(\\beta\\) (find \\(\\hat{\\beta}\\)) and obtain the model: \\[\np(y_i = 1) = \\frac{1}{1+\\text{exp}({- \\sum  \\hat{\\beta}_i x_i})},\n\\]\nIn this lecture, we’ll build a spam filter. Or, at least, learn a bit about how spam filters are built by building a very simple (likely not very effective) one."
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-1",
    "href": "lectures/09/09-logistic-regression.html#exercise-1",
    "title": "Logistic regression",
    "section": "Exercise 1",
    "text": "Exercise 1\nOne predictor model: Visualize a linear model where the outcome is type (spam or not) and george is the only predictor. Then, discuss your visualization with your neighbor. Is this a good model? Why or why not?\nAdd response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-2",
    "href": "lectures/09/09-logistic-regression.html#exercise-2",
    "title": "Logistic regression",
    "section": "Exercise 2",
    "text": "Exercise 2\nTwo predictor model: In this exercise focus on two predictors: you and capitalTotal.\n\nCreate a visualization with you on the x-axis and capitalTotal on the y-axis. Color data points by whether or not they are spam (type). Make sure that type is being used as a categorical variable (factor).\n\n\n# add code here\n\n\nFit the model predicting type from you and capitalTotal. Comment on how the code differs from code used in previous models we fit. Also comment on how it’s similar.\n\n\n# add code here"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-3",
    "href": "lectures/09/09-logistic-regression.html#exercise-3",
    "title": "Logistic regression",
    "section": "Exercise 3",
    "text": "Exercise 3\nWrite the model equation.\nAdd response here."
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-4",
    "href": "lectures/09/09-logistic-regression.html#exercise-4",
    "title": "Logistic regression",
    "section": "Exercise 4",
    "text": "Exercise 4\nWhat is the probability the email is spam if the frequency of you is 5% in the email and there are 2500 capital letters.\n\nFirst, so this “by hand” (using R as a calculator) and the model you wrote in the previous exercise.\n\n\n# add code here\n\n\nThen, do it using R functions designed for prediction.\n\n\n# add code here"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-5",
    "href": "lectures/09/09-logistic-regression.html#exercise-5",
    "title": "Logistic regression",
    "section": "Exercise 5",
    "text": "Exercise 5\n\nWhat would you set your decision boundary to and why?\nChange decision_boundary in the code above to 0.01 and 0.999999. Do the results surprise you? Why or why not?\n\nAdd response here."
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-6",
    "href": "lectures/09/09-logistic-regression.html#exercise-6",
    "title": "Logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nIf you set a lower decision boundary, do you label fewer or more emails as spam? What happens if you set 0 as your boundary? What about 1 as your boundary? If you very much dislike spam, should you set a high or low boundary?\nAdd response here."
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-6-1",
    "href": "lectures/09/09-logistic-regression.html#exercise-6-1",
    "title": "Logistic regression",
    "section": "Exercise 6",
    "text": "Exercise 6\nUsing your model, predict whether this email will be classified as spam or not. What does the model predict for the probability that this email is spam? With a decision boundary of 0.5, how does the model classify thie email? Do you believe this classification? Why or why not?\n\n# add code here\n\nAdd response here."
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-7",
    "href": "lectures/09/09-logistic-regression.html#exercise-7",
    "title": "Logistic regression",
    "section": "Exercise 7",
    "text": "Exercise 7\nInspect hp_spam_split. How many emails are in hp_spam_train, how many are in hp_spam_test. Check out the documentation for the initial_split() function, what ratio does it use for splitting the dataset into training and testing samples?\nAdd response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-8",
    "href": "lectures/09/09-logistic-regression.html#exercise-8",
    "title": "Logistic regression",
    "section": "Exercise 8",
    "text": "Exercise 8\nTrain your model on the training set. Build a predictive model using any combination of predictors from hp_spam to predict type. Save your fitted model as my_model_fit and display its tidy summary.\n\n# add code here"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-9",
    "href": "lectures/09/09-logistic-regression.html#exercise-9",
    "title": "Logistic regression",
    "section": "Exercise 9",
    "text": "Exercise 9\nMake predictions for your testing set and augment your testing set with these predictions.\n\n# add code here"
  },
  {
    "objectID": "lectures/09/09-logistic-regression.html#exercise-10",
    "href": "lectures/09/09-logistic-regression.html#exercise-10",
    "title": "Logistic regression",
    "section": "Exercise 10",
    "text": "Exercise 10\nWhat are the false positive and false negative rates of this model?\n\n# add code here\n\nAdd response here."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html",
    "href": "lectures/16/16-inference-two-proportions.html",
    "title": "Inference for two proportions",
    "section": "",
    "text": "Peer review due Sunday at 11:59 pm\nIf you have not emailed your reviewer yet, do so (and cc me)!"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#announcements",
    "href": "lectures/16/16-inference-two-proportions.html#announcements",
    "title": "Inference for two proportions",
    "section": "",
    "text": "Peer review due Sunday at 11:59 pm\nIf you have not emailed your reviewer yet, do so (and cc me)!"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#nc-poll-on-equality",
    "href": "lectures/16/16-inference-two-proportions.html#nc-poll-on-equality",
    "title": "Inference for two proportions",
    "section": "NC poll on equality",
    "text": "NC poll on equality\nA September 16-19, 2023, asked North Carolina voters, among other issues, about issues of equality and women’s progress. Specifically, one of the questions asked:\n\nWhich of these two statements come closest to your own views—even if neither is exactly right?\n\nThe country has made most of the changes needed to give women equal rights with men.\nThe country needs to continue to make changes to give women equal rights to men."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#sta-101-vs.-nc",
    "href": "lectures/16/16-inference-two-proportions.html#sta-101-vs.-nc",
    "title": "Inference for two proportions",
    "section": "STA 101 vs. NC",
    "text": "STA 101 vs. NC\n\nHow do you think the distribution of responses from this class would compare to the NC polling results?\na. Similar distribution of answers between the two polls.\nb. Higher percentage of “The country has made most of the changes needed to give women equal rights with men” in STA 101 compared to NC poll.\nc. Lower percentage of “The country has made most of the changes needed to give women equal rights with men” in STA 101 compared to NC poll."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-1",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-1",
    "title": "Inference for two proportions",
    "section": "Exercise 1",
    "text": "Exercise 1\nThe two populations of interest in this survey are 18-24 year olds and 25+ year olds. State the hypotheses for evaluating whether there is a discernible difference between the proportions of those who think “The country needs to continue to make changes to give women equal rights to men.” (need more changes) in the two age groups.\nAdd response here."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-2",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-2",
    "title": "Inference for two proportions",
    "section": "Exercise 2",
    "text": "Exercise 2\nLoad the data.\n\n# add code here"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-3",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-3",
    "title": "Inference for two proportions",
    "section": "Exercise 3",
    "text": "Exercise 3\nCreate a 2x2 table of the responses across the two age groups.\n\n# add code here"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-4",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-4",
    "title": "Inference for two proportions",
    "section": "Exercise 4",
    "text": "Exercise 4\nWhat proportion of 18-24 year olds think “The country needs to continue to make changes to give women equal rights to men”? What proportion of 25+ year olds? Calculate and visualize these proportions.\n\n# add code here"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-5",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-5",
    "title": "Inference for two proportions",
    "section": "Exercise 5",
    "text": "Exercise 5\nCalculate the observed sample statistic, i.e., the difference between the proportions of respondents who think “The country needs to continue to make changes to give women equal rights to men” between the two age groups.\n\n# add code here"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-6",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-6",
    "title": "Inference for two proportions",
    "section": "Exercise 6",
    "text": "Exercise 6\nWhat is the parameter of interest?\nAdd response here."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-7",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-7",
    "title": "Inference for two proportions",
    "section": "Exercise 7",
    "text": "Exercise 7\nExplain how you can set up a simulation for this hypothesis test.\nAdd response here."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-8",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-8",
    "title": "Inference for two proportions",
    "section": "Exercise 8",
    "text": "Exercise 8\nConduct the hypothesis test using randomization and visualize and report the p-value.\n\n# add code here"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-9",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-9",
    "title": "Inference for two proportions",
    "section": "Exercise 9",
    "text": "Exercise 9\nWhat is the conclusion of the hypothesis test?\nAdd response here."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-10",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-10",
    "title": "Inference for two proportions",
    "section": "Exercise 10",
    "text": "Exercise 10\nInterpret the p-value in the context of the data and the hypotheses.\nAdd response here."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-11",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-11",
    "title": "Inference for two proportions",
    "section": "Exercise 11",
    "text": "Exercise 11\nEstimate the difference in population proportions of 18-24 year old NC voters and 25+ year old NC voters using a 95% bootstrap interval.\n\n# add code here"
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-12",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-12",
    "title": "Inference for two proportions",
    "section": "Exercise 12",
    "text": "Exercise 12\nInterpret the confidence interval in context of the data.\nAdd response here."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-13",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-13",
    "title": "Inference for two proportions",
    "section": "Exercise 13",
    "text": "Exercise 13\nDescribe how the simulation scheme for bootstrapping is different than that for the hypothesis test.\nAdd response here."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-14",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-14",
    "title": "Inference for two proportions",
    "section": "Exercise 14",
    "text": "Exercise 14\nWhat is \\(p\\) vs. \\(\\hat{p}\\) vs. p-value. Explain generically as well as in the context of these data and research question.\nAdd response here."
  },
  {
    "objectID": "lectures/16/16-inference-two-proportions.html#exercise-15",
    "href": "lectures/16/16-inference-two-proportions.html#exercise-15",
    "title": "Inference for two proportions",
    "section": "Exercise 15",
    "text": "Exercise 15\nWhat is sampling distribution vs. bootstrap distribution vs. null distribution? Explain generically as well as in the context of these data and research question.\nAdd response here."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html",
    "title": "Regression with multiple predictors",
    "section": "",
    "text": "No lab or class on Monday, May 27th.\nProject proposal due Tuesday, May 28th.\nLab 3 due Wednesday, May 29th.\n\n\n\n\n\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(scatterplot3d)"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#announcements",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#announcements",
    "title": "Regression with multiple predictors",
    "section": "",
    "text": "No lab or class on Monday, May 27th.\nProject proposal due Tuesday, May 28th.\nLab 3 due Wednesday, May 29th."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#load-packages-and-data",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#load-packages-and-data",
    "title": "Regression with multiple predictors",
    "section": "",
    "text": "library(tidyverse)\nlibrary(tidymodels)\nlibrary(scatterplot3d)"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#r2",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#r2",
    "title": "Regression with multiple predictors",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\\(R^2\\), aka “the coefficient of determination” or “correlation squared” is a way to see how well a given model fits the data.\n\\[\nR^2 = r^2\n\\]"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#sum-of-squares-total-sst",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#sum-of-squares-total-sst",
    "title": "Regression with multiple predictors",
    "section": "Sum of squares total, SST",
    "text": "Sum of squares total, SST\nThe sum of squares total is a measure of the total variability in the outcome variable:\n\\[\nSST = (y_1 - \\bar{y})^2 + (y_2 - \\bar{y})^2 + \\cdots + (y_n - \\bar{y})^2\n\\]"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#sum-of-squares-residuals-sse",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#sum-of-squares-residuals-sse",
    "title": "Regression with multiple predictors",
    "section": "Sum of squares residuals, SSE",
    "text": "Sum of squares residuals, SSE\nThe sum of squares residuals (error) is a measure of the variability in the residuals, i.e., variability left unexplained in the outcome variable after the model is fit:\n\\[\nSSE = (y_1 - \\hat{y}_1)^2 + (y_2 - \\hat{y}_2)^2 + \\cdots + (y_n - \\hat{y}_n)^2\n\\]"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#r2-another-look",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#r2-another-look",
    "title": "Regression with multiple predictors",
    "section": "\\(R^2\\), another look",
    "text": "\\(R^2\\), another look\n\\[\nR^2 = \\frac{SST - SSE}{SST} = 1 - \\frac{SSE}{SST}\n\\]\n. . .\n\nThis can be summarized as “\\(R^2\\) is 1 minus the sum of squared residuals divided by the sum of squared total”.\n\n. . .\n\nIn other words, \\(R^2\\) is the proportion of variability in the outcome that is explained by the model."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#r2-1",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#r2-1",
    "title": "Regression with multiple predictors",
    "section": "\\(R^2\\)",
    "text": "\\(R^2\\)\n\n\nIf the sum of squared residuals is 0, then the model explains all variability and \\(R^2 = 1 - 0 = 1\\).\nIf the sum of squared residuals is the same as all the variability in the data, then model does not explain any variability and \\(R^2 = 1 - 1 = 0\\).\n\\(R^2\\) is a measure of the proportion of variability the model explains. An \\(R^2\\) of 0 is a poor fit and \\(R^2\\) of 1 is a perfect fit."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#finding-r2",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#finding-r2",
    "title": "Regression with multiple predictors",
    "section": "Finding \\(R^2\\)",
    "text": "Finding \\(R^2\\)\nTo find \\(R^2\\) simply call the function glance() on your model_fit, e.g.\n\nmodel_fit &lt;- linear_reg() |&gt;\n  fit(outcome ~ predictor, data = data_set)\n  \nglance(model_fit)"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#two-predictors",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#two-predictors",
    "title": "Regression with multiple predictors",
    "section": "Two predictors",
    "text": "Two predictors\n\\[\ny = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\epsilon\n\\]\n\n\n\\(y\\): the outcome variable. Also called the “response” or “dependent variable”. In prediction problems, this is what we are interested in predicting.\n\\(x_i\\): the \\(i^{th}\\) predictor. Also commonly referred to as “regressor”, “independent variable”, “covariate”, “feature”, “the data”.\n\\(\\beta_i\\): “constants” or coefficients i.e. fixed numbers. These are population parameters. \\(\\beta_0\\) has another special name, “the intercept”.\n\\(\\epsilon\\): the error. This quantity represents observational error, i.e. the difference between our observation and the true population-level expected value: \\(\\beta_0 + \\beta_1 x\\).\nEffectively this model says our data \\(y\\) is linearly related to the \\(x_1\\) and \\(x_2\\) but is not perfectly observed due to unexplained errors."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#a-simple-example",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#a-simple-example",
    "title": "Regression with multiple predictors",
    "section": "A simple example",
    "text": "A simple example\nLet’s examine the first quarter of 2020 high prices of Microsoft, IBM, and Apple stocks to illustrate some ideas.\n\n\n\n\n\n\n\n\n\n\nIf we have three measurements (variables) then each observation is a point in three-dimensional space. In this example, we can choose one of our measurements to be the outcome variable (e.g. Apple stock price) and use our other two measurements (MSFT and IBM price) as predictors.\nIn general, the total number of measurements, i.e. variables (columns) in our linear model represents the spatial dimension of our model."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#predictors-1-outcome-3-dimensions",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#predictors-1-outcome-3-dimensions",
    "title": "Regression with multiple predictors",
    "section": "2 predictors + 1 outcome = 3 dimensions",
    "text": "2 predictors + 1 outcome = 3 dimensions\nThe fitted linear model no longer looks like a line, but instead looks like a plane. It shows our prediction of AAPL price (\\(y\\)) given both MSFT price (\\(x_1\\)) and IBM price (\\(x_2\\))."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#fitting-a-multiple-regression-model-in-r",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#fitting-a-multiple-regression-model-in-r",
    "title": "Regression with multiple predictors",
    "section": "Fitting a multiple regression model in R",
    "text": "Fitting a multiple regression model in R\nFind the equation of the plane by adding in new predictors:\n\nmy_model_fit &lt;- linear_reg() |&gt;\n  fit(outcome ~ predictor1 + predictor2 + predictor3 + ..., data = data_frame)\n\n. . .\n\nThis code template will fit the model according to the ordinary least squares (OLS) objective function, i.e., we are finding the equation of the hyperplane that minimizes the sum of squared residuals\n\n. . .\n\nYou can then display a tidy output of the model with the tidy() function on your fitted model: tidy(my_model_fit)\n\nToday we’ll explore the question “How do volume and weights books relate?” and “How, if at all, does that change when we take whether the book is hardback or paperback into consideration?”"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-1",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-1",
    "title": "Regression with multiple predictors",
    "section": "Exercise 1",
    "text": "Exercise 1\nVisualize the relationship between volume (on the x-axis) and weight (on the y-axis). Overlay the line of best fit. Describe the relationship between these variables.\n\nggplot(allbacks, aes(x = volume, y = weight)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = F) +\n  labs(\n    x = \"Volume (cubic centimeters)\",\n    y = \"Weight (grams)\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-2",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-2",
    "title": "Regression with multiple predictors",
    "section": "Exercise 2",
    "text": "Exercise 2\nFit a model predicting weight from volume for these books and save it as weight_fit. Display a tidy output of the model.\n\nweight_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume, data = allbacks)\n\ntidy(weight_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic    p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n1 (Intercept)  108.      88.4         1.22 0.245     \n2 volume         0.709    0.0975      7.27 0.00000626"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-3",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-3",
    "title": "Regression with multiple predictors",
    "section": "Exercise 3",
    "text": "Exercise 3\nInterpret the slope and the intercept in context of the data.\n\n\nIntercept: when the book volume is 0, on average, the weight is approximately 107.68. This doesn’t make sense in the context of the data, and the intercept is only there to adjust the height of the line on the \\(y\\)-axis.\nSlope: For each additional cubic centimeter the book volume increases by, on average, we expect the weight to increase by 0.71 grams."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-4",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-4",
    "title": "Regression with multiple predictors",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate the \\(R^2\\) of this model and interpret it in context of the data.\n\nglance(weight_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic    p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.803         0.787  124.      52.9 0.00000626     1  -92.5  191.  193.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\nVolume explains approximately 80% of the variability in book weights."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-5",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-5",
    "title": "Regression with multiple predictors",
    "section": "Exercise 5",
    "text": "Exercise 5\nVisualize the relationship between volume (on the x-axis) and weight (on the y-axis), taking into consideration the cover type of the book. Use different colors and shapes for hardback and paperback books. Also use different colors for lines of best fit for the two types of books. In addition, add the overall line of best fit (from Exercise 1) as a gray dashed line so that you can see the difference between the lines when considering and not considering cover type.\n\nggplot(allbacks, aes(x = volume, y = weight)) + \n  geom_point(aes(color = cover, shape = cover)) + \n  geom_smooth(method = \"lm\", se = F, color = \"gray\", linetype = \"dashed\") +\n  geom_smooth(aes(color = cover), method = \"lm\", se = F) +\n  labs( \n    x = \"Volume (cubic centimeters)\",\n    y = \"Weight (grams)\",\n    shape = \"Cover\",\n    color = \"Cover\"\n      )\n\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\n\nThe slopes of two lines seem fairly similar, however, their intercepts are different. Maybe we should have a model with different intercepts depending on the cover type."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-6",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-6",
    "title": "Regression with multiple predictors",
    "section": "Exercise 6",
    "text": "Exercise 6\nFit a model predicting weight from volume for these books and save it as weight_cover_fit. Display a tidy output of the model.\n\nweight_cover_fit &lt;- linear_reg() |&gt;\n  fit(weight ~ volume + cover, data = allbacks) \n\ntidy(weight_cover_fit)\n\n# A tibble: 3 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)  198.      59.2         3.34 0.00584     \n2 volume         0.718    0.0615     11.7  0.0000000660\n3 coverpb     -184.      40.5        -4.55 0.000672"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#categorical-predictor-with-two-levels",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#categorical-predictor-with-two-levels",
    "title": "Regression with multiple predictors",
    "section": "Categorical predictor with two levels",
    "text": "Categorical predictor with two levels\nWhen using a predictor with two levels, we create a variable that takes on two values, 0 or 1 depending on the level of the categorical variable. In our example, \\(x_2\\) (or \\(\\text{cover}_{pb}\\)) is the variable representing whether the book is paperback. In particular, \\(x_2 = 1\\) is the book is paperback, and 0 otherwise. We can write this as:\n\\[\n\\widehat{\\text{weight}} = \\hat\\beta_0 + \\hat\\beta_1\\times\\text{volume} +\\hat \\beta_2 \\times \\text{cover}_{\\text{pb}}.\n\\] Thus, our model becomes \\[\n\\widehat{\\text{weight}} = 198 + 0.718\\times\\text{volume} -184 \\times \\text{cover}_{\\text{pb}}.\n\\]"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-7",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-7",
    "title": "Regression with multiple predictors",
    "section": "Exercise 7",
    "text": "Exercise 7\nIn the model output we have a variable coverpb. Why is only the pb (paperback) level of the cover variable shown? What happened to the hb (hardback) level?\n\nHardback is the reference level, therefore it does not show up in the model output.\n\nBy default, R chooses reference level alphabetically. Thus, in our example, hb is the reference level."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#coefficients",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#coefficients",
    "title": "Regression with multiple predictors",
    "section": "Coefficients",
    "text": "Coefficients\nTo better understand what the coefficients represent, lets write out the model for hardback and paperback books separately.\n\nHardback: if the book is hardback, \\(\\text{cover}_{pb}\\) = 0, so our model becomes: \\[\n\\widehat{\\text{weight}} = \\hat{\\beta_0} + \\hat\\beta_1\\times\\text{volume} +\\hat\\beta_2 \\times 0 = \\hat\\beta_0 + \\hat\\beta_1\\times\\text{volume}.\n\\]\nPaperback: if the book is hardback, \\(\\text{cover}_{pb}\\) = 1, so our model becomes: \\[\n\\widehat{\\text{weight}} = \\hat{\\beta_0} + \\hat{\\beta_1}\\times\\text{volume} +\\hat{\\beta_2}\\times 1 = (\\hat{\\beta_0} + \\hat{\\beta_2}) + \\hat{\\beta_1}\\times\\text{volume}.\n\\]\n\nFrom the first case, \\(\\hat\\beta_0\\) corresponds to the intercept in the case when the book is hardback., i.e. the average weight we expect for a hardback book with volume 0.\nFrom the second case, \\(\\hat\\beta_0 + \\hat\\beta_2\\) corresponds to the intercept in the case when the book is paperback, i.e. the average weight we expect for a paperback book with volume 0.\nFixing the volume to be the same (say \\(v\\)) for two books, the difference in average weight between paperback and hardback book is \\[\n(\\hat{\\beta_0} + \\hat{\\beta_2}) + \\hat{\\beta_1}\\times v - (\\hat\\beta_0 + \\hat\\beta_1\\times v) = \\hat\\beta_2.\n\\] Thus, \\(\\hat\\beta_2\\) is how much the model predicts the weight of paperback book to differ from the weight of hardback book (reference level) given both have the same volume."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-8",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-8",
    "title": "Regression with multiple predictors",
    "section": "Exercise 8",
    "text": "Exercise 8\nInterpret the slopes and the intercept in context of the data.\n\n\nIntercept: Books with volume 0 that are hardback are expected, on average, to weight approximately 197.96 grams. This doesn’t make sense in the context of the data, and the intercept is only there to adjust the height of the line on the \\(y\\)-axis.\nSlope - volume: all else held constant, for each additional cubic centimeter the book’s volume increases, we expect the weight to increase by 0.72 grams, on average.\nSlope - cover: controlling for volume, paperback books weigh, on average, 184.05 grams less than hardback books."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-9",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-9",
    "title": "Regression with multiple predictors",
    "section": "Exercise 9",
    "text": "Exercise 9\nFirst, guess whether the \\(R^2\\) of this model will be greater than, less than, or the same as the previous model, or whether we can’t tell. Then, calculate the \\(R^2\\) of this model to confirm your guess, and then interpret it in context of the data.\n\nglance(weight_cover_fit)\n\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC\n      &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0.927         0.915  78.2      76.7 0.000000145     2  -85.0  178.  181.\n# ℹ 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;\n\n\n\n\\(R^2\\) of this model will be higher since it has an additional predictor.\nVolume and cover type explain approximately 93% of the variability on book weights."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-10",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-10",
    "title": "Regression with multiple predictors",
    "section": "Exercise 10",
    "text": "Exercise 10\nWhich model is preferred for predicting book weights and why?\n\nThe second model since it has higher adjusted \\(R^2\\)."
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-11",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#exercise-11",
    "title": "Regression with multiple predictors",
    "section": "Exercise 11",
    "text": "Exercise 11\nUsing the model you chose, predict the weight of a hardcover book that is 1000 cubic centimeters (that is, roughly 25 centimeters in length, 20 centimeters in width, and 2 centimeters in height/thickness).\n\nnew_book &lt;- tibble(\n  cover = \"hb\",\n  volume = 1000\n)\n\npredict(weight_cover_fit, new_data = new_book)\n\n# A tibble: 1 × 1\n  .pred\n  &lt;dbl&gt;\n1  916.\n\n\nAnother way to do it is to use the output directly. Since we are looking at the hardback cover, we set \\(\\text{cover}_{pb} = 0\\). We have:\n\\[\n\\begin{align*}\n\\widehat{\\text{weight}} &= 198 + 0.718\\times\\text{volume} -184 \\times \\text{cover}\\_{\\text{pb}} \\\\\n&= 198 + 0.718 \\times 1000 - 0\\\\\n&= 916\n\\end{align*}\n\\]"
  },
  {
    "objectID": "lectures/07/07-regression-multiple-predictors-filled-in.html#more-levels-in-categorical-variable",
    "href": "lectures/07/07-regression-multiple-predictors-filled-in.html#more-levels-in-categorical-variable",
    "title": "Regression with multiple predictors",
    "section": "More levels in categorical variable",
    "text": "More levels in categorical variable\nWhen we fit a model using a categorical variable with \\(k \\geq 2\\) levels, the output provides \\(k-1\\) rows for the variable. Each row represents the relative difference for each level of the variable. However, one level will not get a row. The missing level is called the reference level and it represents the default level that other levels are measured against.\nIn particular, \\(k-1\\) dummy variables are created, corresponding to \\(k-1\\) non-reference levels. Each of the variables take on a value of 1 if the observation belongs to the corresponding level, and 0 otherwise.\nGoing back to our example, suppose, in addition, we had a board book (bb) cover type. By default, R chooses reference level alphabetically. Thus, the reference level for cover type would be board book. Since there would now be 3 levels (bb, hb, pb), we would have 2 dummy variables and software would provide 2 coefficients. Our model would be:\n\\[\n\\begin{align*}\n\\widehat{\\text{weight}} = \\hat\\beta_0 + \\hat\\beta_1\\times\\text{volume} +\\hat \\beta_2 \\times \\text{cover}_{\\text{hb}} + \\hat\\beta_3\\times \\text{cover}_{\\text{pb}}.\n\\end{align*}\n\\] where \\(\\text{cover}_{hb}\\) is 1 if the book is hardback and 0 otherwise, and \\(\\text{cover}_{pb}\\) is 1 if the book is hardback and 0 otherwise.\nWe now have:\n\nBoard book: if the book is board book, \\(\\text{cover}_{hb} = 0\\), \\(\\text{cover}_{pb}\\) = 0, so our model becomes: \\[\n\\widehat{\\text{weight}} = \\hat{\\beta_0} + \\hat\\beta_1\\times\\text{volume} +\\hat\\beta_2 \\times 0 + \\hat\\beta_3\\times 0= \\hat\\beta_0 + \\hat\\beta_1\\times\\text{volume}.\n\\]\nHardback: if the book is hardback, \\(\\text{cover}_{hb} = 1\\), \\(\\text{cover}_{pb}\\) = 0, so our model becomes: \\[\n\\widehat{\\text{weight}} = \\hat{\\beta_0} + \\hat{\\beta_1}\\times\\text{volume} +\\hat{\\beta_2}\\times 1 + \\hat{\\beta_3}\\times 0 = (\\hat{\\beta_0} + \\hat{\\beta_2}) + \\hat{\\beta_1}\\times\\text{volume}.\n  \\]\nPaperback: if the book is paperback, \\(\\text{cover}_{hb} = 0\\), \\(\\text{cover}_{pb}\\) = 1, so our model becomes: \\[\n    \\widehat{\\text{weight}} = \\hat{\\beta_0} + \\hat{\\beta_1}\\times\\text{volume} +\\hat{\\beta_2}\\times 0 + \\hat{\\beta_3}\\times 1 = (\\hat{\\beta_0} + \\hat{\\beta_3}) + \\hat{\\beta_1}\\times\\text{volume}.\n  \\]\n\nFrom the first case, \\(\\hat\\beta_0\\) corresponds to the intercept in the case when the book is board book, i.e. the average weight we expect for a board book with volume 0.\nFrom the second case, \\(\\hat\\beta_0 + \\hat\\beta_2\\) corresponds to the intercept in the case when the book is hardback., i.e. the average weight we expect for a hardback book with volume 0.\nFrom the third case, \\(\\hat\\beta_0 + \\hat\\beta_3\\) corresponds to the intercept in the case when the book is paperback., i.e. the average weight we expect for a hardback book with volume 0.\nFixing the volume to be the same (say \\(v\\)), the difference in average weight between hardback and board book is \\[\n(\\hat{\\beta_0} + \\hat{\\beta_2}) + \\hat{\\beta_1}\\times v - (\\hat\\beta_0 + \\hat\\beta_1\\times v) = \\hat\\beta_2.\n\\] Thus, \\(\\hat\\beta_2\\) is how much the model predicts the weight of hardback book to differ from the weight of board book (reference level) given both have the same volume.\nFixing the volume to be the same (say \\(v\\)) , the difference in average weight between paperback and board book is \\[\n(\\hat{\\beta_0} + \\hat{\\beta_3}) + \\hat{\\beta_1}\\times v - (\\hat\\beta_0 + \\hat\\beta_1\\times v) = \\hat\\beta_3.\n\\] Thus, \\(\\hat\\beta_3\\) is how much the model predicts the weight of paperback book to differ from the weight of board book (reference level) given both have the same volume.\n\n\n\n\n\n\nImportant\n\n\n\nThe coefficients tell us how the levels compare to the reference level! Thus, \\(\\hat\\beta_2\\) compares board books and hardback books, and \\(\\hat\\beta_3\\) compares board books and paperback books."
  },
  {
    "objectID": "lectures/12/12-ethics.html#announcements",
    "href": "lectures/12/12-ethics.html#announcements",
    "title": "Ethics",
    "section": "Announcements",
    "text": "Announcements\n\nExam review tomorrow! Come with questions."
  },
  {
    "objectID": "lectures/12/12-ethics.html#cost-of-gas",
    "href": "lectures/12/12-ethics.html#cost-of-gas",
    "title": "Ethics",
    "section": "Cost of gas",
    "text": "Cost of gas"
  },
  {
    "objectID": "lectures/12/12-ethics.html#cost-of-gas-1",
    "href": "lectures/12/12-ethics.html#cost-of-gas-1",
    "title": "Ethics",
    "section": "Cost of gas",
    "text": "Cost of gas"
  },
  {
    "objectID": "lectures/12/12-ethics.html#covid-19-cases",
    "href": "lectures/12/12-ethics.html#covid-19-cases",
    "title": "Ethics",
    "section": "COVID-19 Cases",
    "text": "COVID-19 Cases\n\n\n\n\n\n\nWhat is wrong with this graph? How would you correct it?"
  },
  {
    "objectID": "lectures/12/12-ethics.html#covid-19-cases---redo",
    "href": "lectures/12/12-ethics.html#covid-19-cases---redo",
    "title": "Ethics",
    "section": "COVID-19 Cases - redo",
    "text": "COVID-19 Cases - redo\n\n\n\n\n\n\n\nSource: https://livefreeordichotomize.com/posts/2020-05-17-graph-detective"
  },
  {
    "objectID": "lectures/12/12-ethics.html#brexit",
    "href": "lectures/12/12-ethics.html#brexit",
    "title": "Ethics",
    "section": "Brexit",
    "text": "Brexit\n\n\n\n\n\n\n\nWhat is the graph trying to show?\nWhy is this graph misleading?\nHow can you improve this graph?\n\n\n\n\nSource: https://humansofdata.atlan.com/2019/02/dos-donts-data-visualization"
  },
  {
    "objectID": "lectures/12/12-ethics.html#exercise-and-cancer",
    "href": "lectures/12/12-ethics.html#exercise-and-cancer",
    "title": "Ethics",
    "section": "Exercise and cancer",
    "text": "Exercise and cancer\n\n\n\n\n\n\n\n\nExercise Can Lower Risk of Some Cancers By 20%\nPeople who were more active had on average a 20% lower risk of cancers of the esophagus, lung, kidney, stomach, endometrium and others compared with people who were less active.\n\n\n\n\nAlice Park. Exercise Can Lower Risk of Some Cancers By 20%. Time Magazine. 16 May 2016."
  },
  {
    "objectID": "lectures/12/12-ethics.html#exercise-and-cancer---another-look",
    "href": "lectures/12/12-ethics.html#exercise-and-cancer---another-look",
    "title": "Ethics",
    "section": "Exercise and cancer - another look",
    "text": "Exercise and cancer - another look\n\n\n\n\n\n\n\n\nExercising drives down risk for 13 cancers, research shows\n[…] those who got the most moderate to intense exercise reduced their risk of developing seven kinds of cancer by at least 20%.\n\n\n\n\nMelissa Healy. Exercising drives down risk for 13 cancers, research shows.\nLos Angeles Times. 16 May 2016."
  },
  {
    "objectID": "lectures/12/12-ethics.html#spurious-correlations",
    "href": "lectures/12/12-ethics.html#spurious-correlations",
    "title": "Ethics",
    "section": "Spurious correlations",
    "text": "Spurious correlations\n\n\n\n\n\n\n\nWhat does this graph show?\n\n\n\n\nSource: https://www.tylervigen.com/spurious-correlations"
  },
  {
    "objectID": "lectures/12/12-ethics.html#catalan-independence",
    "href": "lectures/12/12-ethics.html#catalan-independence",
    "title": "Ethics",
    "section": "Catalan independence",
    "text": "Catalan independence\nOn December 19, 2014, the front page of Spanish national newspaper El País read “Catalan public opinion swings toward ‘no’ for independence, says survey”.\n\n\n\n\n\n\n\nAlberto Cairo. The truthful art: Data, charts, and maps for communication. New Riders, 2016."
  },
  {
    "objectID": "lectures/12/12-ethics.html#catalan-independence---with-uncertainty",
    "href": "lectures/12/12-ethics.html#catalan-independence---with-uncertainty",
    "title": "Ethics",
    "section": "Catalan independence - with uncertainty",
    "text": "Catalan independence - with uncertainty\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlberto Cairo. “Uncertainty and Graphicacy: How Should Statisticians Journalists and Designers Reveal Uncertainty in Graphics for Public Consumption?”, Power from Statistics: Data Information and Knowledge, 2017."
  },
  {
    "objectID": "lectures/12/12-ethics.html#google-translate---a-few-years-ago",
    "href": "lectures/12/12-ethics.html#google-translate---a-few-years-ago",
    "title": "Ethics",
    "section": "Google translate - a few years ago",
    "text": "Google translate - a few years ago"
  },
  {
    "objectID": "lectures/12/12-ethics.html#google-translate---today",
    "href": "lectures/12/12-ethics.html#google-translate---today",
    "title": "Ethics",
    "section": "Google translate - today",
    "text": "Google translate - today"
  },
  {
    "objectID": "lectures/12/12-ethics.html#criminal-sentencing",
    "href": "lectures/12/12-ethics.html#criminal-sentencing",
    "title": "Ethics",
    "section": "Criminal sentencing",
    "text": "Criminal sentencing\nThere’s software used across the country to predict future criminals.\nAnd it’s biased against blacks.\n\n\n\n\n\n\n\nJulia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner. Machine Bias. 23 May 2016. ProPublica."
  },
  {
    "objectID": "lectures/12/12-ethics.html#a-tale-of-two-convicts",
    "href": "lectures/12/12-ethics.html#a-tale-of-two-convicts",
    "title": "Ethics",
    "section": "A tale of two convicts",
    "text": "A tale of two convicts"
  },
  {
    "objectID": "lectures/12/12-ethics.html#propublica-analysis",
    "href": "lectures/12/12-ethics.html#propublica-analysis",
    "title": "Ethics",
    "section": "ProPublica analysis",
    "text": "ProPublica analysis\n\nData: Risk scores assigned to more than 7,000 people arrested in Broward County, Florida, in 2013 and 2014 + whether they were charged with new crimes over the next two years.\n\n\n\nResults:\n\n20% of those predicted to commit violent crimes actually did\nAlgorithm had higher accuracy (61%) when full range of crimes taken into account (e.g. misdemeanors)\n\nAlgorithm was more likely to falsely flag black defendants as future criminals, at almost twice the rate as white defendants\nWhite defendants were mislabeled as low risk more often than black defendants"
  },
  {
    "objectID": "lectures/12/12-ethics.html#how-to-write-a-racist-ai-without-trying",
    "href": "lectures/12/12-ethics.html#how-to-write-a-racist-ai-without-trying",
    "title": "Ethics",
    "section": "How to write a racist AI without trying",
    "text": "How to write a racist AI without trying\n\n\n\nThomas Lumley. How to write a racist AI in R without really trying.\nBiased and Inefficient. 27 September 2018."
  },
  {
    "objectID": "lectures/12/12-ethics.html#chat-gpt",
    "href": "lectures/12/12-ethics.html#chat-gpt",
    "title": "Ethics",
    "section": "Chat GPT",
    "text": "Chat GPT\n\n\n\nDo you use Chat GPT? How?\nHow, if at all, does Chat GPT (or other similar Large Language Models) reflect human bias?\nHow would you feel if a company use AI-assisted chatbots to respond to your product return requests? How about if your professors responded to your emails with a similar chatbot? How about if your therapist responded to your inquiries with a similar chatbot?"
  },
  {
    "objectID": "lectures/12/12-ethics.html#web-scraping",
    "href": "lectures/12/12-ethics.html#web-scraping",
    "title": "Ethics",
    "section": "Web scraping",
    "text": "Web scraping\n\nA data analyst received permission to post a data set that was scraped from a social media site. The full data set included name, screen name, email address, geographic location, IP (Internet protocol) address, demographic profiles, and preferences for relationships. The analyst removes name and email address from the data set in effort to deidentify it.\n\nWhy might it be problematic to post this data set publicly?\nHow can you store the full dataset in a safe and ethical way?\nYou want to make the data available so your analysis is transparent and reproducible. How can you modify the full data set to make the data available in an ethical way?"
  },
  {
    "objectID": "lectures/12/12-ethics.html#further-reading-1",
    "href": "lectures/12/12-ethics.html#further-reading-1",
    "title": "Ethics",
    "section": "Further reading",
    "text": "Further reading\n\nExecutive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence by The White House\nMachine Bias by Julia Angwin, Jeff Larson, Surya Mattu, and Lauren Kirchner\nEthics and Data Science by Mike Loukides, Hilary Mason, DJ Patil (Free Kindle download)\nWeapons of Math Destruction How Big Data Increases Inequality and Threatens Democracy by Cathy O’Neil\nAlgorithms of Oppression How Search Engines Reinforce Racism by Safiya Umoja Noble\nWhy Pokémon Go’s plan to 3D-scan the world is dangerous by Loren Smith\nHow Charts Lie: Getting Smarter about Visual Information by Alberto Cairo\nCalling Bullshit: The Art of Skepticism in a Data-Driven World by Carl Bergstrom and Jevin West"
  },
  {
    "objectID": "lectures/03/03_study_design.html",
    "href": "lectures/03/03_study_design.html",
    "title": "Study design",
    "section": "",
    "text": "Thanks to those who read the syllabus and followed the prompts\nLab 1 is due Sunday (May 19) at 11:59 pm on Gradescope\nLate policy review\n\n\nAny questions about the first assignment due?"
  },
  {
    "objectID": "lectures/03/03_study_design.html#announcements",
    "href": "lectures/03/03_study_design.html#announcements",
    "title": "Study design",
    "section": "",
    "text": "Thanks to those who read the syllabus and followed the prompts\nLab 1 is due Sunday (May 19) at 11:59 pm on Gradescope\nLate policy review\n\n\nAny questions about the first assignment due?"
  },
  {
    "objectID": "lectures/03/03_study_design.html#reading-check-in",
    "href": "lectures/03/03_study_design.html#reading-check-in",
    "title": "Study design",
    "section": "Reading check in",
    "text": "Reading check in\n\nAny questions on the readings or tutorials?"
  },
  {
    "objectID": "lectures/03/03_study_design.html#sat-scores-and-teacher-salaries",
    "href": "lectures/03/03_study_design.html#sat-scores-and-teacher-salaries",
    "title": "Study design",
    "section": "SAT scores and teacher salaries",
    "text": "SAT scores and teacher salaries\n\nWhat is going on in the following plot?\n\n\n\n\n\n\n\n\nModern Data Science with R. Baumer, Kaplan, Horton. (2023)"
  },
  {
    "objectID": "lectures/03/03_study_design.html#sat-scores-and-teacher-salaries-1",
    "href": "lectures/03/03_study_design.html#sat-scores-and-teacher-salaries-1",
    "title": "Study design",
    "section": "SAT scores and teacher salaries",
    "text": "SAT scores and teacher salaries\n\nWhat about this plot?"
  },
  {
    "objectID": "lectures/03/03_study_design.html#covid-vaccine-and-deaths-from-delta-variant",
    "href": "lectures/03/03_study_design.html#covid-vaccine-and-deaths-from-delta-variant",
    "title": "Study design",
    "section": "COVID vaccine and deaths from Delta variant",
    "text": "COVID vaccine and deaths from Delta variant\nThe main question we’ll explore today is “How do deaths from COVID cases compare between vaccinated and unvaccinated?”\nWhat do you think?"
  },
  {
    "objectID": "lectures/03/03_study_design.html#exercise-1",
    "href": "lectures/03/03_study_design.html#exercise-1",
    "title": "Study design",
    "section": "Exercise 1",
    "text": "Exercise 1\nHow many rows and columns are in this dataset? Answer in a full sentence using inline code. What does each row represent and what does each column represent? For each variable, identify its type.\nAdd your answer here."
  },
  {
    "objectID": "lectures/03/03_study_design.html#exercise-2",
    "href": "lectures/03/03_study_design.html#exercise-2",
    "title": "Study design",
    "section": "Exercise 2",
    "text": "Exercise 2\nDo these data come from an observational study or experiment? Why?\nAdd your answer here."
  },
  {
    "objectID": "lectures/03/03_study_design.html#exercise-3",
    "href": "lectures/03/03_study_design.html#exercise-3",
    "title": "Study design",
    "section": "Exercise 3",
    "text": "Exercise 3\nCreate a visualization of health outcome by vaccine status that allows you to compare the proportion of deaths across those who are and are not vaccinated. What can you say about death rates in these two groups based on this visualization?\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "lectures/03/03_study_design.html#exercise-4",
    "href": "lectures/03/03_study_design.html#exercise-4",
    "title": "Study design",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate the proportion of deaths in among those who are vaccinated. Then, calculate the proportion among those who are not vaccinated.\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "lectures/03/03_study_design.html#exercise-5",
    "href": "lectures/03/03_study_design.html#exercise-5",
    "title": "Study design",
    "section": "Exercise 5",
    "text": "Exercise 5\nCreate the visualization and calculate proportions from the two previous exercises, this time controlling for age. How do the proportions compare?\nAdd your answer here.\n\n# add code here"
  },
  {
    "objectID": "lectures/03/03_study_design.html#exercise-6",
    "href": "lectures/03/03_study_design.html#exercise-6",
    "title": "Study design",
    "section": "Exercise 6",
    "text": "Exercise 6\nBased on your findings so far, fill in the blanks with more, less, or equally: Is there anything surprising about these statements? Speculate on what, if anything, the discrepancy might be due to.\n\nIn 2021, among those in the UK who were COVID Delta cases, the vaccinated were ___ likely to die than the unvaccinated.\nFor those under 50, those who were unvaccinated were ___ likely to die than those who were vaccinated.\nFor those 50 and up, those who were unvaccinated were ___ likely to die than those who were vaccinated.\n\nAdd your answer here."
  },
  {
    "objectID": "lectures/03/03_study_design.html#exercise-7",
    "href": "lectures/03/03_study_design.html#exercise-7",
    "title": "Study design",
    "section": "Exercise 7",
    "text": "Exercise 7\nLet’s rephrase the previous question which asked you to speculate on why deaths among vaccinated cases overall is higher while deaths among unvaccinated cases are higher when we split the data into two groups (below 50 and 50 and up). What might be the confounding variable in the relationship between vaccination and deaths?\nAdd your answer here."
  },
  {
    "objectID": "lectures/03/03_study_design.html#exercise-8",
    "href": "lectures/03/03_study_design.html#exercise-8",
    "title": "Study design",
    "section": "Exercise 8",
    "text": "Exercise 8\nVisualize and describe the distribution of seniors (50 and up) based on (a.k.a. conditional on) vaccination status. Hint: Your description will benefit from calculating proportions of seniors in each of the vaccination groups and working those values into your narrative.\nAdd your answer here.\n\n# add your code here"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html",
    "title": "Regression with one predictor",
    "section": "",
    "text": "We’ll work with data on Apple and Microsoft stock prices and use the tidyverse and tidymodels packages. The data for lecture was originally gathered using the tidyquant R package. It features Apple and Microsoft stock prices from January 1st 2020 to December 31st 2021.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nstocks &lt;- read_csv(\"stocks.csv\")\n\n\n\n\n\\[\ny = \\beta_{1} + \\beta_1 x + \\epsilon\n\\]\n\n\n\\(y\\): the outcome variable. Also called the “response” or “dependent variable”. In prediction problems, this is what we are interested in predicting.\n\\(x\\): the predictor. Also commonly referred to as “regressor”, “independent variable”, “covariate”, “feature”, “the data”.\n\\(\\beta_0\\), \\(\\beta_1\\) are called “constants” or coefficients. They are fixed numbers. These are population parameters. \\(\\beta_0\\) has another special name, “the intercept”.\n\\(\\epsilon\\): the error. This quantity represents observational error, i.e. the difference between our observation and the true population-level expected value: \\(\\beta_0 + \\beta_1 x\\).\n\n\n. . .\nEffectively this model says our data \\(y\\) is linearly related to \\(x\\) but is not perfectly observed due to some error.\n\n\n\nLet’s examine January 2020 open prices of Microsoft and Apple stocks to illustrate some ideas.\n\nstocks_jan2020 &lt;- stocks |&gt;\n  filter(month(date) == 1 & year(date) == 2020)\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )\n\n\n\n\n\n\n\n\n\n\n\nBefore we get to fitting the best model, let’s fit “some” model, say with slope = -5 and intercept = 0.5.\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  geom_abline(slope = 0.5, intercept = -5) +\n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )\n\n\n\n\n\n\n\n\n\n\n\n\\[\n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x  \\\\\n\\hat{y} = -5 + 0.5 ~ x\n\\]\n\n\\(\\hat{y}\\) is the expected outcome\n\\(\\hat{\\beta}\\) is the estimated or fitted coefficient\nThere is no error term here because we do not predict error\n\n\n\n\n\n\nPopulation:\n\\[\ny = \\beta_0 + \\beta_1 ~ x\n\\]\n\nSamples: \\[\n\\hat{y} = \\hat{\\beta_0} +  \\hat{\\beta_1} ~ x\n\\]\n\n\n\n\nThe central idea is that if we measure every \\(x\\) and every \\(y\\) in existence, (“the entire population”) there is some true “best” \\(\\beta_0\\) and \\(\\beta_1\\) that describe the relationship between \\(x\\) and \\(y\\)\nSince we only have a sample of the data, we estimate \\(\\beta_0\\) and \\(\\beta_1\\)\nWe call our estimates \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) “beta hat”. We never have all the data, thus we never can really know what the true \\(\\beta\\)s are\n\n\n\n\n\n\nFor any linear equation we write down, there will be some difference between the predicted outcome of our linear model (\\(\\hat{y}\\)) and what we observe (\\(y\\))… (But of course! Otherwise everything would fall on a perfect straight line!)\n\nThis difference between what we observe and what we predict \\(y - \\hat{y}\\) is known as a residual, \\(e\\).\nMore concisely,\n\\[\ne = y - \\hat{y}\n\\]\n\n\n\nResiduals are dependent on the line we draw. Visually, here is a model of the data, \\(y = -5 + 0.5 ~ x\\) and one of the residuals is outlined in red.\n\n\n\n\n\n\n\n\n\n\n\n\nThere is, in fact, a residual associated with every single point in the plot.\n\n\n\n\n\n\n\n\n\n\n\n\nWe often wish to find a line that fits the data “really well”, but what does this mean? Well, we want small residuals! So we pick an objective function. That is, a function we wish to minimize or maximize.\nToday we’ll explore the question “How do stock prices of Apple and Microsoft relate to each other?”"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#data-and-packages",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#data-and-packages",
    "title": "Regression with one predictor",
    "section": "",
    "text": "We’ll work with data on Apple and Microsoft stock prices and use the tidyverse and tidymodels packages. The data for lecture was originally gathered using the tidyquant R package. It features Apple and Microsoft stock prices from January 1st 2020 to December 31st 2021.\n\nlibrary(tidyverse)\nlibrary(tidymodels)\n\nstocks &lt;- read_csv(\"stocks.csv\")"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#simple-regression-model-and-notation",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#simple-regression-model-and-notation",
    "title": "Regression with one predictor",
    "section": "",
    "text": "\\[\ny = \\beta_{1} + \\beta_1 x + \\epsilon\n\\]\n\n\n\\(y\\): the outcome variable. Also called the “response” or “dependent variable”. In prediction problems, this is what we are interested in predicting.\n\\(x\\): the predictor. Also commonly referred to as “regressor”, “independent variable”, “covariate”, “feature”, “the data”.\n\\(\\beta_0\\), \\(\\beta_1\\) are called “constants” or coefficients. They are fixed numbers. These are population parameters. \\(\\beta_0\\) has another special name, “the intercept”.\n\\(\\epsilon\\): the error. This quantity represents observational error, i.e. the difference between our observation and the true population-level expected value: \\(\\beta_0 + \\beta_1 x\\).\n\n\n. . .\nEffectively this model says our data \\(y\\) is linearly related to \\(x\\) but is not perfectly observed due to some error."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#stock-prices-of-microsoft-and-apple",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#stock-prices-of-microsoft-and-apple",
    "title": "Regression with one predictor",
    "section": "",
    "text": "Let’s examine January 2020 open prices of Microsoft and Apple stocks to illustrate some ideas.\n\nstocks_jan2020 &lt;- stocks |&gt;\n  filter(month(date) == 1 & year(date) == 2020)\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#fitting-some-model",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#fitting-some-model",
    "title": "Regression with one predictor",
    "section": "",
    "text": "Before we get to fitting the best model, let’s fit “some” model, say with slope = -5 and intercept = 0.5.\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  geom_abline(slope = 0.5, intercept = -5) +\n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#fitting-some-model-1",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#fitting-some-model-1",
    "title": "Regression with one predictor",
    "section": "",
    "text": "\\[\n\\hat{y} = \\hat{\\beta}_0 + \\hat{\\beta}_1 ~ x  \\\\\n\\hat{y} = -5 + 0.5 ~ x\n\\]\n\n\\(\\hat{y}\\) is the expected outcome\n\\(\\hat{\\beta}\\) is the estimated or fitted coefficient\nThere is no error term here because we do not predict error"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#populations-vs.-samples",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#populations-vs.-samples",
    "title": "Regression with one predictor",
    "section": "",
    "text": "Population:\n\\[\ny = \\beta_0 + \\beta_1 ~ x\n\\]\n\nSamples: \\[\n\\hat{y} = \\hat{\\beta_0} +  \\hat{\\beta_1} ~ x\n\\]\n\n\n\n\nThe central idea is that if we measure every \\(x\\) and every \\(y\\) in existence, (“the entire population”) there is some true “best” \\(\\beta_0\\) and \\(\\beta_1\\) that describe the relationship between \\(x\\) and \\(y\\)\nSince we only have a sample of the data, we estimate \\(\\beta_0\\) and \\(\\beta_1\\)\nWe call our estimates \\(\\hat{\\beta_0}\\), \\(\\hat{\\beta_1}\\) “beta hat”. We never have all the data, thus we never can really know what the true \\(\\beta\\)s are"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#residuals",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#residuals",
    "title": "Regression with one predictor",
    "section": "",
    "text": "For any linear equation we write down, there will be some difference between the predicted outcome of our linear model (\\(\\hat{y}\\)) and what we observe (\\(y\\))… (But of course! Otherwise everything would fall on a perfect straight line!)\n\nThis difference between what we observe and what we predict \\(y - \\hat{y}\\) is known as a residual, \\(e\\).\nMore concisely,\n\\[\ne = y - \\hat{y}\n\\]"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#a-residual-visualized",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#a-residual-visualized",
    "title": "Regression with one predictor",
    "section": "",
    "text": "Residuals are dependent on the line we draw. Visually, here is a model of the data, \\(y = -5 + 0.5 ~ x\\) and one of the residuals is outlined in red."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#all-residuals-visualized",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#all-residuals-visualized",
    "title": "Regression with one predictor",
    "section": "",
    "text": "There is, in fact, a residual associated with every single point in the plot."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#minimize-residuals",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#minimize-residuals",
    "title": "Regression with one predictor",
    "section": "",
    "text": "We often wish to find a line that fits the data “really well”, but what does this mean? Well, we want small residuals! So we pick an objective function. That is, a function we wish to minimize or maximize.\nToday we’ll explore the question “How do stock prices of Apple and Microsoft relate to each other?”"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-1",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-1",
    "title": "Regression with one predictor",
    "section": "Exercise 1",
    "text": "Exercise 1\nAt first, you might be tempted to minimize \\(\\sum_i e_i\\), the sum of all residuals, but this is problematic. Why? Can you come up with a better solution (other than the one listed below)?\n\n\nLarge positive and negative residuals could cancel out.\nWe could minimize the sum of absolute values."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#minimize-the-sum-of-squared-residuals",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#minimize-the-sum-of-squared-residuals",
    "title": "Regression with one predictor",
    "section": "Minimize the sum of squared residuals",
    "text": "Minimize the sum of squared residuals\nIn practice, we minimize the sum of squared residuals:\n\\[\n\\sum_i e_i^2\n\\]\nNote, this is the same as\n\\[\n\\sum_i (y_i - \\hat{y}_i)^2\n\\]"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-2",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-2",
    "title": "Regression with one predictor",
    "section": "Exercise 2",
    "text": "Exercise 2\nCheck out an interactive visualization of “least squares regression” here. Click on I and drag the points around to get started. Describe what you see.\n\nEach square is a “square residual”. The line minimizes the sum of squared residuals, (i.e. it minimizes the total area of squares we see on the screen).\nThis is called “Ordinary Least Squares” (OLS) regression."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-4",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-4",
    "title": "Regression with one predictor",
    "section": "Exercise 4",
    "text": "Exercise 4\nIn the slides we fit a model with slope 0.5 and intercept -5. The code for layering the line that represents the model over your data is given below. Add geom_smooth() as described above with color = \"steelblue\" to see how close your line is.\n\nggplot(stocks_jan2020, aes(x = MSFT.Open, y = AAPL.Open)) +\n  geom_point() + \n  geom_abline(slope = 0.5, intercept = -5) +\n  geom_smooth(method = \"lm\", se = F, color = \"steelblue\") +\n  labs(\n    x = \"MSFT Open\", \n    y = \"AAPL Open\", \n    title = \"Open prices of MSFT and AAPL\",\n    subtitle = \"January 2020\"\n  )\n\n`geom_smooth()` using formula = 'y ~ x'"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-5",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-5",
    "title": "Regression with one predictor",
    "section": "Exercise 5",
    "text": "Exercise 5\nFind the least squares line \\(y = \\hat{\\beta_0} + \\hat{\\beta_1} x\\) for January 2020, where \\(x\\) is Microsoft’s opening price and \\(y\\) is Apple’s opening price. Display a tidy summary of your model.\n\nmic_app_fit &lt;- linear_reg() |&gt;\n  fit(AAPL.Open ~ MSFT.Open, data =stocks_jan2020)\n\ntidy(mic_app_fit)\n\n# A tibble: 2 × 5\n  term        estimate std.error statistic      p.value\n  &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;        &lt;dbl&gt;\n1 (Intercept)    3.31     8.87       0.373 0.713       \n2 MSFT.Open      0.454    0.0541     8.40  0.0000000808"
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-6",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-6",
    "title": "Regression with one predictor",
    "section": "Exercise 6",
    "text": "Exercise 6\nRe-write the fitted equation replacing \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) with the estimates from the model you fit in the previous exercise.\n\\[\n\\hat{y} = 3.31174 + 0.45423 x\n\\]\nwhere \\(\\hat{y}\\) is the predicted Apple open price and \\(x\\) is the open price of Microsoft.\n\\(\\hat{\\beta}_0 = 3.31174\\) and \\(\\hat{\\beta}_1 = 0.45423\\)."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-7",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#exercise-7",
    "title": "Regression with one predictor",
    "section": "Exercise 7",
    "text": "Exercise 7\nInterpret \\(\\hat{\\beta}_0\\) and \\(\\hat{\\beta}_1\\) in context of the data.\n\n\\(\\hat{\\beta}_0 = 3.31174\\) is the price of Apple if Microsoft opened at 0.\n\\(\\hat{\\beta}_1 = 0.45423\\) : for every dollar increase in Microsoft open price, we expect Apple open price to increase by 0.45423."
  },
  {
    "objectID": "lectures/06/06-regression-one-predictor-filled-in.html#bonus-exercise",
    "href": "lectures/06/06-regression-one-predictor-filled-in.html#bonus-exercise",
    "title": "Regression with one predictor",
    "section": "Bonus exercise",
    "text": "Bonus exercise\nSay Microsoft opens at 166 dollars. What do I predict the opening price of AAPL to be?\n\\[\n\\hat{y} = 3.31174 + 0.45423 * 166\n\\]\n\nyhat &lt;- 3.31174 + 0.45423*166\nyhat\n\n[1] 78.71392"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "A hypothesis test is a statistical technique used to evaluate competing claims using data.\n\nNull hypothesis, \\(H_o\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n\n\n\n\n\nNote\n\n\n\nHypotheses are always at the population level!\n\n\n\n\n\nSuppose you’re cooking a pot of soup:\n\n\nTaste a spoonful and decide if that spoonful has enough salt \\(\\rightarrow\\) exploratory data analysis of the sample\nDecide the pot of soup must also have enough salt since the spoonful does \\(\\rightarrow\\) inference\nMixing the soup in the pot before taking a spoonful \\(\\rightarrow\\) randomizing\nTaking a spoonful with the intention of making an inference about the pot \\(\\rightarrow\\) sampling\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::%||%()   masks base::%||%()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5          ✔ rsample      1.2.0     \n✔ dials        1.2.0          ✔ tune         1.1.2     \n✔ infer        1.0.5.9000     ✔ workflows    1.1.3     \n✔ modeldata    1.2.0          ✔ workflowsets 1.0.1     \n✔ parsnip      1.1.1          ✔ yardstick    1.2.0     \n✔ recipes      1.0.8          \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::%||%()     masks base::%||%()\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(openintro)  # for data for case study 2: yawn\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#hypothesis-testing-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#hypothesis-testing-1",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "A hypothesis test is a statistical technique used to evaluate competing claims using data.\n\nNull hypothesis, \\(H_o\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n\n\n\n\n\nNote\n\n\n\nHypotheses are always at the population level!"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#populations-vs.-samples",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#populations-vs.-samples",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "Suppose you’re cooking a pot of soup:\n\n\nTaste a spoonful and decide if that spoonful has enough salt \\(\\rightarrow\\) exploratory data analysis of the sample\nDecide the pot of soup must also have enough salt since the spoonful does \\(\\rightarrow\\) inference\nMixing the soup in the pot before taking a spoonful \\(\\rightarrow\\) randomizing\nTaking a spoonful with the intention of making an inference about the pot \\(\\rightarrow\\) sampling"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#packages",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#packages",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::%||%()   masks base::%||%()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5          ✔ rsample      1.2.0     \n✔ dials        1.2.0          ✔ tune         1.1.2     \n✔ infer        1.0.5.9000     ✔ workflows    1.1.3     \n✔ modeldata    1.2.0          ✔ workflowsets 1.0.1     \n✔ parsnip      1.1.1          ✔ yardstick    1.2.0     \n✔ recipes      1.0.8          \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::%||%()     masks base::%||%()\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use tidymodels_prefer() to resolve common conflicts.\n\nlibrary(openintro)  # for data for case study 2: yawn\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#organ-donors",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#organ-donors",
    "title": "Hypothesis testing with randomization",
    "section": "Organ donors",
    "text": "Organ donors\nPeople providing an organ for donation sometimes seek the help of a special “medical consultant”. These consultants assist the patient in all aspects of the surgery, with the goal of reducing the possibility of complications during the medical procedure and recovery. Patients might choose a consultant based in part on the historical complication rate of the consultant’s clients.\nOne consultant tried to attract patients by noting that the average complication rate for liver donor surgeries in the US is about 10%, but her clients have only had 3 complications in the 62 liver donor surgeries she has facilitated. She claims this is strong evidence that her work meaningfully contributes to reducing complications (and therefore she should be hired!)."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#data",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#data",
    "title": "Hypothesis testing with randomization",
    "section": "Data",
    "text": "Data\n\norgan_donor &lt;- read_csv(\"organ-donor.csv\")\n\norgan_donor |&gt;\n  count(outcome)\n\n# A tibble: 2 × 2\n  outcome             n\n  &lt;chr&gt;           &lt;int&gt;\n1 complication        3\n2 no complication    59"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#parameter-vs.-statistic",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#parameter-vs.-statistic",
    "title": "Hypothesis testing with randomization",
    "section": "Parameter vs. statistic",
    "text": "Parameter vs. statistic\nA parameter for a hypothesis test is the “true” value of interest. We typically estimate the parameter using a sample statistic as a point estimate.\n\\(p~\\): true rate of complication\n\\(\\hat{p}~\\): rate of complication in the sample = \\(\\frac{3}{62}\\) = 0.048"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#correlation-vs.-causation",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#correlation-vs.-causation",
    "title": "Hypothesis testing with randomization",
    "section": "Correlation vs. causation",
    "text": "Correlation vs. causation\n\nIs it possible to assess the consultant’s claim using the data?\n\nNo. The claim is that there is a causal connection, but the data are observational. For example, maybe patients who can afford a medical consultant can afford better medical care, which can also lead to a lower complication rate.\nWhile it is not possible to assess the causal claim, it is still possible to test for an association using these data. For this question we ask, could the low complication rate of \\(\\hat{p}\\) = 0.048 be due to chance?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#two-claims",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#two-claims",
    "title": "Hypothesis testing with randomization",
    "section": "Two claims",
    "text": "Two claims\n\nNull hypothesis: “There is nothing going on”\n\nComplication rate for this consultant is no different than the US average of 10%\n\nAlternative hypothesis: “There is something going on”\n\nComplication rate for this consultant is different than the US average of 10%"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#hypothesis-testing-as-a-court-trial",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#hypothesis-testing-as-a-court-trial",
    "title": "Hypothesis testing with randomization",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\nHypotheses:\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\n\nPresent the evidence: Collect data\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#hypothesis-testing-framework",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#hypothesis-testing-framework",
    "title": "Hypothesis testing with randomization",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\), that represents the status quo\nSet an alternative hypothesis, \\(H_A\\), that represents the research question, i.e. what we’re testing for\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#setting-the-hypotheses",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#setting-the-hypotheses",
    "title": "Hypothesis testing with randomization",
    "section": "Setting the hypotheses",
    "text": "Setting the hypotheses\n\nWhich of the following is the correct set of hypotheses for evaluating whether the consultant’s complication rate is different than the US average of 10%?\n\n\n\\(H_0: p = 0.10\\); \\(H_A: p \\ne 0.10\\)\n\\(H_0: p = 0.10\\); \\(H_A: p &gt; 0.10\\)\n\\(H_0: p = 0.10\\); \\(H_A: p &lt; 0.10\\)\n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} \\ne 0.10\\)\n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} &gt; 0.10\\)\n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} &lt; 0.10\\)"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulating-the-null-distribution",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulating-the-null-distribution",
    "title": "Hypothesis testing with randomization",
    "section": "Simulating the null distribution",
    "text": "Simulating the null distribution\nSince \\(H_0: p = 0.10\\), we need to simulate a null distribution where the probability of success (complication) for each trial (patient) is 0.10.\n\n\nDescribe how you would simulate the null distribution for this study using a bag of chips. How many chips? What colors? What do the colors indicate? How many draws? With replacement or without replacement?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#what-do-we-expect",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#what-do-we-expect",
    "title": "Hypothesis testing with randomization",
    "section": "What do we expect?",
    "text": "What do we expect?\n\nWhen sampling from the null distribution, what is the expected proportion of success (complications)?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-1",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation #1",
    "text": "Simulation #1\n\n\nsim1\n   complication no complication \n              7              55 \n\n\n[1] 0.1129032"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-2",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-2",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation #2",
    "text": "Simulation #2\n\n\nsim2\n   complication no complication \n             10              52 \n\n\n[1] 0.1612903"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-3",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-3",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation #3",
    "text": "Simulation #3\n\n\nsim3\n   complication no complication \n              5              57 \n\n\n[1] 0.08064516"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#this-is-getting-boring",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#this-is-getting-boring",
    "title": "Hypothesis testing with randomization",
    "section": "This is getting boring…",
    "text": "This is getting boring…\nWe need a way to automate this process!\nThe first dataset we’ll use is organ_donors:\n\norgan_donor &lt;- read_csv(\"organ-donor.csv\")\n\nRows: 62 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): outcome\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe hypotheses we are testing are:\n\\(H_0: p = 0.10\\)\n\\(H_A: p \\ne 0.10\\)\nwhere \\(p\\) is the true complication rate for this consultant."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-1",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 1",
    "text": "Exercise 1\nConstruct the null distribution with 100 resamples. Name it null_dist_donor. How many rows does null_dist_donor have? How many columns? What does each row and each column represent?\n\n# add code here\n\nAdd response here."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-2",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-2",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhere do you expect the center of the null distribution to be? Visualize it to confirm.\n\n# option 1\n\n# add code here\n\n# option 2\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-2-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-2-1",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 2",
    "text": "Exercise 2\nCalculate the observed complication rate of this consultant. Name it obs_stat_donor.\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-3",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-3",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 3",
    "text": "Exercise 3\nOverlay the observed statistic on the null distribution and comment on whether an observed outcome as extreme as the observed statistic, or lower, is a likely or unlikely outcome, if in fact the null hypothesis is true.\n\n# option 1\n\n# add code here\n\n# option 2\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-4",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-4",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate the p-value and comment on whether it provides convincing evidence that this consultant incurs a lower complication rate than 10% (overall US complication rate).\nAdd response here.\n\n# option 1\n\n# add code here\n\n# option 2\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-5",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-5",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s get real! Redo the test with 15,000 simulations. Note: This can take some time to run.\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#is-yawning-contagious",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#is-yawning-contagious",
    "title": "Hypothesis testing with randomization",
    "section": "Is yawning contagious?",
    "text": "Is yawning contagious?\n\nDo you think yawning is contagious?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#is-yawning-contagious-1",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#is-yawning-contagious-1",
    "title": "Hypothesis testing with randomization",
    "section": "Is yawning contagious?",
    "text": "Is yawning contagious?\nAn experiment conducted by the MythBusters tested if a person can be subconsciously influenced into yawning if another person near them yawns.\nIf you’re interested, you can watch the full episode at https://www.dailymotion.com/video/x7ydkt2."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#study-description",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#study-description",
    "title": "Hypothesis testing with randomization",
    "section": "Study description",
    "text": "Study description\nIn this study 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a control group where they didn’t see someone yawn (control).\nThe data are in the openintro package: yawn\n\nyawn |&gt;\n  count(group, result)\n\n# A tibble: 4 × 3\n  group result       n\n  &lt;fct&gt; &lt;fct&gt;    &lt;int&gt;\n1 ctrl  not yawn    12\n2 ctrl  yawn         4\n3 trmt  not yawn    24\n4 trmt  yawn        10"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#proportion-of-yawners",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#proportion-of-yawners",
    "title": "Hypothesis testing with randomization",
    "section": "Proportion of yawners",
    "text": "Proportion of yawners\n\nyawn |&gt;\n  count(group, result) |&gt;\n  group_by(group) |&gt;\n  mutate(p_hat = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group result       n p_hat\n  &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 ctrl  not yawn    12 0.75 \n2 ctrl  yawn         4 0.25 \n3 trmt  not yawn    24 0.706\n4 trmt  yawn        10 0.294\n\n\n\nProportion of yawners in the treatment group: \\(\\frac{10}{34} = 0.2941\\)\nProportion of yawners in the control group: \\(\\frac{4}{16} = 0.25\\)\nDifference: \\(0.2941 - 0.25 = 0.0441\\)\nOur results match the ones calculated on the MythBusters episode."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#independence",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#independence",
    "title": "Hypothesis testing with randomization",
    "section": "Independence?",
    "text": "Independence?\n\nBased on the proportions we calculated, do you think yawning is really contagious, i.e. are seeing someone yawn and yawning dependent?\n\n\n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group result       n p_hat\n  &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 ctrl  not yawn    12 0.75 \n2 ctrl  yawn         4 0.25 \n3 trmt  not yawn    24 0.706\n4 trmt  yawn        10 0.294"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#dependence-or-another-possible-explanation",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#dependence-or-another-possible-explanation",
    "title": "Hypothesis testing with randomization",
    "section": "Dependence, or another possible explanation?",
    "text": "Dependence, or another possible explanation?\n\n\nThe observed differences might suggest that yawning is contagious, i.e. seeing someone yawn and yawning are dependent.\nBut the differences are small enough that we might wonder if they might simple be due to chance.\nPerhaps if we were to repeat the experiment, we would see slightly different results.\nSo we will do just that - well, somewhat - and see what happens.\nInstead of actually conducting the experiment many times, we will simulate our results."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#two-competing-claims",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#two-competing-claims",
    "title": "Hypothesis testing with randomization",
    "section": "Two competing claims",
    "text": "Two competing claims\n\n\nNull hypothesis:\n“There is nothing going on.” Yawning and seeing someone yawn are independent, yawning is not contagious, observed difference in proportions is simply due to chance.\n\nAlternative hypothesis:\n“There is something going on.” Yawning and seeing someone yawn are dependent, yawning is contagious, observed difference in proportions is not due to chance."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-by-hand---setup",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-by-hand---setup",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation by hand - setup",
    "text": "Simulation by hand - setup\n\nA regular deck of cards is comprised of 52 cards: 4 aces, 4 of numbers 2-10, 4 jacks, 4 queens, and 4 kings.\nTake out two aces from the deck of cards and set them aside.\nThe remaining 50 playing cards to represent each participant in the study:\n\n14 face cards (including the 2 aces) represent the people who yawn.\n36 non-face cards represent the people who don’t yawn."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-by-hand---running",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-by-hand---running",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation by hand - running",
    "text": "Simulation by hand - running\n\nShuffle the 50 cards at least 7 times1 to ensure that the cards counted out are from a random process.\nCount out the top 16 cards and set them aside. These cards represent the people in the control group.\nOut of the remaining 34 cards (treatment group) count the number of face cards (the number of people who yawned in the treatment group).\nCalculate the difference in proportions of yawners (treatment - control), and plot it on the board.\nMark the difference you find on the dot plot on the board.\n\n\n\n[1] http://www.dartmouth.edu/~chance/course/topics/winning_number.html"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-by-computation",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#simulation-by-computation",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation by computation",
    "text": "Simulation by computation"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-6",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#exercise-6",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 6",
    "text": "Exercise 6\nUsing the yawn dataset in the openintro package, conduct a hypothesis test for evaluating whether yawning is contagious. First, set the hypotheses. Then, conduct a randomization test using 1000 simulations. Visualize and calculate the p-value and use it to make a conclusion about the statistical discernability of the difference in proportions of yawners in the two groups. Then, comment on whether you “buy” this conclusion.\nAdd response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#types-of-alternative-hypotheses",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#types-of-alternative-hypotheses",
    "title": "Hypothesis testing with randomization",
    "section": "Types of alternative hypotheses",
    "text": "Types of alternative hypotheses\n\nOne-sided (one-tailed) alternatives: The parameter is hypothesized to be less than or greater than the null value, &lt; or &gt;\nTwo-sided (two-tailed) alternatives: The parameter is hypothesized to be not equal to the null value, \\(\\ne\\)\n\nCalculated as two times the tail area beyond the observed sample statistic\nMore objective, and hence more widely preferred\n\n\n\nAverage systolic blood pressure of people with Stage 1 Hypertension is 150 mm Hg. Suppose we want to use a hypothesis test to evaluate whether a new blood pressure medication has an effect on the average blood pressure of heart patients. What are the hypotheses?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#discernability-level",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#discernability-level",
    "title": "Hypothesis testing with randomization",
    "section": "Discernability level",
    "text": "Discernability level\nWe often use 5% as the cutoff for whether the p-value is low enough that the data are unlikely to have come from the null model. This cutoff value is called the discernability level, \\(\\alpha\\).\n\nIf p-value &lt; \\(\\alpha\\), reject \\(H_0\\) in favor of \\(H_A\\): The data provide convincing evidence for the alternative hypothesis.\nIf p-value &gt; \\(\\alpha\\), fail to reject \\(H_0\\) in favor of \\(H_A\\): The data do not provide convincing evidence for the alternative hypothesis."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#statistically-discernable",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#statistically-discernable",
    "title": "Hypothesis testing with randomization",
    "section": "Statistically discernable",
    "text": "Statistically discernable\n\nIf you’ve taken a statistics course before, or read papers that use hypothesis testing for making a conclusion, you might have encountered the term “statistically significant” or “significance level”.\nWe will use the term “statistically discernable” or discernability level”, because “significant” has a different meaning in everyday language and this often causes misconceptions of what “statistically significant” means. It doesn’t necessarily mean a notable or important event has happened, it just means the data are unlikely to have come from the null model."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization-clean.html#setting-a-seed",
    "href": "lectures/10/10-hypothesis-testing-randomization-clean.html#setting-a-seed",
    "title": "Hypothesis testing with randomization",
    "section": "Setting a seed",
    "text": "Setting a seed\n\nGoal: Pin down the random generation so that the same random generation happens each time a document is rendered (by you or by someone else wanting to replicate your results)\nWhen: Set a seed each time right before generate()ing new resamples. Setting a seed once in a document would also work for re-rendering the document, but considering we often run the code chunk interactively, it’s best to set the seed again in each code chunk that does random generation."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html",
    "href": "lectures/10/10-hypothesis-testing-randomization.html",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "A hypothesis test is a statistical technique used to evaluate competing claims using data.\n\nNull hypothesis, \\(H_o\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n\n\n\n\n\nNote\n\n\n\nHypotheses are always at the population level!\n\n\n\n\n\nSuppose you’re cooking a pot of soup:\n\n\nTaste a spoonful and decide if that spoonful has enough salt \\(\\rightarrow\\) exploratory data analysis of the sample\nDecide the pot of soup must also have enough salt since the spoonful does \\(\\rightarrow\\) inference\nMixing the soup in the pot before taking a spoonful \\(\\rightarrow\\) randomizing\nTaking a spoonful with the intention of making an inference about the pot \\(\\rightarrow\\) sampling\n\n\n\n\n\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::%||%()   masks base::%||%()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5          ✔ rsample      1.2.0     \n✔ dials        1.2.0          ✔ tune         1.1.2     \n✔ infer        1.0.5.9000     ✔ workflows    1.1.3     \n✔ modeldata    1.2.0          ✔ workflowsets 1.0.1     \n✔ parsnip      1.1.1          ✔ yardstick    1.2.0     \n✔ recipes      1.0.8          \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::%||%()     masks base::%||%()\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(openintro)  # for data for case study 2: yawn\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#hypothesis-testing-1",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#hypothesis-testing-1",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "A hypothesis test is a statistical technique used to evaluate competing claims using data.\n\nNull hypothesis, \\(H_o\\): An assumption about the population. “There is nothing going on.”\nAlternative hypothesis, \\(H_A\\): A research question about the population. “There is something going on”.\n\n\n\n\n\n\n\nNote\n\n\n\nHypotheses are always at the population level!"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#populations-vs.-samples",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#populations-vs.-samples",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "Suppose you’re cooking a pot of soup:\n\n\nTaste a spoonful and decide if that spoonful has enough salt \\(\\rightarrow\\) exploratory data analysis of the sample\nDecide the pot of soup must also have enough salt since the spoonful does \\(\\rightarrow\\) inference\nMixing the soup in the pot before taking a spoonful \\(\\rightarrow\\) randomizing\nTaking a spoonful with the intention of making an inference about the pot \\(\\rightarrow\\) sampling"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#packages",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#packages",
    "title": "Hypothesis testing with randomization",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ purrr::%||%()   masks base::%||%()\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(tidymodels)\n\n── Attaching packages ────────────────────────────────────── tidymodels 1.1.1 ──\n✔ broom        1.0.5          ✔ rsample      1.2.0     \n✔ dials        1.2.0          ✔ tune         1.1.2     \n✔ infer        1.0.5.9000     ✔ workflows    1.1.3     \n✔ modeldata    1.2.0          ✔ workflowsets 1.0.1     \n✔ parsnip      1.1.1          ✔ yardstick    1.2.0     \n✔ recipes      1.0.8          \n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::%||%()     masks base::%||%()\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Use suppressPackageStartupMessages() to eliminate package startup messages\n\nlibrary(openintro)  # for data for case study 2: yawn\n\nLoading required package: airports\nLoading required package: cherryblossom\nLoading required package: usdata\n\nAttaching package: 'openintro'\n\nThe following object is masked from 'package:modeldata':\n\n    ames"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#organ-donors",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#organ-donors",
    "title": "Hypothesis testing with randomization",
    "section": "Organ donors",
    "text": "Organ donors\nPeople providing an organ for donation sometimes seek the help of a special “medical consultant”. These consultants assist the patient in all aspects of the surgery, with the goal of reducing the possibility of complications during the medical procedure and recovery. Patients might choose a consultant based in part on the historical complication rate of the consultant’s clients.\nOne consultant tried to attract patients by noting that the average complication rate for liver donor surgeries in the US is about 10%, but her clients have only had 3 complications in the 62 liver donor surgeries she has facilitated. She claims this is strong evidence that her work meaningfully contributes to reducing complications (and therefore she should be hired!)."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#data",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#data",
    "title": "Hypothesis testing with randomization",
    "section": "Data",
    "text": "Data\n\norgan_donor &lt;- read_csv(\"organ-donor.csv\")\n\norgan_donor |&gt;\n  count(outcome)\n\n# A tibble: 2 × 2\n  outcome             n\n  &lt;chr&gt;           &lt;int&gt;\n1 complication        3\n2 no complication    59"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#parameter-vs.-statistic",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#parameter-vs.-statistic",
    "title": "Hypothesis testing with randomization",
    "section": "Parameter vs. statistic",
    "text": "Parameter vs. statistic\nA parameter for a hypothesis test is the “true” value of interest. We typically estimate the parameter using a sample statistic as a point estimate.\n\\(p~\\): true rate of complication\n\\(\\hat{p}~\\): rate of complication in the sample = \\(\\frac{3}{62}\\) = 0.048"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#correlation-vs.-causation",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#correlation-vs.-causation",
    "title": "Hypothesis testing with randomization",
    "section": "Correlation vs. causation",
    "text": "Correlation vs. causation\n\nIs it possible to assess the consultant’s claim using the data?\n\nNo. The claim is that there is a causal connection, but the data are observational. For example, maybe patients who can afford a medical consultant can afford better medical care, which can also lead to a lower complication rate.\nWhile it is not possible to assess the causal claim, it is still possible to test for an association using these data. For this question we ask, could the low complication rate of \\(\\hat{p}\\) = 0.048 be due to chance?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#two-claims",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#two-claims",
    "title": "Hypothesis testing with randomization",
    "section": "Two claims",
    "text": "Two claims\n\nNull hypothesis: “There is nothing going on”\n\nComplication rate for this consultant is no different than the US average of 10%\n\nAlternative hypothesis: “There is something going on”\n\nComplication rate for this consultant is different than the US average of 10%"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#hypothesis-testing-as-a-court-trial",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#hypothesis-testing-as-a-court-trial",
    "title": "Hypothesis testing with randomization",
    "section": "Hypothesis testing as a court trial",
    "text": "Hypothesis testing as a court trial\n\nHypotheses:\n\nNull hypothesis, \\(H_0\\): Defendant is innocent\nAlternative hypothesis, \\(H_A\\): Defendant is guilty\n\nPresent the evidence: Collect data\nJudge the evidence: “Could these data plausibly have happened by chance if the null hypothesis were true?”\n\nYes: Fail to reject \\(H_0\\)\nNo: Reject \\(H_0\\)"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#hypothesis-testing-framework",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#hypothesis-testing-framework",
    "title": "Hypothesis testing with randomization",
    "section": "Hypothesis testing framework",
    "text": "Hypothesis testing framework\n\n\nStart with a null hypothesis, \\(H_0\\), that represents the status quo\nSet an alternative hypothesis, \\(H_A\\), that represents the research question, i.e. what we’re testing for\nConduct a hypothesis test under the assumption that the null hypothesis is true and calculate a p-value (probability of observed or more extreme outcome given that the null hypothesis is true)\n\nif the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis\nif they do, then reject the null hypothesis in favor of the alternative"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#setting-the-hypotheses",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#setting-the-hypotheses",
    "title": "Hypothesis testing with randomization",
    "section": "Setting the hypotheses",
    "text": "Setting the hypotheses\n\nWhich of the following is the correct set of hypotheses for evaluating whether the consultant’s complication rate is different than the US average of 10%?\n\n\n\\(H_0: p = 0.10\\); \\(H_A: p \\ne 0.10\\)\n\\(H_0: p = 0.10\\); \\(H_A: p &gt; 0.10\\)\n\\(H_0: p = 0.10\\); \\(H_A: p &lt; 0.10\\)\n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} \\ne 0.10\\)\n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} &gt; 0.10\\)\n\\(H_0: \\hat{p} = 0.10\\); \\(H_A: \\hat{p} &lt; 0.10\\)"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#simulating-the-null-distribution",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#simulating-the-null-distribution",
    "title": "Hypothesis testing with randomization",
    "section": "Simulating the null distribution",
    "text": "Simulating the null distribution\nSince \\(H_0: p = 0.10\\), we need to simulate a null distribution where the probability of success (complication) for each trial (patient) is 0.10.\n\n\nDescribe how you would simulate the null distribution for this study using a bag of chips. How many chips? What colors? What do the colors indicate? How many draws? With replacement or without replacement?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#what-do-we-expect",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#what-do-we-expect",
    "title": "Hypothesis testing with randomization",
    "section": "What do we expect?",
    "text": "What do we expect?\n\nWhen sampling from the null distribution, what is the expected proportion of success (complications)?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#simulation-1",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#simulation-1",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation #1",
    "text": "Simulation #1\n\n\nsim1\n   complication no complication \n              7              55 \n\n\n[1] 0.1129032"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#simulation-2",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#simulation-2",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation #2",
    "text": "Simulation #2\n\n\nsim2\n   complication no complication \n             10              52 \n\n\n[1] 0.1612903"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#simulation-3",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#simulation-3",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation #3",
    "text": "Simulation #3\n\n\nsim3\n   complication no complication \n              5              57 \n\n\n[1] 0.08064516"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#this-is-getting-boring",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#this-is-getting-boring",
    "title": "Hypothesis testing with randomization",
    "section": "This is getting boring…",
    "text": "This is getting boring…\nWe need a way to automate this process!\nThe first dataset we’ll use is organ_donors:\n\norgan_donor &lt;- read_csv(\"organ-donor.csv\")\n\nRows: 62 Columns: 1\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): outcome\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nThe hypotheses we are testing are:\n\\(H_0: p = 0.10\\)\n\\(H_A: p \\ne 0.10\\)\nwhere \\(p\\) is the true complication rate for this consultant."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#exercise-1",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#exercise-1",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 1",
    "text": "Exercise 1\nConstruct the null distribution with 100 resamples. Name it null_dist_donor. How many rows does null_dist_donor have? How many columns? What does each row and each column represent?\n\n# add code here\n\nAdd response here."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#exercise-2",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#exercise-2",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 2",
    "text": "Exercise 2\nWhere do you expect the center of the null distribution to be? Visualize it to confirm.\n\n# option 1\n\n# add code here\n\n# option 2\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#exercise-2-1",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#exercise-2-1",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 2",
    "text": "Exercise 2\nCalculate the observed complication rate of this consultant. Name it obs_stat_donor.\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#exercise-3",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#exercise-3",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 3",
    "text": "Exercise 3\nOverlay the observed statistic on the null distribution and comment on whether an observed outcome as extreme as the observed statistic, or lower, is a likely or unlikely outcome, if in fact the null hypothesis is true.\n\n# option 1\n\n# add code here\n\n# option 2\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#exercise-4",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#exercise-4",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 4",
    "text": "Exercise 4\nCalculate the p-value and comment on whether it provides convincing evidence that this consultant incurs a lower complication rate than 10% (overall US complication rate).\nAdd response here.\n\n# option 1\n\n# add code here\n\n# option 2\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#exercise-5",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#exercise-5",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 5",
    "text": "Exercise 5\nLet’s get real! Redo the test with 15,000 simulations. Note: This can take some time to run.\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#is-yawning-contagious",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#is-yawning-contagious",
    "title": "Hypothesis testing with randomization",
    "section": "Is yawning contagious?",
    "text": "Is yawning contagious?\n\nDo you think yawning is contagious?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#is-yawning-contagious-1",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#is-yawning-contagious-1",
    "title": "Hypothesis testing with randomization",
    "section": "Is yawning contagious?",
    "text": "Is yawning contagious?\nAn experiment conducted by the MythBusters tested if a person can be subconsciously influenced into yawning if another person near them yawns.\nIf you’re interested, you can watch the full episode at https://www.dailymotion.com/video/x7ydkt2."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#study-description",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#study-description",
    "title": "Hypothesis testing with randomization",
    "section": "Study description",
    "text": "Study description\nIn this study 50 people were randomly assigned to two groups: 34 to a group where a person near them yawned (treatment) and 16 to a control group where they didn’t see someone yawn (control).\nThe data are in the openintro package: yawn\n\nyawn |&gt;\n  count(group, result)\n\n# A tibble: 4 × 3\n  group result       n\n  &lt;fct&gt; &lt;fct&gt;    &lt;int&gt;\n1 ctrl  not yawn    12\n2 ctrl  yawn         4\n3 trmt  not yawn    24\n4 trmt  yawn        10"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#proportion-of-yawners",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#proportion-of-yawners",
    "title": "Hypothesis testing with randomization",
    "section": "Proportion of yawners",
    "text": "Proportion of yawners\n\nyawn |&gt;\n  count(group, result) |&gt;\n  group_by(group) |&gt;\n  mutate(p_hat = n / sum(n))\n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group result       n p_hat\n  &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 ctrl  not yawn    12 0.75 \n2 ctrl  yawn         4 0.25 \n3 trmt  not yawn    24 0.706\n4 trmt  yawn        10 0.294\n\n\n\nProportion of yawners in the treatment group: \\(\\frac{10}{34} = 0.2941\\)\nProportion of yawners in the control group: \\(\\frac{4}{16} = 0.25\\)\nDifference: \\(0.2941 - 0.25 = 0.0441\\)\nOur results match the ones calculated on the MythBusters episode."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#independence",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#independence",
    "title": "Hypothesis testing with randomization",
    "section": "Independence?",
    "text": "Independence?\n\nBased on the proportions we calculated, do you think yawning is really contagious, i.e. are seeing someone yawn and yawning dependent?\n\n\n\n# A tibble: 4 × 4\n# Groups:   group [2]\n  group result       n p_hat\n  &lt;fct&gt; &lt;fct&gt;    &lt;int&gt; &lt;dbl&gt;\n1 ctrl  not yawn    12 0.75 \n2 ctrl  yawn         4 0.25 \n3 trmt  not yawn    24 0.706\n4 trmt  yawn        10 0.294"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#dependence-or-another-possible-explanation",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#dependence-or-another-possible-explanation",
    "title": "Hypothesis testing with randomization",
    "section": "Dependence, or another possible explanation?",
    "text": "Dependence, or another possible explanation?\n\n\nThe observed differences might suggest that yawning is contagious, i.e. seeing someone yawn and yawning are dependent.\nBut the differences are small enough that we might wonder if they might simple be due to chance.\nPerhaps if we were to repeat the experiment, we would see slightly different results.\nSo we will do just that - well, somewhat - and see what happens.\nInstead of actually conducting the experiment many times, we will simulate our results."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#two-competing-claims",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#two-competing-claims",
    "title": "Hypothesis testing with randomization",
    "section": "Two competing claims",
    "text": "Two competing claims\n\n\nNull hypothesis:\n“There is nothing going on.” Yawning and seeing someone yawn are independent, yawning is not contagious, observed difference in proportions is simply due to chance.\n\nAlternative hypothesis:\n“There is something going on.” Yawning and seeing someone yawn are dependent, yawning is contagious, observed difference in proportions is not due to chance."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#simulation-by-hand---setup",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#simulation-by-hand---setup",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation by hand - setup",
    "text": "Simulation by hand - setup\n\nA regular deck of cards is comprised of 52 cards: 4 aces, 4 of numbers 2-10, 4 jacks, 4 queens, and 4 kings.\nTake out two aces from the deck of cards and set them aside.\nThe remaining 50 playing cards to represent each participant in the study:\n\n14 face cards (including the 2 aces) represent the people who yawn.\n36 non-face cards represent the people who don’t yawn."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#simulation-by-hand---running",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#simulation-by-hand---running",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation by hand - running",
    "text": "Simulation by hand - running\n\nShuffle the 50 cards at least 7 times1 to ensure that the cards counted out are from a random process.\nCount out the top 16 cards and set them aside. These cards represent the people in the control group.\nOut of the remaining 34 cards (treatment group) count the number of face cards (the number of people who yawned in the treatment group).\nCalculate the difference in proportions of yawners (treatment - control), and plot it on the board.\nMark the difference you find on the dot plot on the board.\n\n\n\n[1] http://www.dartmouth.edu/~chance/course/topics/winning_number.html"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#simulation-by-computation",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#simulation-by-computation",
    "title": "Hypothesis testing with randomization",
    "section": "Simulation by computation",
    "text": "Simulation by computation"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#exercise-6",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#exercise-6",
    "title": "Hypothesis testing with randomization",
    "section": "Exercise 6",
    "text": "Exercise 6\nUsing the yawn dataset in the openintro package, conduct a hypothesis test for evaluating whether yawning is contagious. First, set the hypotheses. Then, conduct a randomization test using 1000 simulations. Visualize and calculate the p-value and use it to make a conclusion about the statistical discernability of the difference in proportions of yawners in the two groups. Then, comment on whether you “buy” this conclusion.\nAdd response here.\n\n# add code here"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#types-of-alternative-hypotheses",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#types-of-alternative-hypotheses",
    "title": "Hypothesis testing with randomization",
    "section": "Types of alternative hypotheses",
    "text": "Types of alternative hypotheses\n\nOne-sided (one-tailed) alternatives: The parameter is hypothesized to be less than or greater than the null value, &lt; or &gt;\nTwo-sided (two-tailed) alternatives: The parameter is hypothesized to be not equal to the null value, \\(\\ne\\)\n\nCalculated as two times the tail area beyond the observed sample statistic\nMore objective, and hence more widely preferred\n\n\n\nAverage systolic blood pressure of people with Stage 1 Hypertension is 150 mm Hg. Suppose we want to use a hypothesis test to evaluate whether a new blood pressure medication has an effect on the average blood pressure of heart patients. What are the hypotheses?"
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#discernability-level",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#discernability-level",
    "title": "Hypothesis testing with randomization",
    "section": "Discernability level",
    "text": "Discernability level\nWe often use 5% as the cutoff for whether the p-value is low enough that the data are unlikely to have come from the null model. This cutoff value is called the discernability level, \\(\\alpha\\).\n\nIf p-value &lt; \\(\\alpha\\), reject \\(H_0\\) in favor of \\(H_A\\): The data provide convincing evidence for the alternative hypothesis.\nIf p-value &gt; \\(\\alpha\\), fail to reject \\(H_0\\) in favor of \\(H_A\\): The data do not provide convincing evidence for the alternative hypothesis."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#statistically-discernable",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#statistically-discernable",
    "title": "Hypothesis testing with randomization",
    "section": "Statistically discernable",
    "text": "Statistically discernable\n\nIf you’ve taken a statistics course before, or read papers that use hypothesis testing for making a conclusion, you might have encountered the term “statistically significant” or “significance level”.\nWe will use the term “statistically discernable” or discernability level”, because “significant” has a different meaning in everyday language and this often causes misconceptions of what “statistically significant” means. It doesn’t necessarily mean a notable or important event has happened, it just means the data are unlikely to have come from the null model."
  },
  {
    "objectID": "lectures/10/10-hypothesis-testing-randomization.html#setting-a-seed",
    "href": "lectures/10/10-hypothesis-testing-randomization.html#setting-a-seed",
    "title": "Hypothesis testing with randomization",
    "section": "Setting a seed",
    "text": "Setting a seed\n\nGoal: Pin down the random generation so that the same random generation happens each time a document is rendered (by you or by someone else wanting to replicate your results)\nWhen: Set a seed each time right before generate()ing new resamples. Setting a seed once in a document would also work for re-rendering the document, but considering we often run the code chunk interactively, it’s best to set the seed again in each code chunk that does random generation."
  },
  {
    "objectID": "lectures/02/02-hello_data.html",
    "href": "lectures/02/02-hello_data.html",
    "title": "Hello data",
    "section": "",
    "text": "Office hours are updated with minor changes on the course website .\nIf you haven’t yet done so, please:\n\ncomplete the Getting to know you survey\nread through the syllabus"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#rstudio",
    "href": "lectures/02/02-hello_data.html#rstudio",
    "title": "Hello data",
    "section": "RStudio",
    "text": "RStudio\n\nFiles, plots, viewer, environment, etc. panes\nConsole\nEditor"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#r",
    "href": "lectures/02/02-hello_data.html#r",
    "title": "Hello data",
    "section": "R",
    "text": "R\n\nWriting code in the console\nBasic math with R\nCreating variables in R, the assignment operator (&lt;-), and the Environment pane\nR functions and packages and the Packages pane\nGetting help with R and the Help pane"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#quarto",
    "href": "lectures/02/02-hello_data.html#quarto",
    "title": "Hello data",
    "section": "Quarto",
    "text": "Quarto\n\nYAML: Metadata\nNarrative: Edited with the visual editor (or the source editor)\nCode: In code chunks\n\nChunk options (following #|)\nComments (following #)\nCode\n\nRunning individual code chunks vs. rendering a document"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#load-packages",
    "href": "lectures/02/02-hello_data.html#load-packages",
    "title": "Hello data",
    "section": "Load packages",
    "text": "Load packages\nWe’ll use the tidyverse package for analysis, which offers functionality for data import, wrangling, visualization, and more.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\nLoading this package prints out a message. What does this message mean? How can we suppress the message from the output?"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#load-data",
    "href": "lectures/02/02-hello_data.html#load-data",
    "title": "Hello data",
    "section": "Load data",
    "text": "Load data\nThe read_csv() function can be used for reading CSV (comma separated values) files. The file we’re reading is called flint with the suffix (.csv) which indicates its file type.\n\nflint &lt;- read_csv(\"flint.csv\")\n\nRows: 813 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): draw\ndbl (4): id, zip, ward, lead\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nOne of two things may have happened:\n\nThe file was read successfully and you now see a dataset called flint in your Environment pane.\nThe file was not read successfully and you see an error Error in read_csv(\"data/flint.csv\") : could not find function \"read_csv\".\n\nIf (1) happened, great!\nIf (2) happened, let’s troubleshoot first before continuing."
  },
  {
    "objectID": "lectures/02/02-hello_data.html#data-dictionary",
    "href": "lectures/02/02-hello_data.html#data-dictionary",
    "title": "Hello data",
    "section": "Data dictionary",
    "text": "Data dictionary\nThe following variables are in the flint data frame:\n\nid: sample ID number (identifies the home)\nzip: ZIP code in Flint of the sample’s location\nward: ward in Flint of the sample’s location\ndraw: which time point the water was sampled from\nlead: lead content in parts per billion (ppb)"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#populations-and-samples",
    "href": "lectures/02/02-hello_data.html#populations-and-samples",
    "title": "Hello data",
    "section": "Populations and samples",
    "text": "Populations and samples\nWe want to learn about the population using a sample.\nIn the case we want to learn about the lead content in all of Flint, MI homes but only have available water readings from a sample of homes (our data set).\nExercise 1: Look at the data, how many observations are there? How many variables?\n\n# add code here"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#frequencies",
    "href": "lectures/02/02-hello_data.html#frequencies",
    "title": "Hello data",
    "section": "Frequencies",
    "text": "Frequencies\nLet’s count() to find the number of different time points water was sampled with the count() function.\n\nThe first argument is flint: the data frame\nThe second argument is draw: the variable\n\n\ncount(flint, draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can achieve the same result with the following “piped” operation as well.\n\nThe first line is flint: the data frame\nThen the pipe operator, read as “and then”, which places what comes before it as the first argument of what comes after it\nThe second line is count(draw)\n\n\nflint |&gt;\n  count(draw)\n\n# A tibble: 3 × 2\n  draw       n\n  &lt;chr&gt;  &lt;int&gt;\n1 first    271\n2 second   271\n3 third    271\n\n\nWe can use a similar approach to fund out how many unique homes are in the data set:\n\nflint |&gt;\n  count(id)\n\n# A tibble: 269 × 2\n      id     n\n   &lt;dbl&gt; &lt;int&gt;\n 1     1     3\n 2     2     3\n 3     4     3\n 4     5     3\n 5     6     3\n 6     7     3\n 7     8     3\n 8     9     3\n 9    12     3\n10    13     3\n# ℹ 259 more rows\n\n\nExercise 2: How many samples were taken from each zip code?\n\n# add code here\n\nExercise 3: Which ZIP code had the most samples drawn? Hint: See the help for count.\n\n# add code here"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#measures-of-central-tendency",
    "href": "lectures/02/02-hello_data.html#measures-of-central-tendency",
    "title": "Hello data",
    "section": "Measures of central tendency",
    "text": "Measures of central tendency\n\nmean\nmedian\nmode"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#measures-of-spread",
    "href": "lectures/02/02-hello_data.html#measures-of-spread",
    "title": "Hello data",
    "section": "Measures of spread",
    "text": "Measures of spread\n\nvariance\nstandard deviation\nrange\nquartiles\ninter-quartile range (IQR)"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#order-statistics",
    "href": "lectures/02/02-hello_data.html#order-statistics",
    "title": "Hello data",
    "section": "Order statistics",
    "text": "Order statistics\n\nquantiles\nminimum (0 percentile)\nmedian (50th percentile)\nmaximum (100 percentile)\n\n… and any other arbitrary function of the data you can come up with!\nExercise 4: Compute each of these statistics for lead ppb.\n\n# add code here"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#histograms",
    "href": "lectures/02/02-hello_data.html#histograms",
    "title": "Hello data",
    "section": "Histograms",
    "text": "Histograms\nLet’s take a look at the distribution of lead content in homes in Flint, MI.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n\nWe can make this plot look nicer/more useful by adjusting the number of bins and zooming into the x-axis.\n\nggplot(flint, aes(x = lead)) +\n  geom_histogram(bins = 50) +\n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nLet’s visualize some of our summary statistics on the plot.\nExercise 5: Add a new layer, geom_vline(xintercept = __, color = \"red\"), to the histogram below, filling in the blank with the mean.\n\nggplot(flint, aes(x = lead)) + \n  geom_histogram(bins = 50) + \n  coord_cartesian(xlim = c(0, 100))\n\n\n\n\n\n\n\n\nExercise 6: Add one more layer which overlays the median, in a different color.\n\n# add code here"
  },
  {
    "objectID": "lectures/02/02-hello_data.html#box-plots",
    "href": "lectures/02/02-hello_data.html#box-plots",
    "title": "Hello data",
    "section": "Box plots",
    "text": "Box plots\nNext, let’s narrow our focus to the zip codes 48503, 48504, 48505, 48506, and 48507 and observations with lead values less than 1,000 ppb.\n\nflint_focus &lt;- flint |&gt;\n  filter(zip %in% 48503:48507 & lead &lt; 1000)\n\nExercise 7: Below are side-by-side box plots for the three flushing times in each of the five zip codes we considered. Add x and y labels; add a title by inserting title = \"title_name\" inside the labs() function.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) +\n  labs(x = \"___\", y = \"___\", fill = \"Flushing time\") +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  )\n\n\n\n\n\n\n\n\nExercise 8: Add labels for x, y, a title, and subtitle to the code below to update the corresponding plot.\n\nggplot(data = flint_focus, aes(y = factor(zip), x = lead)) +\n  geom_boxplot(aes(fill = factor(draw))) + \n  labs(\n    x = \"___\", y = \"___\", fill = \"Flushing time\",\n    title = \"___\",\n    subtitle = \"___\"\n    ) +\n  scale_fill_discrete(\n    breaks = c(\"first\", \"second\", \"third\"),\n    labels = c(\"0 (sec)\", \"45 (sec)\", \"120 (sec)\")\n  ) +\n  coord_cartesian(xlim = c(0, 50)) +\n  theme_bw()\n\n\n\n\n\n\n\n\nExercise 9: What is the difference between the two plots? What are the advantages and disadvantages to each plot?\n[Add your answer here]"
  },
  {
    "objectID": "computing/computing-access.html",
    "href": "computing/computing-access.html",
    "title": "Computing access",
    "section": "",
    "text": "To access RStudio in the browser, go to the Duke Container Manager.\nAt the beginning of the semester you should reserve an RStudio container for STA101.",
    "crumbs": [
      "Computing",
      "Access"
    ]
  }
]